{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serde import serde\n",
    "from serde.json import to_json, from_json\n",
    "from dataclasses import dataclass\n",
    "from time import sleep\n",
    "from scrapping import Voiture\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import conversion_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récuperation du json et conversion en quelque chose d'utilisable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion en base de données panda et nettoyage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarques sur les variables :\n",
    "\n",
    "- modele : enlever les espaces, ou supprimer les variables peu occurentes (<=1)\n",
    "- carburant : même remarque\n",
    "- même remarque pour toutes les variables textuelles\n",
    "- utilisation précédente : regrouper par pro/loueur/part/ ne sait pas ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de dummys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = conversion_df.data_frame_pandas('donnees_citroen.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modele                    object\n",
       "carburant                 object\n",
       "prix                       int64\n",
       "kilometrage              float64\n",
       "garantie_kilometrage      object\n",
       "boite_de_vitesse          object\n",
       "transmission             float64\n",
       "couleur                   object\n",
       "garantie                  object\n",
       "date_mise_circulation      int64\n",
       "puissance                float64\n",
       "silhouette                object\n",
       "nb_places                float64\n",
       "utilisation_prec          object\n",
       "puissance_fiscale        float64\n",
       "critair                  float64\n",
       "ptac                     float64\n",
       "nb_portes                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1835.0\n",
       "1      2300.0\n",
       "2      1735.0\n",
       "3      1540.0\n",
       "4      1600.0\n",
       "        ...  \n",
       "595    1795.0\n",
       "596    1610.0\n",
       "597    1610.0\n",
       "598    1610.0\n",
       "599    1610.0\n",
       "Name: ptac, Length: 600, dtype: float64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ptac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modele                    string\n",
       "carburant                 string\n",
       "prix                       Int64\n",
       "kilometrage              Float64\n",
       "garantie_kilometrage      string\n",
       "boite_de_vitesse          string\n",
       "transmission               Int64\n",
       "couleur                   string\n",
       "garantie                  string\n",
       "date_mise_circulation      Int64\n",
       "puissance                Float64\n",
       "silhouette                string\n",
       "nb_places                Float64\n",
       "utilisation_prec          string\n",
       "puissance_fiscale        Float64\n",
       "critair                  Float64\n",
       "ptac                     Float64\n",
       "nb_portes                Float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.convert_dtypes().dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passage sous numpy + ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'conversion_df' from 'c:\\\\Users\\\\mathi\\\\Documents\\\\Cours\\\\M2\\\\Machine Learning\\\\VERON_NEPVEUX_PROJECT\\\\veron_nepveux_project\\\\conversion_df.py'>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "import conversion_df\n",
    "\n",
    "reload(conversion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = conversion_df.data_frame_modele('donnees_citroen.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20629.,  2021.,   110., ...,     0.,     0.,     0.],\n",
       "       [ 5104.,  2022.,   181., ...,     0.,     0.,     0.],\n",
       "       [ 8900.,  2021.,   131., ...,     0.,     0.,     0.],\n",
       "       ...,\n",
       "       [   30.,  2022.,   110., ...,     0.,     0.,     0.],\n",
       "       [   30.,  2022.,   110., ...,     0.,     0.,     0.],\n",
       "       [   30.,  2022.,   110., ...,     0.,     0.,     0.]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.297e+08, tolerance: 1.955e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+08, tolerance: 2.229e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.303e+08, tolerance: 2.340e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+08, tolerance: 2.337e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.409e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+08, tolerance: 1.955e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.982e+07, tolerance: 2.229e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.390e+08, tolerance: 2.340e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.483e+08, tolerance: 2.337e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.767e+07, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.969e+07, tolerance: 1.955e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.952e+08, tolerance: 2.229e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.688e+08, tolerance: 2.340e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+07, tolerance: 2.337e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+07, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+07, tolerance: 1.955e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.449e+07, tolerance: 2.229e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.199e+08, tolerance: 2.340e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.215e+08, tolerance: 2.337e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.283e+08, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.975e+07, tolerance: 2.229e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.398e+06, tolerance: 2.340e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+08, tolerance: 2.337e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.582e+07, tolerance: 2.221e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.238e+07, tolerance: 2.340e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.819e+06, tolerance: 2.229e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.147e+06, tolerance: 2.229e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.701e+08, tolerance: 2.340e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023535</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 0.01}</td>\n",
       "      <td>0.894038</td>\n",
       "      <td>0.914747</td>\n",
       "      <td>0.892849</td>\n",
       "      <td>0.918680</td>\n",
       "      <td>0.898777</td>\n",
       "      <td>0.903818</td>\n",
       "      <td>0.010786</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015957</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 0.25}</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>0.915369</td>\n",
       "      <td>0.896189</td>\n",
       "      <td>0.921021</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.907085</td>\n",
       "      <td>0.009503</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023568</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 0.5}</td>\n",
       "      <td>0.907773</td>\n",
       "      <td>0.915394</td>\n",
       "      <td>0.899678</td>\n",
       "      <td>0.923603</td>\n",
       "      <td>0.907909</td>\n",
       "      <td>0.910871</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036303</td>\n",
       "      <td>0.009946</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 0.75}</td>\n",
       "      <td>0.920262</td>\n",
       "      <td>0.913786</td>\n",
       "      <td>0.902274</td>\n",
       "      <td>0.926609</td>\n",
       "      <td>0.912487</td>\n",
       "      <td>0.915083</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.105939</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 1}</td>\n",
       "      <td>0.944220</td>\n",
       "      <td>0.908411</td>\n",
       "      <td>0.893623</td>\n",
       "      <td>0.934955</td>\n",
       "      <td>0.921566</td>\n",
       "      <td>0.920555</td>\n",
       "      <td>0.018117</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.023535      0.005659         0.000994        0.000631    0.015625   \n",
       "1       0.015957      0.001089         0.000399        0.000488    0.015625   \n",
       "2       0.023568      0.004683         0.000567        0.000464    0.015625   \n",
       "3       0.036303      0.009946         0.000598        0.000489    0.015625   \n",
       "4       0.105939      0.006449         0.000705        0.000379    0.015625   \n",
       "\n",
       "  param_l1_ratio                                 params  split0_test_score  \\\n",
       "0           0.01  {'alpha': 0.015625, 'l1_ratio': 0.01}           0.894038   \n",
       "1           0.25  {'alpha': 0.015625, 'l1_ratio': 0.25}           0.899720   \n",
       "2            0.5   {'alpha': 0.015625, 'l1_ratio': 0.5}           0.907773   \n",
       "3           0.75  {'alpha': 0.015625, 'l1_ratio': 0.75}           0.920262   \n",
       "4              1     {'alpha': 0.015625, 'l1_ratio': 1}           0.944220   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.914747           0.892849           0.918680           0.898777   \n",
       "1           0.915369           0.896189           0.921021           0.903125   \n",
       "2           0.915394           0.899678           0.923603           0.907909   \n",
       "3           0.913786           0.902274           0.926609           0.912487   \n",
       "4           0.908411           0.893623           0.934955           0.921566   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.903818        0.010786               16  \n",
       "1         0.907085        0.009503               15  \n",
       "2         0.910871        0.008077               13  \n",
       "3         0.915083        0.008150               11  \n",
       "4         0.920555        0.018117                9  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = ElasticNet()\n",
    "en_gs = GridSearchCV(\n",
    "    en,\n",
    "    {\n",
    "        \"alpha\": [2 ** p  for p in range(-6, 6)],\n",
    "        \"l1_ratio\": (0.01, 0.25, 0.5, 0.75, 1),\n",
    "    }\n",
    ")\n",
    "en_gs.fit(X_tr, y_tr) #problème vient du fit\n",
    "en_df = pd.DataFrame(en_gs.cv_results_)\n",
    "en_df.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 2, 'l1_ratio': 1}, 0.922197217213192)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_gs.best_params_, en_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr = KNeighborsRegressor()\n",
    "knr_gs = GridSearchCV(\n",
    "    knr,\n",
    "    {\n",
    "        \"n_neighbors\": range(5, 15),\n",
    "        \"weights\": (\"uniform\", \"distance\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform'}</td>\n",
       "      <td>0.394768</td>\n",
       "      <td>0.251342</td>\n",
       "      <td>0.025068</td>\n",
       "      <td>0.161833</td>\n",
       "      <td>0.123955</td>\n",
       "      <td>0.191393</td>\n",
       "      <td>0.124933</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.444726</td>\n",
       "      <td>0.333097</td>\n",
       "      <td>0.031749</td>\n",
       "      <td>0.222572</td>\n",
       "      <td>0.137956</td>\n",
       "      <td>0.234020</td>\n",
       "      <td>0.144559</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'uniform'}</td>\n",
       "      <td>0.355400</td>\n",
       "      <td>0.249664</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.191035</td>\n",
       "      <td>0.129295</td>\n",
       "      <td>0.201680</td>\n",
       "      <td>0.095256</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'distance'}</td>\n",
       "      <td>0.425699</td>\n",
       "      <td>0.329144</td>\n",
       "      <td>0.083163</td>\n",
       "      <td>0.249399</td>\n",
       "      <td>0.153053</td>\n",
       "      <td>0.248091</td>\n",
       "      <td>0.121942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'uniform'}</td>\n",
       "      <td>0.312301</td>\n",
       "      <td>0.217796</td>\n",
       "      <td>0.060646</td>\n",
       "      <td>0.148042</td>\n",
       "      <td>0.142852</td>\n",
       "      <td>0.176328</td>\n",
       "      <td>0.084275</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.000447      0.000550         0.011718        0.005628   \n",
       "1       0.000399      0.000489         0.009768        0.001151   \n",
       "2       0.000595      0.000486         0.007971        0.000880   \n",
       "3       0.000809      0.000406         0.008561        0.001508   \n",
       "4       0.000399      0.000489         0.006383        0.001016   \n",
       "\n",
       "  param_n_neighbors param_weights                                     params  \\\n",
       "0                 5       uniform   {'n_neighbors': 5, 'weights': 'uniform'}   \n",
       "1                 5      distance  {'n_neighbors': 5, 'weights': 'distance'}   \n",
       "2                 6       uniform   {'n_neighbors': 6, 'weights': 'uniform'}   \n",
       "3                 6      distance  {'n_neighbors': 6, 'weights': 'distance'}   \n",
       "4                 7       uniform   {'n_neighbors': 7, 'weights': 'uniform'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.394768           0.251342           0.025068           0.161833   \n",
       "1           0.444726           0.333097           0.031749           0.222572   \n",
       "2           0.355400           0.249664           0.083008           0.191035   \n",
       "3           0.425699           0.329144           0.083163           0.249399   \n",
       "4           0.312301           0.217796           0.060646           0.148042   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.123955         0.191393        0.124933               12  \n",
       "1           0.137956         0.234020        0.144559                9  \n",
       "2           0.129295         0.201680        0.095256               11  \n",
       "3           0.153053         0.248091        0.121942                1  \n",
       "4           0.142852         0.176328        0.084275               13  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knr_gs.fit(X_tr, y_tr)\n",
    "knr_df = pd.DataFrame(knr_gs.cv_results_)\n",
    "knr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_neighbors': 6, 'weights': 'distance'}, 0.24809144009222037)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knr_gs.best_params_, knr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr_gs = GridSearchCV(\n",
    "    rfr,\n",
    "    {   \n",
    "        \"n_estimators\": (8 , 16, 32, 64, 128, 256),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027923</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_estimators': 8}</td>\n",
       "      <td>0.910364</td>\n",
       "      <td>0.846120</td>\n",
       "      <td>0.871130</td>\n",
       "      <td>0.826891</td>\n",
       "      <td>0.856757</td>\n",
       "      <td>0.862252</td>\n",
       "      <td>0.028051</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053058</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_estimators': 16}</td>\n",
       "      <td>0.914589</td>\n",
       "      <td>0.864101</td>\n",
       "      <td>0.867215</td>\n",
       "      <td>0.854030</td>\n",
       "      <td>0.868530</td>\n",
       "      <td>0.873693</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.119287</td>\n",
       "      <td>0.011323</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>32</td>\n",
       "      <td>{'n_estimators': 32}</td>\n",
       "      <td>0.928112</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>0.870193</td>\n",
       "      <td>0.858463</td>\n",
       "      <td>0.887544</td>\n",
       "      <td>0.884162</td>\n",
       "      <td>0.023905</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.200071</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>64</td>\n",
       "      <td>{'n_estimators': 64}</td>\n",
       "      <td>0.927947</td>\n",
       "      <td>0.881107</td>\n",
       "      <td>0.880629</td>\n",
       "      <td>0.859547</td>\n",
       "      <td>0.874914</td>\n",
       "      <td>0.884829</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.362430</td>\n",
       "      <td>0.010195</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>128</td>\n",
       "      <td>{'n_estimators': 128}</td>\n",
       "      <td>0.924498</td>\n",
       "      <td>0.883875</td>\n",
       "      <td>0.872230</td>\n",
       "      <td>0.866710</td>\n",
       "      <td>0.887871</td>\n",
       "      <td>0.887037</td>\n",
       "      <td>0.020231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.027923      0.000891         0.001197        0.000399   \n",
       "1       0.053058      0.002926         0.001796        0.000400   \n",
       "2       0.119287      0.011323         0.003591        0.000798   \n",
       "3       0.200071      0.018566         0.004781        0.000396   \n",
       "4       0.362430      0.010195         0.008578        0.001196   \n",
       "\n",
       "  param_n_estimators                 params  split0_test_score  \\\n",
       "0                  8    {'n_estimators': 8}           0.910364   \n",
       "1                 16   {'n_estimators': 16}           0.914589   \n",
       "2                 32   {'n_estimators': 32}           0.928112   \n",
       "3                 64   {'n_estimators': 64}           0.927947   \n",
       "4                128  {'n_estimators': 128}           0.924498   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.846120           0.871130           0.826891           0.856757   \n",
       "1           0.864101           0.867215           0.854030           0.868530   \n",
       "2           0.876500           0.870193           0.858463           0.887544   \n",
       "3           0.881107           0.880629           0.859547           0.874914   \n",
       "4           0.883875           0.872230           0.866710           0.887871   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.862252        0.028051                6  \n",
       "1         0.873693        0.021070                5  \n",
       "2         0.884162        0.023905                4  \n",
       "3         0.884829        0.022927                3  \n",
       "4         0.887037        0.020231                2  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_gs.fit(X_tr, y_tr)\n",
    "rfr_df = pd.DataFrame(rfr_gs.cv_results_)\n",
    "rfr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 256}, 0.8876187424461225)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_gs.best_params_, rfr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_epsilon</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.1}</td>\n",
       "      <td>-0.052352</td>\n",
       "      <td>-0.041738</td>\n",
       "      <td>-0.022034</td>\n",
       "      <td>-0.036633</td>\n",
       "      <td>-0.149735</td>\n",
       "      <td>-0.060498</td>\n",
       "      <td>0.045674</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008577</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 1.0}</td>\n",
       "      <td>-0.052352</td>\n",
       "      <td>-0.041717</td>\n",
       "      <td>-0.022034</td>\n",
       "      <td>-0.036631</td>\n",
       "      <td>-0.149735</td>\n",
       "      <td>-0.060494</td>\n",
       "      <td>0.045676</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008984</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 10}</td>\n",
       "      <td>-0.052352</td>\n",
       "      <td>-0.041246</td>\n",
       "      <td>-0.022034</td>\n",
       "      <td>-0.036142</td>\n",
       "      <td>-0.149735</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>0.045766</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009360</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1.0, 'epsilon': 0.1}</td>\n",
       "      <td>-0.050967</td>\n",
       "      <td>-0.040301</td>\n",
       "      <td>-0.021590</td>\n",
       "      <td>-0.035221</td>\n",
       "      <td>-0.146704</td>\n",
       "      <td>-0.058957</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008783</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'epsilon': 1.0}</td>\n",
       "      <td>-0.050967</td>\n",
       "      <td>-0.040310</td>\n",
       "      <td>-0.021590</td>\n",
       "      <td>-0.035221</td>\n",
       "      <td>-0.146704</td>\n",
       "      <td>-0.058958</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.009574      0.001196         0.004787        0.000400     0.1   \n",
       "1       0.008577      0.000489         0.004588        0.000488     0.1   \n",
       "2       0.008984      0.000631         0.004387        0.000491     0.1   \n",
       "3       0.009360      0.000790         0.004602        0.000500     1.0   \n",
       "4       0.008783      0.000403         0.004781        0.000396     1.0   \n",
       "\n",
       "  param_epsilon                      params  split0_test_score  \\\n",
       "0           0.1  {'C': 0.1, 'epsilon': 0.1}          -0.052352   \n",
       "1           1.0  {'C': 0.1, 'epsilon': 1.0}          -0.052352   \n",
       "2            10   {'C': 0.1, 'epsilon': 10}          -0.052352   \n",
       "3           0.1  {'C': 1.0, 'epsilon': 0.1}          -0.050967   \n",
       "4           1.0  {'C': 1.0, 'epsilon': 1.0}          -0.050967   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -0.041738          -0.022034          -0.036633          -0.149735   \n",
       "1          -0.041717          -0.022034          -0.036631          -0.149735   \n",
       "2          -0.041246          -0.022034          -0.036142          -0.149735   \n",
       "3          -0.040301          -0.021590          -0.035221          -0.146704   \n",
       "4          -0.040310          -0.021590          -0.035221          -0.146704   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -0.060498        0.045674                9  \n",
       "1        -0.060494        0.045676                8  \n",
       "2        -0.060302        0.045766                7  \n",
       "3        -0.058957        0.044880                5  \n",
       "4        -0.058958        0.044880                6  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr_gs = GridSearchCV(\n",
    "    svr,\n",
    "    {\n",
    "        \"C\": (0.1, 1.0, 10),\n",
    "        \"epsilon\": (0.1, 1.0, 10),\n",
    "    }\n",
    ")\n",
    "svr_gs.fit(X_tr, y_tr)\n",
    "\n",
    "svr_df = pd.DataFrame(svr_gs.cv_results_)\n",
    "svr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 10, 'epsilon': 0.1}, -0.04565444631037137)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_gs.best_params_, svr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(\n",
    "    [\n",
    "        (\"mise_echelle\", MinMaxScaler()),\n",
    "        (\"support_vecteurs\", SVR()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_gs = GridSearchCV(\n",
    "    pl,\n",
    "    {\n",
    "        \"support_vecteurs__C\": (0.1, 1.0, 10),\n",
    "        \"support_vecteurs__epsilon\": (0.1, 1.0, 10),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_support_vecteurs__C</th>\n",
       "      <th>param_support_vecteurs__epsilon</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'support_vecteurs__C': 0.1, 'support_vecteurs...</td>\n",
       "      <td>-0.052153</td>\n",
       "      <td>-0.041614</td>\n",
       "      <td>-0.021666</td>\n",
       "      <td>-0.036429</td>\n",
       "      <td>-0.149600</td>\n",
       "      <td>-0.060292</td>\n",
       "      <td>0.045722</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'support_vecteurs__C': 0.1, 'support_vecteurs...</td>\n",
       "      <td>-0.052153</td>\n",
       "      <td>-0.041591</td>\n",
       "      <td>-0.021666</td>\n",
       "      <td>-0.036399</td>\n",
       "      <td>-0.149600</td>\n",
       "      <td>-0.060282</td>\n",
       "      <td>0.045727</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008949</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'support_vecteurs__C': 0.1, 'support_vecteurs...</td>\n",
       "      <td>-0.052153</td>\n",
       "      <td>-0.041143</td>\n",
       "      <td>-0.021666</td>\n",
       "      <td>-0.035908</td>\n",
       "      <td>-0.149600</td>\n",
       "      <td>-0.060094</td>\n",
       "      <td>0.045815</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009577</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'support_vecteurs__C': 1.0, 'support_vecteurs...</td>\n",
       "      <td>-0.048983</td>\n",
       "      <td>-0.039056</td>\n",
       "      <td>-0.017911</td>\n",
       "      <td>-0.033178</td>\n",
       "      <td>-0.145352</td>\n",
       "      <td>-0.056896</td>\n",
       "      <td>0.045360</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009182</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'support_vecteurs__C': 1.0, 'support_vecteurs...</td>\n",
       "      <td>-0.048983</td>\n",
       "      <td>-0.039064</td>\n",
       "      <td>-0.017911</td>\n",
       "      <td>-0.033178</td>\n",
       "      <td>-0.145352</td>\n",
       "      <td>-0.056898</td>\n",
       "      <td>0.045360</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.009781      0.000987         0.004787        0.000400   \n",
       "1       0.009756      0.000392         0.004605        0.000503   \n",
       "2       0.008949      0.000069         0.004187        0.000400   \n",
       "3       0.009577      0.000492         0.004578        0.000501   \n",
       "4       0.009182      0.000396         0.003983        0.000013   \n",
       "\n",
       "  param_support_vecteurs__C param_support_vecteurs__epsilon  \\\n",
       "0                       0.1                             0.1   \n",
       "1                       0.1                             1.0   \n",
       "2                       0.1                              10   \n",
       "3                       1.0                             0.1   \n",
       "4                       1.0                             1.0   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'support_vecteurs__C': 0.1, 'support_vecteurs...          -0.052153   \n",
       "1  {'support_vecteurs__C': 0.1, 'support_vecteurs...          -0.052153   \n",
       "2  {'support_vecteurs__C': 0.1, 'support_vecteurs...          -0.052153   \n",
       "3  {'support_vecteurs__C': 1.0, 'support_vecteurs...          -0.048983   \n",
       "4  {'support_vecteurs__C': 1.0, 'support_vecteurs...          -0.048983   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -0.041614          -0.021666          -0.036429          -0.149600   \n",
       "1          -0.041591          -0.021666          -0.036399          -0.149600   \n",
       "2          -0.041143          -0.021666          -0.035908          -0.149600   \n",
       "3          -0.039056          -0.017911          -0.033178          -0.145352   \n",
       "4          -0.039064          -0.017911          -0.033178          -0.145352   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -0.060292        0.045722                9  \n",
       "1        -0.060282        0.045727                8  \n",
       "2        -0.060094        0.045815                7  \n",
       "3        -0.056896        0.045360                5  \n",
       "4        -0.056898        0.045360                6  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_gs.fit(X_tr, y_tr)\n",
    "\n",
    "pl_df = pd.DataFrame(pl_gs.cv_results_)\n",
    "pl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'support_vecteurs__C': 10, 'support_vecteurs__epsilon': 10},\n",
       " -0.02352431249443543)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_gs.best_params_, pl_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln = Pipeline(\n",
    "    [\n",
    "        (\"mise_echelle\", MinMaxScaler()),\n",
    "        (\"neurones\", MLPRegressor()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln_gs = GridSearchCV(\n",
    "    pln,\n",
    "    {\n",
    "        \"neurones__alpha\": 10.0 ** -np.arange(1, 7),\n",
    "        'neurones__hidden_layer_sizes': ((25,), (50, ), (100,), (20, 20)),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_neurones__alpha</th>\n",
       "      <th>param_neurones__hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.273378</td>\n",
       "      <td>0.007361</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(25,)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-5.432010</td>\n",
       "      <td>-7.683767</td>\n",
       "      <td>-9.449958</td>\n",
       "      <td>-9.403328</td>\n",
       "      <td>-8.439998</td>\n",
       "      <td>-8.081812</td>\n",
       "      <td>1.478270</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.514626</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-5.390329</td>\n",
       "      <td>-7.620881</td>\n",
       "      <td>-9.390750</td>\n",
       "      <td>-9.321108</td>\n",
       "      <td>-8.408702</td>\n",
       "      <td>-8.026354</td>\n",
       "      <td>1.469502</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.605408</td>\n",
       "      <td>0.037933</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-5.316770</td>\n",
       "      <td>-7.472490</td>\n",
       "      <td>-9.274609</td>\n",
       "      <td>-9.198453</td>\n",
       "      <td>-8.287049</td>\n",
       "      <td>-7.909874</td>\n",
       "      <td>1.454695</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.195483</td>\n",
       "      <td>0.014089</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-4.940322</td>\n",
       "      <td>-6.911076</td>\n",
       "      <td>-8.914810</td>\n",
       "      <td>-8.392282</td>\n",
       "      <td>-7.580262</td>\n",
       "      <td>-7.347750</td>\n",
       "      <td>1.384715</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.278756</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(25,)</td>\n",
       "      <td>{'neurones__alpha': 0.01, 'neurones__hidden_la...</td>\n",
       "      <td>-5.446838</td>\n",
       "      <td>-7.674505</td>\n",
       "      <td>-9.460567</td>\n",
       "      <td>-9.398430</td>\n",
       "      <td>-8.457199</td>\n",
       "      <td>-8.087508</td>\n",
       "      <td>1.475411</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.273378      0.007361         0.001017        0.000017   \n",
       "1       0.514626      0.005831         0.000798        0.000399   \n",
       "2       0.605408      0.037933         0.000604        0.000493   \n",
       "3       0.195483      0.014089         0.000997        0.000002   \n",
       "4       0.278756      0.016807         0.000811        0.000406   \n",
       "\n",
       "  param_neurones__alpha param_neurones__hidden_layer_sizes  \\\n",
       "0                   0.1                              (25,)   \n",
       "1                   0.1                              (50,)   \n",
       "2                   0.1                             (100,)   \n",
       "3                   0.1                           (20, 20)   \n",
       "4                  0.01                              (25,)   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -5.432010   \n",
       "1  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -5.390329   \n",
       "2  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -5.316770   \n",
       "3  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -4.940322   \n",
       "4  {'neurones__alpha': 0.01, 'neurones__hidden_la...          -5.446838   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -7.683767          -9.449958          -9.403328          -8.439998   \n",
       "1          -7.620881          -9.390750          -9.321108          -8.408702   \n",
       "2          -7.472490          -9.274609          -9.198453          -8.287049   \n",
       "3          -6.911076          -8.914810          -8.392282          -7.580262   \n",
       "4          -7.674505          -9.460567          -9.398430          -8.457199   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -8.081812        1.478270               20  \n",
       "1        -8.026354        1.469502               17  \n",
       "2        -7.909874        1.454695               10  \n",
       "3        -7.347750        1.384715                3  \n",
       "4        -8.087508        1.475411               24  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln_gs.fit(X_tr, y_tr)\n",
    "\n",
    "pln_df = pd.DataFrame(pln_gs.cv_results_)\n",
    "pln_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.154981346536397"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln_gs.best_params_\n",
    "\n",
    "pln_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neurones__alpha': 0.0001, 'neurones__hidden_layer_sizes': (20, 20)}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai = en_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "prix_prédits = essai.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "prix_reels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([22990, 42790, 23990, 17290, 17490, 26980, 37390, 17990, 18490,\n",
       "        13790, 12280, 29790, 33790, 11480, 27290, 14990, 10990, 13990,\n",
       "        31990, 23990, 10990, 23990, 19990, 11990, 24990, 23490, 34990,\n",
       "        22990,  9790, 13990, 15990, 13790, 26790, 19390, 26790, 13990,\n",
       "        24990, 26990, 27990, 22890, 14990, 21990, 26990, 15790, 15790,\n",
       "        15790, 14990, 27790, 10990, 26990, 15490, 27990,  7490, 21990,\n",
       "         9990, 18990, 11990, 18890, 19990, 19890, 13990, 22990, 13990,\n",
       "        27990, 25990, 15980, 27490, 45990, 27490, 22990, 24990, 16990,\n",
       "        15990, 20990, 26990, 26990, 43990, 14490, 24990, 19990, 18990,\n",
       "        16490, 17990, 20990, 23990, 19490, 31990, 20490, 18990, 19790,\n",
       "        18990,  9790, 33990, 17490, 16990, 36990, 13990, 27490, 13990,\n",
       "        32990, 34990, 26890, 11990, 39000, 27900, 11500, 26900, 30900,\n",
       "        31900, 29500, 49000, 18900, 18800, 17900, 22400, 25900, 16500,\n",
       "        30500, 28500, 27900, 22500, 36500, 44990, 23900, 18900, 40900,\n",
       "        26900, 21000, 29500, 14900, 29500, 30900, 21000, 19500, 19300,\n",
       "        21100, 15500, 19800, 19900, 32900, 27900, 17500, 28500, 27490,\n",
       "        13500, 19500, 17900, 13490, 10990, 12490, 18990, 24990, 15990,\n",
       "        10990, 13490, 12490, 15990, 16490, 23990, 32990, 14990, 23990,\n",
       "        24990, 14490, 17490, 27990, 12990, 17490, 12990, 17490, 23990,\n",
       "        22990, 41990, 24990, 39790, 22900, 18490, 23490, 16490, 17990,\n",
       "        29490, 26490, 16490, 24490, 27990, 25490, 24990, 24990, 24990,\n",
       "        18990, 16990,  9990, 18490, 22990, 18990, 24990, 15990, 19990,\n",
       "        16990, 18990, 22990, 13850, 29490, 24990, 13490, 17990, 35990,\n",
       "        27990, 11990, 34900, 26990, 25990, 18990, 19990, 15990, 18990,\n",
       "        11990, 27990, 26990, 16490, 14200, 14500, 28990, 18990, 27900,\n",
       "        28900, 31500, 15499, 24990, 15990, 23490, 26499, 22490, 24995,\n",
       "        25999, 29100, 16500, 26890, 18995, 15990, 18990, 18300, 28900,\n",
       "        26990, 24990, 16990, 15990, 13500, 15980, 17990, 14900, 11500,\n",
       "        14900, 18990, 24300, 18340, 20150, 31350, 23990, 14990,  9600,\n",
       "        14900, 20990, 28900, 28900, 28900, 28900, 27900, 24300, 14500,\n",
       "        29900, 23195, 13450, 39990, 29250, 16150, 14050, 29250, 18250,\n",
       "        28850, 21350, 19950, 27250, 26850, 21250, 22450, 29650, 28250,\n",
       "        25990, 37188, 13790, 15990, 18790, 18990, 25490, 17990, 31990,\n",
       "        10790, 11990,  8990, 36290, 20999, 13899, 12299, 17999, 20999,\n",
       "        18499, 18490, 13899, 14499, 14199, 13999, 25499, 14499, 14499,\n",
       "        13999, 14499, 24999, 14499, 28799, 29499, 38999, 13285, 13200,\n",
       "        19485, 22295, 18490, 13995, 11325, 34985, 11485, 16990, 12490,\n",
       "         9890, 25490, 12490,  8490, 37980, 14980, 11780, 39990, 14780,\n",
       "        49990, 17980, 31390, 25250, 14980, 14950, 23950, 13980, 15980,\n",
       "        20950, 47490, 28480, 26490, 23880, 30990, 39590, 24780, 36990,\n",
       "        23900, 24950, 28450, 38250, 33213, 25890, 28600, 16950, 28450,\n",
       "        13850, 15880, 25480,  9950, 24480, 14280, 17480, 17950, 12480,\n",
       "        18280, 22780, 21250, 19480, 31780, 17280, 23980, 14350, 17440,\n",
       "        16780, 16280, 19480, 23480, 23250, 27242, 25480, 17480, 21980,\n",
       "        15450, 18834, 18280, 15250, 19780, 15750, 20250, 37480, 27980,\n",
       "        27450, 16200, 16250, 16200, 16250, 20250, 35780, 15980, 20150,\n",
       "        15700, 20150, 16600, 44980, 16980, 17280, 20980, 15280, 15480,\n",
       "        37980, 33890, 49990, 26780, 17980, 40980, 15280, 34490, 29990,\n",
       "        31490, 29990, 20388, 28990, 13990, 20990, 12490, 19490, 16990,\n",
       "        26990, 26990, 31990, 12490, 18799, 28990, 13890, 11490, 22490,\n",
       "        15990, 12490, 13490, 12990, 11890, 11990, 19990, 36490, 21990,\n",
       "        31990, 27390, 27990, 27390, 31990, 27990, 15990, 11990, 13490,\n",
       "        26490, 14490, 19990, 15990, 15990, 11990, 15990, 19990, 27990,\n",
       "        17990, 15990, 19990, 15990, 29990,  9990, 20990, 20990, 14490,\n",
       "        14900, 20990, 45900, 15490, 18490, 21490, 18490, 18490, 15990,\n",
       "        11290, 16990, 11490, 18990, 11490, 10890, 14990, 18490, 13990,\n",
       "        21990, 14990, 15990, 15490, 38490, 33990, 20490, 45990, 12990,\n",
       "        13990, 38990, 12990, 24990, 26490, 19990, 18990, 23990, 12490,\n",
       "        15490, 48990, 27990, 15490, 11990, 37290, 28990, 17490, 29490,\n",
       "        19900,  8990, 14700, 13900, 17290, 28900, 22900, 25900, 21490,\n",
       "        28900, 31900, 20490, 17900, 28900, 13900, 21900, 20900, 13490,\n",
       "        29900, 15900, 14900, 21790, 18900, 15490, 27489, 15489, 19889,\n",
       "        13989, 16989, 15489, 32960, 29000, 13490, 23950, 11378, 16989,\n",
       "        17389, 35489, 19990, 25989, 34689, 15889, 11989, 16989, 11999,\n",
       "        13889, 18989, 15889, 36849, 13999, 11999, 32989, 32989, 21589,\n",
       "        22979, 32489, 11399, 36790, 12879, 13799, 15799, 21489, 16989,\n",
       "        19989, 17579, 22689, 22689, 22689, 22689], dtype=int64),\n",
       " array([22247.82400014, 42389.00157165, 24137.29676851, 16054.71038285,\n",
       "        16203.88541643, 27347.74352942, 34036.34595786, 19667.2942481 ,\n",
       "        18285.93623114, 16436.44309243, 11748.05205629, 28209.90628191,\n",
       "        33679.22328338, 12953.52596866, 27307.33659483, 15467.69390459,\n",
       "        10202.89143117, 16317.07925927, 34680.62399175, 24780.75648061,\n",
       "         9003.31693875, 25115.35741777, 20998.20166186, 17080.12491887,\n",
       "        28045.40909712, 24450.86497246, 38046.50910666, 24090.93183509,\n",
       "        11329.25565251, 11328.85308894, 16797.18478644, 12473.25809404,\n",
       "        26762.0328209 , 19437.4136555 , 27475.39877615, 14128.64839788,\n",
       "        26909.2462293 , 30449.30218577, 30868.06472798, 22546.23147778,\n",
       "        16379.06576377, 21753.76353597, 27537.23271965, 17039.52425778,\n",
       "        16609.4699212 , 16621.260065  , 16210.65242241, 28934.01997618,\n",
       "        10644.20896283, 28894.73831518, 16450.87938158, 27061.65461832,\n",
       "         6324.33250487, 23438.94770092, 10991.80648581, 20719.96829615,\n",
       "        11786.503883  , 20440.72154259, 20421.76706014, 23260.70887226,\n",
       "        14623.02380657, 23733.03302801, 13832.60948035, 30531.58673201,\n",
       "        27072.2468165 , 16880.00000589, 24890.34892009, 47324.46181761,\n",
       "        28310.33374348, 23239.77336841, 26359.64271783, 16007.44075537,\n",
       "        14765.28034693, 21468.72555579, 26975.36002499, 25641.12242793,\n",
       "        42316.62832871, 13813.68084315, 24563.74408749, 17719.10287705,\n",
       "        15459.22048033, 15268.27116243, 18310.49682958, 21093.08687992,\n",
       "        23593.08198544, 15660.21201438, 28618.55095967, 17991.22745289,\n",
       "        14054.67803443, 17406.59474089, 14953.3685396 ,  5326.34829632,\n",
       "        31211.25344692, 16089.60033239, 14297.93417663, 32896.75152288,\n",
       "        12248.27074171, 25149.0270186 , 13566.56789301, 30404.37785965,\n",
       "        32213.55152492, 26128.045671  , 12982.35006858, 33244.95068227,\n",
       "        31089.20263087,  8162.26799552, 25821.07174774, 27998.91360811,\n",
       "        30125.61511902, 27304.19110365, 47118.53741567, 17658.39733488,\n",
       "        17158.30883049, 18199.87870654, 19572.09506412, 25597.59210609,\n",
       "        19223.56803537, 29800.2355329 , 29947.62957872, 26091.36908733,\n",
       "        23135.97957756, 33684.08311827, 42099.92543084, 27052.24538002,\n",
       "        17658.39733488, 40519.40064125, 26765.98112892, 19771.30709341,\n",
       "        29094.28650405, 13923.68137745, 29753.0344576 , 31815.04764809,\n",
       "        18719.66052647, 17595.66112095, 16307.53020443, 23135.97957756,\n",
       "        14544.78432491, 20097.94501657, 16356.94996884, 29548.19197496,\n",
       "        25751.95679106, 14605.56256146, 27281.70551164, 26593.02506359,\n",
       "        12298.50367701, 15879.10131436, 18144.31888228, 16048.94470294,\n",
       "        10840.84823722, 12740.71776038, 20091.60141939, 26539.87158063,\n",
       "        18693.07900288,  5286.6381604 , 13386.69547438, 13006.03430329,\n",
       "        15527.16234106, 17790.2379395 , 24974.25307228, 34228.78083125,\n",
       "        16136.3331374 , 22606.95077039, 24893.80298493, 15906.28512701,\n",
       "        20872.17256868, 26968.65375827, 12889.02192395, 19540.99226371,\n",
       "        12889.02192395, 19540.99226371, 24276.13349001, 22716.22672646,\n",
       "        42051.49320184, 24751.4200133 , 41709.65049132, 21715.80988977,\n",
       "        19764.30321083, 24278.30586327, 14221.01073825, 15728.57417277,\n",
       "        27677.62893334, 27847.81880871, 17217.31244943, 21095.9965806 ,\n",
       "        29574.44021515, 27513.0786239 , 24093.80774864, 24384.77316955,\n",
       "        24144.07470902, 17475.94961783, 19141.00153944, 10718.48808623,\n",
       "        17773.12752836, 22425.52329369, 19580.24123305, 23102.34441753,\n",
       "        14044.27803991, 21447.45353919, 16742.77220985, 17969.09720531,\n",
       "        22646.55333388, 16060.24244856, 27815.88594156, 23008.30566582,\n",
       "        13586.06685351, 17703.34752765, 34072.28118656, 26978.46768426,\n",
       "        12538.14147605, 32507.41230033, 26630.00570629, 24937.15214221,\n",
       "        18606.11554817, 21535.0949078 , 18935.41072219, 19710.79451311,\n",
       "        12890.00098164, 27730.43077979, 29141.47348303, 17540.70528837,\n",
       "        14580.80699533, 16982.65580067, 30533.88541292, 19972.19173739,\n",
       "        27126.71299115, 27224.3523257 , 30644.21518083, 15527.952558  ,\n",
       "        26848.57007151, 15260.44291127, 23537.5811406 , 26894.03709437,\n",
       "        23091.20064114, 25670.90658708, 27211.92887298, 29130.26268833,\n",
       "        17640.54475042, 27229.71793794, 19613.19244878, 15315.58124842,\n",
       "        21133.14027738, 19494.58501419, 28500.42582445, 28339.3859419 ,\n",
       "        26516.61045399, 16091.41674356, 14404.43945739, 13117.92189863,\n",
       "        15951.49248456, 17774.78355594, 17437.83867493,  9553.50159711,\n",
       "        17420.47115772, 16739.32672337, 24568.37131925, 18876.2715776 ,\n",
       "        20053.52889291, 33528.59365594, 23943.69537303, 11915.58529059,\n",
       "        12198.21042646, 16899.00197602, 21122.42974299, 27056.74872468,\n",
       "        27119.65302481, 27563.24083429, 27200.91323743, 27684.88405441,\n",
       "        24591.87088311, 15684.50050723, 27556.24776487, 19847.28751105,\n",
       "        12831.0609925 , 38249.8220111 , 27247.4405037 , 13276.20151833,\n",
       "        12413.61339805, 26393.18457603, 16689.03215752, 29501.13519041,\n",
       "        19131.23831611, 22208.64224067, 27874.79506029, 25031.94081979,\n",
       "        21914.301477  , 25649.4288732 , 26405.1334252 , 27063.78947201,\n",
       "        25440.55121771, 37713.7461169 , 13923.40561372, 14231.55923107,\n",
       "        17249.52205991, 18881.33448221, 23635.97665628, 17896.94964255,\n",
       "        29913.05722076, 10750.51701134, 12168.56178335,  6966.62916692,\n",
       "        40672.8886151 , 22289.42849862, 14744.8702274 ,  9720.16154577,\n",
       "        19651.2164504 , 20784.81096423, 18103.43026241, 17789.09956314,\n",
       "        14573.90205039, 15617.55266723, 15022.82110238, 14709.49979601,\n",
       "        27357.72340803, 15386.26816979, 15385.98577113, 14622.52101065,\n",
       "        15293.57081169, 25021.77439928, 15256.43538871, 28351.2059287 ,\n",
       "        28658.49694632, 34241.56250792, 14068.48756063, 15689.0203781 ,\n",
       "        21869.89540162, 22740.88812071, 19862.6938763 , 11995.99498667,\n",
       "         9628.12370145, 33500.86989616, 13580.22070468, 19367.53007202,\n",
       "        10832.42442741,  8760.32978166, 27235.30957399, 18189.23865092,\n",
       "         9715.48848334, 34837.91508388, 16361.0152229 , 11557.96310254,\n",
       "        40856.19750297, 15081.59548607, 47580.02562275, 18150.06844407,\n",
       "        29322.08711012, 26751.38817231, 16129.97163882, 15967.80421189,\n",
       "        25170.03506642, 15109.45077365, 16126.20222084, 24765.15440954,\n",
       "        42718.43428723, 27755.81538327, 27326.56363039, 20643.40722457,\n",
       "        42697.7675858 , 34371.09205773, 24812.67279838, 34274.95782272,\n",
       "        26362.88681567, 27847.88166932, 28638.14560254, 31495.58234488,\n",
       "        34359.91963547, 29495.79931963, 34272.32818129, 16760.07065318,\n",
       "        28647.28138336, 14011.01977128, 15324.88071199, 28445.24721754,\n",
       "         7593.14577046, 23222.52686164, 10934.62230849, 17481.24695493,\n",
       "        17747.59052922, 12544.91412781, 17332.47713727, 23205.27044422,\n",
       "        23980.07660442, 18356.25497068, 32606.57345567, 15337.7394849 ,\n",
       "        21720.06465514, 18404.03625015, 18410.95415131, 17739.2006743 ,\n",
       "        17124.2489099 , 19478.76146655, 24403.13228988, 25460.42023262,\n",
       "        26101.74723786, 27050.9914994 , 17502.48000277, 21994.06261818,\n",
       "        16864.37271134, 19269.62983361, 19947.99041558, 17014.25579683,\n",
       "        22548.71572006, 17697.20535693, 22074.96019181, 35644.41689049,\n",
       "        31321.30475393, 28195.17962979, 18013.78437188, 17604.21767278,\n",
       "        17757.07387153, 17735.8860451 , 21905.30920055, 39976.08337669,\n",
       "        18063.48653494, 21785.2897727 , 17160.3655161 , 20501.89007501,\n",
       "        17025.48114332, 46656.52367491, 21356.78468824, 18900.01604098,\n",
       "        22349.9490162 , 16564.52396247, 17049.88382257, 35786.54829349,\n",
       "        30000.7091266 , 48022.49081415, 25637.20672554, 19920.84938946,\n",
       "        35009.65450451, 16798.19786537, 35505.00885753, 28992.32308399,\n",
       "        30131.90710956, 30730.9764764 , 19699.3037017 , 29334.9036893 ,\n",
       "        12643.79999238, 22951.19412655, 13860.1927198 , 19045.99682446,\n",
       "        17406.1827131 , 23405.30733205, 20538.2750671 , 34187.4535837 ,\n",
       "        13644.82154205, 20126.07705431, 29837.04922868, 13205.15930809,\n",
       "        10493.51474211, 22002.0119118 , 17006.8452815 , 13206.92679859,\n",
       "        14542.3164413 , 13564.76093508,  9429.17660447,  9895.58868635,\n",
       "        19619.23672207, 33203.91636266, 20579.10638657, 29741.97819183,\n",
       "        25020.82712267, 27532.1340653 , 25020.82712267, 29733.51320874,\n",
       "        27581.01791284, 15002.30559919, 14150.26006732, 10921.12213468,\n",
       "        27399.88990881, 15950.22062625, 19959.22196821, 15397.77672205,\n",
       "        15502.97022058,  9835.40431332, 16331.5496112 , 23064.20614792,\n",
       "        29225.362009  , 18278.76829424, 15638.45097473, 20277.07426197,\n",
       "        15330.38562751, 30557.23639547,  9021.79034368, 21261.72776802,\n",
       "        21959.38781991, 15959.7374112 , 14381.24406968, 21401.81078166,\n",
       "        46280.46098909, 16212.1200452 , 19743.45104474, 23942.25527944,\n",
       "        19872.9308275 , 16835.80390581, 16857.98110943,  9634.33647183,\n",
       "        14814.46026888, 13449.96432562, 19142.29110945, 12648.94054419,\n",
       "        13194.72997069, 18387.86166948, 20914.04799724, 13769.2001454 ,\n",
       "        19805.8914292 , 14235.17360937, 16638.43009637, 15209.73136355,\n",
       "        34842.37022392, 34476.20606897, 20996.48286832, 42173.51194262,\n",
       "        11859.06522992, 15862.80189739, 35577.70487287, 12766.6849245 ,\n",
       "        26745.22835932, 28988.33348088, 23998.67425469, 18997.17165437,\n",
       "        23464.80646126, 13805.59654978, 15556.08416216, 38265.37364323,\n",
       "        27912.41459802, 16475.50975371, 14580.51677332, 34142.86117983,\n",
       "        28363.04032353, 16944.41736875, 28538.49702152, 20609.99841365,\n",
       "         8604.1936286 , 13878.11196298, 14987.93935625, 16494.45949386,\n",
       "        26725.1829717 , 21951.74419457, 28779.78457541, 21563.86462917,\n",
       "        27360.12267837, 29176.57245958, 20882.54283478, 17289.50403907,\n",
       "        27251.08604266, 14507.13427065, 23767.20461256, 21592.44806708,\n",
       "        14330.17901835, 28822.66969063, 14484.7621765 , 15072.96381575,\n",
       "        22258.97179657, 19962.30749684, 15701.13960825, 28161.06661267,\n",
       "        16520.07565877, 19554.92798436, 15802.41133458, 17355.54890201,\n",
       "        15539.18691655, 34343.01589828, 29754.54976265, 14045.90152368,\n",
       "        24635.62324426, 13157.46743151, 16853.54800151, 16886.80044299,\n",
       "        33648.93602776, 18409.15967453, 25241.35936112, 33496.88695296,\n",
       "        18005.51899857,  9202.48184385, 17496.62376579, 11918.83378199,\n",
       "        15875.30177131, 20566.90945209, 18005.51899857, 38464.90353552,\n",
       "        14931.02149856, 13875.31331166, 34359.91963547, 34359.91963547,\n",
       "        21657.35477176, 22713.16073231, 37369.68540447, 13134.37243951,\n",
       "        32860.67787964, 13342.21561598, 17957.26690856, 18482.52702541,\n",
       "        22611.45169995, 16663.48578013, 21762.25068762, 17632.12507802,\n",
       "        22204.12572142, 22204.12572142, 22741.54841101, 22741.54841101]))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prix_reels,prix_prédits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prix_prédits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prix_reels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22247.82400014, 42389.00157165, 24137.29676851, 16054.71038285,\n",
       "       16203.88541643, 27347.74352942, 34036.34595786, 19667.2942481 ,\n",
       "       18285.93623114, 16436.44309243, 11748.05205629, 28209.90628191,\n",
       "       33679.22328338, 12953.52596866, 27307.33659483, 15467.69390459,\n",
       "       10202.89143117, 16317.07925927, 34680.62399175, 24780.75648061,\n",
       "        9003.31693875, 25115.35741777, 20998.20166186, 17080.12491887,\n",
       "       28045.40909712, 24450.86497246, 38046.50910666, 24090.93183509,\n",
       "       11329.25565251, 11328.85308894, 16797.18478644, 12473.25809404,\n",
       "       26762.0328209 , 19437.4136555 , 27475.39877615, 14128.64839788,\n",
       "       26909.2462293 , 30449.30218577, 30868.06472798, 22546.23147778,\n",
       "       16379.06576377, 21753.76353597, 27537.23271965, 17039.52425778,\n",
       "       16609.4699212 , 16621.260065  , 16210.65242241, 28934.01997618,\n",
       "       10644.20896283, 28894.73831518, 16450.87938158, 27061.65461832,\n",
       "        6324.33250487, 23438.94770092, 10991.80648581, 20719.96829615,\n",
       "       11786.503883  , 20440.72154259, 20421.76706014, 23260.70887226,\n",
       "       14623.02380657, 23733.03302801, 13832.60948035, 30531.58673201,\n",
       "       27072.2468165 , 16880.00000589, 24890.34892009, 47324.46181761,\n",
       "       28310.33374348, 23239.77336841, 26359.64271783, 16007.44075537,\n",
       "       14765.28034693, 21468.72555579, 26975.36002499, 25641.12242793,\n",
       "       42316.62832871, 13813.68084315, 24563.74408749, 17719.10287705,\n",
       "       15459.22048033, 15268.27116243, 18310.49682958, 21093.08687992,\n",
       "       23593.08198544, 15660.21201438, 28618.55095967, 17991.22745289,\n",
       "       14054.67803443, 17406.59474089, 14953.3685396 ,  5326.34829632,\n",
       "       31211.25344692, 16089.60033239, 14297.93417663, 32896.75152288,\n",
       "       12248.27074171, 25149.0270186 , 13566.56789301, 30404.37785965,\n",
       "       32213.55152492, 26128.045671  , 12982.35006858, 33244.95068227,\n",
       "       31089.20263087,  8162.26799552, 25821.07174774, 27998.91360811,\n",
       "       30125.61511902, 27304.19110365, 47118.53741567, 17658.39733488,\n",
       "       17158.30883049, 18199.87870654, 19572.09506412, 25597.59210609,\n",
       "       19223.56803537, 29800.2355329 , 29947.62957872, 26091.36908733,\n",
       "       23135.97957756, 33684.08311827, 42099.92543084, 27052.24538002,\n",
       "       17658.39733488, 40519.40064125, 26765.98112892, 19771.30709341,\n",
       "       29094.28650405, 13923.68137745, 29753.0344576 , 31815.04764809,\n",
       "       18719.66052647, 17595.66112095, 16307.53020443, 23135.97957756,\n",
       "       14544.78432491, 20097.94501657, 16356.94996884, 29548.19197496,\n",
       "       25751.95679106, 14605.56256146, 27281.70551164, 26593.02506359,\n",
       "       12298.50367701, 15879.10131436, 18144.31888228, 16048.94470294,\n",
       "       10840.84823722, 12740.71776038, 20091.60141939, 26539.87158063,\n",
       "       18693.07900288,  5286.6381604 , 13386.69547438, 13006.03430329,\n",
       "       15527.16234106, 17790.2379395 , 24974.25307228, 34228.78083125,\n",
       "       16136.3331374 , 22606.95077039, 24893.80298493, 15906.28512701,\n",
       "       20872.17256868, 26968.65375827, 12889.02192395, 19540.99226371,\n",
       "       12889.02192395, 19540.99226371, 24276.13349001, 22716.22672646,\n",
       "       42051.49320184, 24751.4200133 , 41709.65049132, 21715.80988977,\n",
       "       19764.30321083, 24278.30586327, 14221.01073825, 15728.57417277,\n",
       "       27677.62893334, 27847.81880871, 17217.31244943, 21095.9965806 ,\n",
       "       29574.44021515, 27513.0786239 , 24093.80774864, 24384.77316955,\n",
       "       24144.07470902, 17475.94961783, 19141.00153944, 10718.48808623,\n",
       "       17773.12752836, 22425.52329369, 19580.24123305, 23102.34441753,\n",
       "       14044.27803991, 21447.45353919, 16742.77220985, 17969.09720531,\n",
       "       22646.55333388, 16060.24244856, 27815.88594156, 23008.30566582,\n",
       "       13586.06685351, 17703.34752765, 34072.28118656, 26978.46768426,\n",
       "       12538.14147605, 32507.41230033, 26630.00570629, 24937.15214221,\n",
       "       18606.11554817, 21535.0949078 , 18935.41072219, 19710.79451311,\n",
       "       12890.00098164, 27730.43077979, 29141.47348303, 17540.70528837,\n",
       "       14580.80699533, 16982.65580067, 30533.88541292, 19972.19173739,\n",
       "       27126.71299115, 27224.3523257 , 30644.21518083, 15527.952558  ,\n",
       "       26848.57007151, 15260.44291127, 23537.5811406 , 26894.03709437,\n",
       "       23091.20064114, 25670.90658708, 27211.92887298, 29130.26268833,\n",
       "       17640.54475042, 27229.71793794, 19613.19244878, 15315.58124842,\n",
       "       21133.14027738, 19494.58501419, 28500.42582445, 28339.3859419 ,\n",
       "       26516.61045399, 16091.41674356, 14404.43945739, 13117.92189863,\n",
       "       15951.49248456, 17774.78355594, 17437.83867493,  9553.50159711,\n",
       "       17420.47115772, 16739.32672337, 24568.37131925, 18876.2715776 ,\n",
       "       20053.52889291, 33528.59365594, 23943.69537303, 11915.58529059,\n",
       "       12198.21042646, 16899.00197602, 21122.42974299, 27056.74872468,\n",
       "       27119.65302481, 27563.24083429, 27200.91323743, 27684.88405441,\n",
       "       24591.87088311, 15684.50050723, 27556.24776487, 19847.28751105,\n",
       "       12831.0609925 , 38249.8220111 , 27247.4405037 , 13276.20151833,\n",
       "       12413.61339805, 26393.18457603, 16689.03215752, 29501.13519041,\n",
       "       19131.23831611, 22208.64224067, 27874.79506029, 25031.94081979,\n",
       "       21914.301477  , 25649.4288732 , 26405.1334252 , 27063.78947201,\n",
       "       25440.55121771, 37713.7461169 , 13923.40561372, 14231.55923107,\n",
       "       17249.52205991, 18881.33448221, 23635.97665628, 17896.94964255,\n",
       "       29913.05722076, 10750.51701134, 12168.56178335,  6966.62916692,\n",
       "       40672.8886151 , 22289.42849862, 14744.8702274 ,  9720.16154577,\n",
       "       19651.2164504 , 20784.81096423, 18103.43026241, 17789.09956314,\n",
       "       14573.90205039, 15617.55266723, 15022.82110238, 14709.49979601,\n",
       "       27357.72340803, 15386.26816979, 15385.98577113, 14622.52101065,\n",
       "       15293.57081169, 25021.77439928, 15256.43538871, 28351.2059287 ,\n",
       "       28658.49694632, 34241.56250792, 14068.48756063, 15689.0203781 ,\n",
       "       21869.89540162, 22740.88812071, 19862.6938763 , 11995.99498667,\n",
       "        9628.12370145, 33500.86989616, 13580.22070468, 19367.53007202,\n",
       "       10832.42442741,  8760.32978166, 27235.30957399, 18189.23865092,\n",
       "        9715.48848334, 34837.91508388, 16361.0152229 , 11557.96310254,\n",
       "       40856.19750297, 15081.59548607, 47580.02562275, 18150.06844407,\n",
       "       29322.08711012, 26751.38817231, 16129.97163882, 15967.80421189,\n",
       "       25170.03506642, 15109.45077365, 16126.20222084, 24765.15440954,\n",
       "       42718.43428723, 27755.81538327, 27326.56363039, 20643.40722457,\n",
       "       42697.7675858 , 34371.09205773, 24812.67279838, 34274.95782272,\n",
       "       26362.88681567, 27847.88166932, 28638.14560254, 31495.58234488,\n",
       "       34359.91963547, 29495.79931963, 34272.32818129, 16760.07065318,\n",
       "       28647.28138336, 14011.01977128, 15324.88071199, 28445.24721754,\n",
       "        7593.14577046, 23222.52686164, 10934.62230849, 17481.24695493,\n",
       "       17747.59052922, 12544.91412781, 17332.47713727, 23205.27044422,\n",
       "       23980.07660442, 18356.25497068, 32606.57345567, 15337.7394849 ,\n",
       "       21720.06465514, 18404.03625015, 18410.95415131, 17739.2006743 ,\n",
       "       17124.2489099 , 19478.76146655, 24403.13228988, 25460.42023262,\n",
       "       26101.74723786, 27050.9914994 , 17502.48000277, 21994.06261818,\n",
       "       16864.37271134, 19269.62983361, 19947.99041558, 17014.25579683,\n",
       "       22548.71572006, 17697.20535693, 22074.96019181, 35644.41689049,\n",
       "       31321.30475393, 28195.17962979, 18013.78437188, 17604.21767278,\n",
       "       17757.07387153, 17735.8860451 , 21905.30920055, 39976.08337669,\n",
       "       18063.48653494, 21785.2897727 , 17160.3655161 , 20501.89007501,\n",
       "       17025.48114332, 46656.52367491, 21356.78468824, 18900.01604098,\n",
       "       22349.9490162 , 16564.52396247, 17049.88382257, 35786.54829349,\n",
       "       30000.7091266 , 48022.49081415, 25637.20672554, 19920.84938946,\n",
       "       35009.65450451, 16798.19786537, 35505.00885753, 28992.32308399,\n",
       "       30131.90710956, 30730.9764764 , 19699.3037017 , 29334.9036893 ,\n",
       "       12643.79999238, 22951.19412655, 13860.1927198 , 19045.99682446,\n",
       "       17406.1827131 , 23405.30733205, 20538.2750671 , 34187.4535837 ,\n",
       "       13644.82154205, 20126.07705431, 29837.04922868, 13205.15930809,\n",
       "       10493.51474211, 22002.0119118 , 17006.8452815 , 13206.92679859,\n",
       "       14542.3164413 , 13564.76093508,  9429.17660447,  9895.58868635,\n",
       "       19619.23672207, 33203.91636266, 20579.10638657, 29741.97819183,\n",
       "       25020.82712267, 27532.1340653 , 25020.82712267, 29733.51320874,\n",
       "       27581.01791284, 15002.30559919, 14150.26006732, 10921.12213468,\n",
       "       27399.88990881, 15950.22062625, 19959.22196821, 15397.77672205,\n",
       "       15502.97022058,  9835.40431332, 16331.5496112 , 23064.20614792,\n",
       "       29225.362009  , 18278.76829424, 15638.45097473, 20277.07426197,\n",
       "       15330.38562751, 30557.23639547,  9021.79034368, 21261.72776802,\n",
       "       21959.38781991, 15959.7374112 , 14381.24406968, 21401.81078166,\n",
       "       46280.46098909, 16212.1200452 , 19743.45104474, 23942.25527944,\n",
       "       19872.9308275 , 16835.80390581, 16857.98110943,  9634.33647183,\n",
       "       14814.46026888, 13449.96432562, 19142.29110945, 12648.94054419,\n",
       "       13194.72997069, 18387.86166948, 20914.04799724, 13769.2001454 ,\n",
       "       19805.8914292 , 14235.17360937, 16638.43009637, 15209.73136355,\n",
       "       34842.37022392, 34476.20606897, 20996.48286832, 42173.51194262,\n",
       "       11859.06522992, 15862.80189739, 35577.70487287, 12766.6849245 ,\n",
       "       26745.22835932, 28988.33348088, 23998.67425469, 18997.17165437,\n",
       "       23464.80646126, 13805.59654978, 15556.08416216, 38265.37364323,\n",
       "       27912.41459802, 16475.50975371, 14580.51677332, 34142.86117983,\n",
       "       28363.04032353, 16944.41736875, 28538.49702152, 20609.99841365,\n",
       "        8604.1936286 , 13878.11196298, 14987.93935625, 16494.45949386,\n",
       "       26725.1829717 , 21951.74419457, 28779.78457541, 21563.86462917,\n",
       "       27360.12267837, 29176.57245958, 20882.54283478, 17289.50403907,\n",
       "       27251.08604266, 14507.13427065, 23767.20461256, 21592.44806708,\n",
       "       14330.17901835, 28822.66969063, 14484.7621765 , 15072.96381575,\n",
       "       22258.97179657, 19962.30749684, 15701.13960825, 28161.06661267,\n",
       "       16520.07565877, 19554.92798436, 15802.41133458, 17355.54890201,\n",
       "       15539.18691655, 34343.01589828, 29754.54976265, 14045.90152368,\n",
       "       24635.62324426, 13157.46743151, 16853.54800151, 16886.80044299,\n",
       "       33648.93602776, 18409.15967453, 25241.35936112, 33496.88695296,\n",
       "       18005.51899857,  9202.48184385, 17496.62376579, 11918.83378199,\n",
       "       15875.30177131, 20566.90945209, 18005.51899857, 38464.90353552,\n",
       "       14931.02149856, 13875.31331166, 34359.91963547, 34359.91963547,\n",
       "       21657.35477176, 22713.16073231, 37369.68540447, 13134.37243951,\n",
       "       32860.67787964, 13342.21561598, 17957.26690856, 18482.52702541,\n",
       "       22611.45169995, 16663.48578013, 21762.25068762, 17632.12507802,\n",
       "       22204.12572142, 22204.12572142, 22741.54841101, 22741.54841101])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prix_prédits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22990, 42790, 23990, 17290, 17490, 26980, 37390, 17990, 18490,\n",
       "       13790, 12280, 29790, 33790, 11480, 27290, 14990, 10990, 13990,\n",
       "       31990, 23990, 10990, 23990, 19990, 11990, 24990, 23490, 34990,\n",
       "       22990,  9790, 13990, 15990, 13790, 26790, 19390, 26790, 13990,\n",
       "       24990, 26990, 27990, 22890, 14990, 21990, 26990, 15790, 15790,\n",
       "       15790, 14990, 27790, 10990, 26990, 15490, 27990,  7490, 21990,\n",
       "        9990, 18990, 11990, 18890, 19990, 19890, 13990, 22990, 13990,\n",
       "       27990, 25990, 15980, 27490, 45990, 27490, 22990, 24990, 16990,\n",
       "       15990, 20990, 26990, 26990, 43990, 14490, 24990, 19990, 18990,\n",
       "       16490, 17990, 20990, 23990, 19490, 31990, 20490, 18990, 19790,\n",
       "       18990,  9790, 33990, 17490, 16990, 36990, 13990, 27490, 13990,\n",
       "       32990, 34990, 26890, 11990, 39000, 27900, 11500, 26900, 30900,\n",
       "       31900, 29500, 49000, 18900, 18800, 17900, 22400, 25900, 16500,\n",
       "       30500, 28500, 27900, 22500, 36500, 44990, 23900, 18900, 40900,\n",
       "       26900, 21000, 29500, 14900, 29500, 30900, 21000, 19500, 19300,\n",
       "       21100, 15500, 19800, 19900, 32900, 27900, 17500, 28500, 27490,\n",
       "       13500, 19500, 17900, 13490, 10990, 12490, 18990, 24990, 15990,\n",
       "       10990, 13490, 12490, 15990, 16490, 23990, 32990, 14990, 23990,\n",
       "       24990, 14490, 17490, 27990, 12990, 17490, 12990, 17490, 23990,\n",
       "       22990, 41990, 24990, 39790, 22900, 18490, 23490, 16490, 17990,\n",
       "       29490, 26490, 16490, 24490, 27990, 25490, 24990, 24990, 24990,\n",
       "       18990, 16990,  9990, 18490, 22990, 18990, 24990, 15990, 19990,\n",
       "       16990, 18990, 22990, 13850, 29490, 24990, 13490, 17990, 35990,\n",
       "       27990, 11990, 34900, 26990, 25990, 18990, 19990, 15990, 18990,\n",
       "       11990, 27990, 26990, 16490, 14200, 14500, 28990, 18990, 27900,\n",
       "       28900, 31500, 15499, 24990, 15990, 23490, 26499, 22490, 24995,\n",
       "       25999, 29100, 16500, 26890, 18995, 15990, 18990, 18300, 28900,\n",
       "       26990, 24990, 16990, 15990, 13500, 15980, 17990, 14900, 11500,\n",
       "       14900, 18990, 24300, 18340, 20150, 31350, 23990, 14990,  9600,\n",
       "       14900, 20990, 28900, 28900, 28900, 28900, 27900, 24300, 14500,\n",
       "       29900, 23195, 13450, 39990, 29250, 16150, 14050, 29250, 18250,\n",
       "       28850, 21350, 19950, 27250, 26850, 21250, 22450, 29650, 28250,\n",
       "       25990, 37188, 13790, 15990, 18790, 18990, 25490, 17990, 31990,\n",
       "       10790, 11990,  8990, 36290, 20999, 13899, 12299, 17999, 20999,\n",
       "       18499, 18490, 13899, 14499, 14199, 13999, 25499, 14499, 14499,\n",
       "       13999, 14499, 24999, 14499, 28799, 29499, 38999, 13285, 13200,\n",
       "       19485, 22295, 18490, 13995, 11325, 34985, 11485, 16990, 12490,\n",
       "        9890, 25490, 12490,  8490, 37980, 14980, 11780, 39990, 14780,\n",
       "       49990, 17980, 31390, 25250, 14980, 14950, 23950, 13980, 15980,\n",
       "       20950, 47490, 28480, 26490, 23880, 30990, 39590, 24780, 36990,\n",
       "       23900, 24950, 28450, 38250, 33213, 25890, 28600, 16950, 28450,\n",
       "       13850, 15880, 25480,  9950, 24480, 14280, 17480, 17950, 12480,\n",
       "       18280, 22780, 21250, 19480, 31780, 17280, 23980, 14350, 17440,\n",
       "       16780, 16280, 19480, 23480, 23250, 27242, 25480, 17480, 21980,\n",
       "       15450, 18834, 18280, 15250, 19780, 15750, 20250, 37480, 27980,\n",
       "       27450, 16200, 16250, 16200, 16250, 20250, 35780, 15980, 20150,\n",
       "       15700, 20150, 16600, 44980, 16980, 17280, 20980, 15280, 15480,\n",
       "       37980, 33890, 49990, 26780, 17980, 40980, 15280, 34490, 29990,\n",
       "       31490, 29990, 20388, 28990, 13990, 20990, 12490, 19490, 16990,\n",
       "       26990, 26990, 31990, 12490, 18799, 28990, 13890, 11490, 22490,\n",
       "       15990, 12490, 13490, 12990, 11890, 11990, 19990, 36490, 21990,\n",
       "       31990, 27390, 27990, 27390, 31990, 27990, 15990, 11990, 13490,\n",
       "       26490, 14490, 19990, 15990, 15990, 11990, 15990, 19990, 27990,\n",
       "       17990, 15990, 19990, 15990, 29990,  9990, 20990, 20990, 14490,\n",
       "       14900, 20990, 45900, 15490, 18490, 21490, 18490, 18490, 15990,\n",
       "       11290, 16990, 11490, 18990, 11490, 10890, 14990, 18490, 13990,\n",
       "       21990, 14990, 15990, 15490, 38490, 33990, 20490, 45990, 12990,\n",
       "       13990, 38990, 12990, 24990, 26490, 19990, 18990, 23990, 12490,\n",
       "       15490, 48990, 27990, 15490, 11990, 37290, 28990, 17490, 29490,\n",
       "       19900,  8990, 14700, 13900, 17290, 28900, 22900, 25900, 21490,\n",
       "       28900, 31900, 20490, 17900, 28900, 13900, 21900, 20900, 13490,\n",
       "       29900, 15900, 14900, 21790, 18900, 15490, 27489, 15489, 19889,\n",
       "       13989, 16989, 15489, 32960, 29000, 13490, 23950, 11378, 16989,\n",
       "       17389, 35489, 19990, 25989, 34689, 15889, 11989, 16989, 11999,\n",
       "       13889, 18989, 15889, 36849, 13999, 11999, 32989, 32989, 21589,\n",
       "       22979, 32489, 11399, 36790, 12879, 13799, 15799, 21489, 16989,\n",
       "       19989, 17579, 22689, 22689, 22689, 22689], dtype=int64)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prix_reels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif : maximiser le surplus de l'acheteur, i.e, si l'acheteur à un budget R, et n contraintes, quel véhicule maximiserait son surplus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_finale = conversion_df.data_frame_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_finale['prix_predits'] = prix_prédits\n",
    "data_finale['surplus_conso'] = data_finale['prix'] - data_finale['prix_predits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prix</th>\n",
       "      <th>kilometrage</th>\n",
       "      <th>date_mise_circulation</th>\n",
       "      <th>puissance</th>\n",
       "      <th>nb_places</th>\n",
       "      <th>puissance_fiscale</th>\n",
       "      <th>critair</th>\n",
       "      <th>ptac</th>\n",
       "      <th>nb_portes</th>\n",
       "      <th>BERLINGO</th>\n",
       "      <th>...</th>\n",
       "      <th>SPOTICAR ESSENTIAL</th>\n",
       "      <th>SPOTICAR PREMIUM</th>\n",
       "      <th>Ex-Auto-école</th>\n",
       "      <th>Ex-Import</th>\n",
       "      <th>Ex-Loueur</th>\n",
       "      <th>Ex-Particulier</th>\n",
       "      <th>Ex-Société</th>\n",
       "      <th>Véhicule de direction</th>\n",
       "      <th>prix_predits</th>\n",
       "      <th>surplus_conso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22990</td>\n",
       "      <td>20629.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22247.824000</td>\n",
       "      <td>742.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42790</td>\n",
       "      <td>5104.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>181.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42389.001572</td>\n",
       "      <td>400.998428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23990</td>\n",
       "      <td>8900.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24137.296769</td>\n",
       "      <td>-147.296769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17290</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16054.710383</td>\n",
       "      <td>1235.289617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17490</td>\n",
       "      <td>37377.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16203.885416</td>\n",
       "      <td>1286.114584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>17579</td>\n",
       "      <td>10598.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17632.125078</td>\n",
       "      <td>-53.125078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>22689</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22204.125721</td>\n",
       "      <td>484.874279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>22689</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22204.125721</td>\n",
       "      <td>484.874279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>22689</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22741.548411</td>\n",
       "      <td>-52.548411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>22689</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22741.548411</td>\n",
       "      <td>-52.548411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prix  kilometrage  date_mise_circulation  puissance  nb_places  \\\n",
       "0    22990      20629.0                   2021      110.0        5.0   \n",
       "1    42790       5104.0                   2022      181.0        5.0   \n",
       "2    23990       8900.0                   2021      131.0        5.0   \n",
       "3    17290       1305.0                   2021       83.0        5.0   \n",
       "4    17490      37377.0                   2019      110.0        5.0   \n",
       "..     ...          ...                    ...        ...        ...   \n",
       "595  17579      10598.0                   2018      110.0        5.0   \n",
       "596  22689         30.0                   2022      110.0        5.0   \n",
       "597  22689         30.0                   2022      110.0        5.0   \n",
       "598  22689         30.0                   2022      110.0        5.0   \n",
       "599  22689         30.0                   2022      110.0        5.0   \n",
       "\n",
       "     puissance_fiscale  critair    ptac  nb_portes  BERLINGO  ...  \\\n",
       "0                  6.0      2.0  1835.0        5.0         0  ...   \n",
       "1                 10.0      1.0  2300.0        5.0         0  ...   \n",
       "2                  7.0      1.0  1735.0        5.0         0  ...   \n",
       "3                  4.0      1.0  1540.0        5.0         0  ...   \n",
       "4                  5.0      1.0  1600.0        5.0         0  ...   \n",
       "..                 ...      ...     ...        ...       ...  ...   \n",
       "595                5.0      1.0  1795.0        5.0         0  ...   \n",
       "596                6.0      1.0  1610.0        5.0         0  ...   \n",
       "597                6.0      1.0  1610.0        5.0         0  ...   \n",
       "598                6.0      1.0  1610.0        5.0         0  ...   \n",
       "599                6.0      1.0  1610.0        5.0         0  ...   \n",
       "\n",
       "     SPOTICAR ESSENTIAL  SPOTICAR PREMIUM  Ex-Auto-école  Ex-Import  \\\n",
       "0                     0                 1              0          1   \n",
       "1                     0                 1              0          0   \n",
       "2                     0                 1              0          1   \n",
       "3                     0                 1              0          1   \n",
       "4                     0                 1              0          1   \n",
       "..                  ...               ...            ...        ...   \n",
       "595                   0                 1              0          0   \n",
       "596                   0                 1              0          1   \n",
       "597                   0                 1              0          1   \n",
       "598                   0                 1              0          1   \n",
       "599                   0                 1              0          1   \n",
       "\n",
       "     Ex-Loueur  Ex-Particulier  Ex-Société  Véhicule de direction  \\\n",
       "0            0               0           0                      0   \n",
       "1            1               0           0                      0   \n",
       "2            0               0           0                      0   \n",
       "3            0               0           0                      0   \n",
       "4            0               0           0                      0   \n",
       "..         ...             ...         ...                    ...   \n",
       "595          0               1           0                      0   \n",
       "596          0               0           0                      0   \n",
       "597          0               0           0                      0   \n",
       "598          0               0           0                      0   \n",
       "599          0               0           0                      0   \n",
       "\n",
       "     prix_predits  surplus_conso  \n",
       "0    22247.824000     742.176000  \n",
       "1    42389.001572     400.998428  \n",
       "2    24137.296769    -147.296769  \n",
       "3    16054.710383    1235.289617  \n",
       "4    16203.885416    1286.114584  \n",
       "..            ...            ...  \n",
       "595  17632.125078     -53.125078  \n",
       "596  22204.125721     484.874279  \n",
       "597  22204.125721     484.874279  \n",
       "598  22741.548411     -52.548411  \n",
       "599  22741.548411     -52.548411  \n",
       "\n",
       "[600 rows x 66 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_finale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95d745ba7d4956a2c972602a1881faa5aacde8c57f39878a3d2b517a3ec985cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
