{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serde import serde\n",
    "from serde.json import to_json, from_json\n",
    "from dataclasses import dataclass\n",
    "from time import sleep\n",
    "from scrapping import Voiture\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import conversion_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récuperation du json et conversion en quelque chose d'utilisable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion en base de données panda et nettoyage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarques sur les variables :\n",
    "\n",
    "- modele : enlever les espaces, ou supprimer les variables peu occurentes (<=1)\n",
    "- carburant : même remarque\n",
    "- même remarque pour toutes les variables textuelles\n",
    "- utilisation précédente : regrouper par pro/loueur/part/ ne sait pas ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de dummys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = conversion_df.data_frame_pandas('donnees_citroen.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marque                    object\n",
       "modele                    object\n",
       "carburant                 object\n",
       "prix                       int64\n",
       "kilometrage              float64\n",
       "garantie_kilometrage      object\n",
       "boite_de_vitesse          object\n",
       "transmission             float64\n",
       "couleur                   object\n",
       "garantie                  object\n",
       "date_mise_circulation      int64\n",
       "puissance                float64\n",
       "silhouette                object\n",
       "nb_places                float64\n",
       "utilisation_prec          object\n",
       "puissance_fiscale        float64\n",
       "critair                  float64\n",
       "ptac                     float64\n",
       "nb_portes                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1835.0\n",
       "1      2300.0\n",
       "2      1735.0\n",
       "3      1540.0\n",
       "4      1600.0\n",
       "        ...  \n",
       "595    1795.0\n",
       "596    1610.0\n",
       "597    1610.0\n",
       "598    1610.0\n",
       "599    1610.0\n",
       "Name: ptac, Length: 600, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ptac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marque                   string\n",
       "modele                   string\n",
       "carburant                string\n",
       "prix                      Int64\n",
       "kilometrage               Int64\n",
       "garantie_kilometrage     string\n",
       "boite_de_vitesse         string\n",
       "transmission              Int64\n",
       "couleur                  string\n",
       "garantie                 string\n",
       "date_mise_circulation     Int64\n",
       "puissance                 Int64\n",
       "silhouette               string\n",
       "nb_places                 Int64\n",
       "utilisation_prec         string\n",
       "puissance_fiscale         Int64\n",
       "critair                   Int64\n",
       "ptac                      Int64\n",
       "nb_portes                 Int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.convert_dtypes().dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passage sous numpy + ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "import conversion_df\n",
    "import pandas as pd\n",
    "\n",
    "conversion_df = reload(conversion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trp = conversion_df.data_frame_pandas('donnees_fiat.json')\n",
    "df = conversion_df.data_frame_pandas('donnees_peugeot.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trp_fin = pd.concat([df,trp], ignore_index=True)\n",
    "trp_fin_cat = conversion_df.data_frame_dummies(trp_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prix</th>\n",
       "      <th>kilometrage</th>\n",
       "      <th>date_mise_circulation</th>\n",
       "      <th>puissance</th>\n",
       "      <th>nb_places</th>\n",
       "      <th>puissance_fiscale</th>\n",
       "      <th>critair</th>\n",
       "      <th>ptac</th>\n",
       "      <th>nb_portes</th>\n",
       "      <th>Peugeot</th>\n",
       "      <th>...</th>\n",
       "      <th>AUTOEXPERT</th>\n",
       "      <th>SPOTICAR ADVANCED</th>\n",
       "      <th>SPOTICAR ESSENTIAL</th>\n",
       "      <th>SPOTICAR PREMIUM</th>\n",
       "      <th>Ex-Auto-ï¿½cole</th>\n",
       "      <th>Ex-Import</th>\n",
       "      <th>Ex-Loueur</th>\n",
       "      <th>Ex-Particulier</th>\n",
       "      <th>Ex-Sociï¿½tï¿½</th>\n",
       "      <th>Vï¿½hicule de direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20290</td>\n",
       "      <td>75967</td>\n",
       "      <td>2019</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31900</td>\n",
       "      <td>29066</td>\n",
       "      <td>2021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33920</td>\n",
       "      <td>31997</td>\n",
       "      <td>2021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21980</td>\n",
       "      <td>40952</td>\n",
       "      <td>2021</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22990</td>\n",
       "      <td>7901</td>\n",
       "      <td>2021</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>31490</td>\n",
       "      <td>2535</td>\n",
       "      <td>2022</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1770.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>37490</td>\n",
       "      <td>21164</td>\n",
       "      <td>2022</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>36490</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>38990</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>177.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>21990</td>\n",
       "      <td>19050</td>\n",
       "      <td>2021</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>601 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prix  kilometrage  date_mise_circulation  puissance  nb_places  \\\n",
       "0    20290        75967                   2019      130.0        5.0   \n",
       "1    31900        29066                   2021      130.0        5.0   \n",
       "2    33920        31997                   2021      130.0        5.0   \n",
       "3    21980        40952                   2021      100.0        5.0   \n",
       "4    22990         7901                   2021      100.0        5.0   \n",
       "..     ...          ...                    ...        ...        ...   \n",
       "596  31490         2535                   2022      131.0        5.0   \n",
       "597  37490        21164                   2022      131.0        5.0   \n",
       "598  36490           10                   2022      145.0        3.0   \n",
       "599  38990           10                   2022      177.0        6.0   \n",
       "600  21990        19050                   2021      100.0        5.0   \n",
       "\n",
       "     puissance_fiscale  critair    ptac  nb_portes  Peugeot  ...  AUTOEXPERT  \\\n",
       "0                  6.0      2.0  1890.0        5.0        1  ...           0   \n",
       "1                  7.0      2.0  1875.0        5.0        1  ...           0   \n",
       "2                  7.0      1.0  1875.0        5.0        1  ...           0   \n",
       "3                  5.0      1.0  1875.0        5.0        1  ...           0   \n",
       "4                  5.0      1.0  1875.0        5.0        1  ...           0   \n",
       "..                 ...      ...     ...        ...      ...  ...         ...   \n",
       "596                7.0      2.0  1770.0        5.0        1  ...           0   \n",
       "597                7.0      2.0  2000.0        5.0        1  ...           0   \n",
       "598                7.0      2.0  1875.0        5.0        1  ...           0   \n",
       "599                7.0      2.0  2790.0        5.0        1  ...           0   \n",
       "600                5.0      1.0    1800        5.0        1  ...           0   \n",
       "\n",
       "     SPOTICAR ADVANCED  SPOTICAR ESSENTIAL  SPOTICAR PREMIUM  Ex-Auto-ï¿½cole  \\\n",
       "0                    0                   0                 1                0   \n",
       "1                    0                   0                 1                0   \n",
       "2                    0                   0                 1                0   \n",
       "3                    0                   0                 1                0   \n",
       "4                    0                   0                 1                0   \n",
       "..                 ...                 ...               ...              ...   \n",
       "596                  0                   0                 1                0   \n",
       "597                  0                   0                 1                0   \n",
       "598                  0                   0                 1                0   \n",
       "599                  0                   0                 1                0   \n",
       "600                  0                   0                 1                0   \n",
       "\n",
       "     Ex-Import  Ex-Loueur  Ex-Particulier  Ex-Sociï¿½tï¿½  \\\n",
       "0            0          1               0               0   \n",
       "1            0          1               0               0   \n",
       "2            0          1               0               0   \n",
       "3            0          1               0               0   \n",
       "4            0          0               1               0   \n",
       "..         ...        ...             ...             ...   \n",
       "596          1          0               0               0   \n",
       "597          0          1               0               0   \n",
       "598          0          1               0               0   \n",
       "599          0          1               0               0   \n",
       "600          0          1               0               0   \n",
       "\n",
       "     Vï¿½hicule de direction  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "..                       ...  \n",
       "596                        0  \n",
       "597                        0  \n",
       "598                        0  \n",
       "599                        0  \n",
       "600                        0  \n",
       "\n",
       "[601 rows x 62 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trp_fin_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = trp_fin.loc[:, trp_fin.columns != 'prix'].to_numpy()\n",
    "y_pred = trp_fin['prix'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'prix'].to_numpy()\n",
    "y = df['prix'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['prix', 'kilometrage', 'date_mise_circulation', 'puissance',\n",
       "       'nb_places', 'puissance_fiscale', 'critair', 'ptac', 'nb_portes',\n",
       "       'Peugeot', '108', '2008', '208', '3008', '308', '308 SW', '4008',\n",
       "       '5008', '508', '508 SW', 'BOXER', 'EXPERT', 'PARTNER', 'RIFTER',\n",
       "       'TRAVELLER', 'garanti', 'non garanti', 'Diesel', 'Electrique',\n",
       "       'Essence', 'Hybride rechargeable', 'Automatique', 'Manuelle',\n",
       "       'Blanc', 'Bleu', 'Brun', 'Gris', 'Jaune', 'Noir', 'Orange',\n",
       "       'Rouge', 'Sable', 'Vert', 'Berline', 'Break', 'Citadine',\n",
       "       'Familiale', 'SUV-4x4', 'Utilitaire', 2.0, 4.0, 'AUTOEXPERT',\n",
       "       'SPOTICAR ADVANCED', 'SPOTICAR ESSENTIAL', 'SPOTICAR PREMIUM',\n",
       "       'Ex-Auto-ï¿½cole', 'Ex-Import', 'Ex-Loueur', 'Ex-Particulier',\n",
       "       'Ex-Sociï¿½tï¿½', 'Vï¿½hicule de direction'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = conversion_df.data_frame_dummies(df)\n",
    "df_cat.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['prix', 'kilometrage', 'date_mise_circulation', 'puissance',\n",
       "       'nb_places', 'puissance_fiscale', 'critair', 'ptac', 'nb_portes',\n",
       "       'Peugeot', '108', '2008', '208', '3008', '308', '308 SW', '4008',\n",
       "       '5008', '508', '508 SW', 'BOXER', 'EXPERT', 'PARTNER', 'RIFTER',\n",
       "       'TRAVELLER', 'garanti', 'non garanti', 'Diesel', 'Electrique',\n",
       "       'Essence', 'Hybride rechargeable', 'Automatique', 'Manuelle',\n",
       "       'Blanc', 'Bleu', 'Brun', 'Gris', 'Jaune', 'Noir', 'Orange',\n",
       "       'Rouge', 'Sable', 'Vert', 'Berline', 'Break', 'Citadine',\n",
       "       'Familiale', 'SUV-4x4', 'Utilitaire', 2.0, 4.0, '2.0',\n",
       "       'AUTOEXPERT', 'SPOTICAR ADVANCED', 'SPOTICAR ESSENTIAL',\n",
       "       'SPOTICAR PREMIUM', 'Ex-Auto-ï¿½cole', 'Ex-Import', 'Ex-Loueur',\n",
       "       'Ex-Particulier', 'Ex-Sociï¿½tï¿½', 'Vï¿½hicule de direction'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trp_fin_cat.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.216e+08, tolerance: 2.843e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.759e+08, tolerance: 2.995e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.444e+08, tolerance: 2.670e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.563e+08, tolerance: 2.923e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.513e+08, tolerance: 2.935e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.204e+08, tolerance: 2.843e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.760e+08, tolerance: 2.995e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.453e+08, tolerance: 2.670e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.573e+08, tolerance: 2.923e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.487e+08, tolerance: 2.935e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.194e+08, tolerance: 2.843e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.714e+08, tolerance: 2.995e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.454e+08, tolerance: 2.670e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.672e+08, tolerance: 2.923e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.027e+08, tolerance: 2.935e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.109e+08, tolerance: 2.843e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.749e+08, tolerance: 2.995e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.508e+08, tolerance: 2.670e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.619e+08, tolerance: 2.923e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.498e+08, tolerance: 2.935e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.867e+08, tolerance: 2.843e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.700e+08, tolerance: 2.995e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.379e+08, tolerance: 2.670e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.508e+08, tolerance: 2.923e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.481e+08, tolerance: 2.935e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.813e+08, tolerance: 2.843e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.565e+08, tolerance: 2.995e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.370e+08, tolerance: 2.670e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.371e+08, tolerance: 2.923e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.427e+08, tolerance: 2.935e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.402e+08, tolerance: 2.843e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.171e+08, tolerance: 2.995e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.395e+08, tolerance: 2.670e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.941e+08, tolerance: 2.923e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.307e+08, tolerance: 2.935e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.628e+08, tolerance: 2.843e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.530e+08, tolerance: 2.995e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.037e+08, tolerance: 2.923e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.528e+08, tolerance: 2.935e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e+07, tolerance: 2.843e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.307e+08, tolerance: 2.923e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.420e+08, tolerance: 2.935e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015834</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 0.01}</td>\n",
       "      <td>0.905659</td>\n",
       "      <td>0.911354</td>\n",
       "      <td>0.882837</td>\n",
       "      <td>0.922235</td>\n",
       "      <td>0.895935</td>\n",
       "      <td>0.903604</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014031</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 0.25}</td>\n",
       "      <td>0.904595</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.882037</td>\n",
       "      <td>0.921721</td>\n",
       "      <td>0.895886</td>\n",
       "      <td>0.903004</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017320</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 0.5}</td>\n",
       "      <td>0.902391</td>\n",
       "      <td>0.909652</td>\n",
       "      <td>0.881149</td>\n",
       "      <td>0.920748</td>\n",
       "      <td>0.895190</td>\n",
       "      <td>0.901826</td>\n",
       "      <td>0.013351</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054195</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 0.75}</td>\n",
       "      <td>0.896691</td>\n",
       "      <td>0.907388</td>\n",
       "      <td>0.880773</td>\n",
       "      <td>0.918086</td>\n",
       "      <td>0.893113</td>\n",
       "      <td>0.899210</td>\n",
       "      <td>0.012701</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044841</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 1}</td>\n",
       "      <td>0.874638</td>\n",
       "      <td>0.902261</td>\n",
       "      <td>0.894180</td>\n",
       "      <td>0.865373</td>\n",
       "      <td>0.900072</td>\n",
       "      <td>0.887305</td>\n",
       "      <td>0.014666</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.015834      0.003362         0.000399        0.000488    0.015625   \n",
       "1       0.014031      0.001314         0.000000        0.000000    0.015625   \n",
       "2       0.017320      0.004734         0.000776        0.000390    0.015625   \n",
       "3       0.054195      0.009747         0.000598        0.000489    0.015625   \n",
       "4       0.044841      0.027747         0.000598        0.000488    0.015625   \n",
       "\n",
       "  param_l1_ratio                                 params  split0_test_score  \\\n",
       "0           0.01  {'alpha': 0.015625, 'l1_ratio': 0.01}           0.905659   \n",
       "1           0.25  {'alpha': 0.015625, 'l1_ratio': 0.25}           0.904595   \n",
       "2            0.5   {'alpha': 0.015625, 'l1_ratio': 0.5}           0.902391   \n",
       "3           0.75  {'alpha': 0.015625, 'l1_ratio': 0.75}           0.896691   \n",
       "4              1     {'alpha': 0.015625, 'l1_ratio': 1}           0.874638   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.911354           0.882837           0.922235           0.895935   \n",
       "1           0.910782           0.882037           0.921721           0.895886   \n",
       "2           0.909652           0.881149           0.920748           0.895190   \n",
       "3           0.907388           0.880773           0.918086           0.893113   \n",
       "4           0.902261           0.894180           0.865373           0.900072   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.903604        0.013428                7  \n",
       "1         0.903004        0.013443                9  \n",
       "2         0.901826        0.013351               15  \n",
       "3         0.899210        0.012701               18  \n",
       "4         0.887305        0.014666               28  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = ElasticNet()\n",
    "en_gs = GridSearchCV(\n",
    "    en,\n",
    "    {\n",
    "        \"alpha\": [2 ** p  for p in range(-6, 6)],\n",
    "        \"l1_ratio\": (0.01, 0.25, 0.5, 0.75, 1),\n",
    "    }\n",
    ")\n",
    "en_gs.fit(X_tr, y_tr) #problème vient du fit\n",
    "en_df = pd.DataFrame(en_gs.cv_results_)\n",
    "en_df.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 0.03125, 'l1_ratio': 0.25}, 0.9040899919567875)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_gs.best_params_, en_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(en_gs\u001b[39m.\u001b[39;49mpredict(X_pred))[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:500\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[39mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39m    the best found parameters.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    499\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 500\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mpredict(X)\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:355\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    342\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1077\u001b[0m, in \u001b[0;36mElasticNet._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[0;32m   1076\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1077\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:338\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    336\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 338\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcoo\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    339\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 535\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    536\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    537\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:919\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    914\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    915\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    916\u001b[0m         )\n\u001b[0;32m    918\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 919\u001b[0m         _assert_all_finite(\n\u001b[0;32m    920\u001b[0m             array,\n\u001b[0;32m    921\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    922\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    923\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    924\u001b[0m         )\n\u001b[0;32m    926\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    927\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(en_gs.predict(X_pred))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prix</th>\n",
       "      <th>kilometrage</th>\n",
       "      <th>date_mise_circulation</th>\n",
       "      <th>puissance</th>\n",
       "      <th>nb_places</th>\n",
       "      <th>puissance_fiscale</th>\n",
       "      <th>critair</th>\n",
       "      <th>ptac</th>\n",
       "      <th>nb_portes</th>\n",
       "      <th>Peugeot</th>\n",
       "      <th>...</th>\n",
       "      <th>AUTOEXPERT</th>\n",
       "      <th>SPOTICAR ADVANCED</th>\n",
       "      <th>SPOTICAR ESSENTIAL</th>\n",
       "      <th>SPOTICAR PREMIUM</th>\n",
       "      <th>Ex-Auto-ï¿½cole</th>\n",
       "      <th>Ex-Import</th>\n",
       "      <th>Ex-Loueur</th>\n",
       "      <th>Ex-Particulier</th>\n",
       "      <th>Ex-Sociï¿½tï¿½</th>\n",
       "      <th>Vï¿½hicule de direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31900</td>\n",
       "      <td>29066</td>\n",
       "      <td>2021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20290</td>\n",
       "      <td>75967</td>\n",
       "      <td>2019</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1890.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31900</td>\n",
       "      <td>29066</td>\n",
       "      <td>2021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1874.729367</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33920</td>\n",
       "      <td>31997</td>\n",
       "      <td>2021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1874.729367</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21980</td>\n",
       "      <td>40952</td>\n",
       "      <td>2021</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1874.729367</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>33990</td>\n",
       "      <td>3254</td>\n",
       "      <td>2022</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>31490</td>\n",
       "      <td>2535</td>\n",
       "      <td>2022</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1770.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>37490</td>\n",
       "      <td>21164</td>\n",
       "      <td>2022</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>36490</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1874.729367</td>\n",
       "      <td>4.934673</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>38990</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>177.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2790.000000</td>\n",
       "      <td>4.934673</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>601 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prix  kilometrage  date_mise_circulation  puissance  nb_places  \\\n",
       "0    31900        29066                   2021      130.0        5.0   \n",
       "1    20290        75967                   2019      130.0        5.0   \n",
       "2    31900        29066                   2021      130.0        5.0   \n",
       "3    33920        31997                   2021      130.0        5.0   \n",
       "4    21980        40952                   2021      100.0        5.0   \n",
       "..     ...          ...                    ...        ...        ...   \n",
       "596  33990         3254                   2022      131.0        5.0   \n",
       "597  31490         2535                   2022      131.0        5.0   \n",
       "598  37490        21164                   2022      131.0        5.0   \n",
       "599  36490           10                   2022      145.0        3.0   \n",
       "600  38990           10                   2022      177.0        6.0   \n",
       "\n",
       "     puissance_fiscale  critair         ptac  nb_portes  Peugeot  ...  \\\n",
       "0                  7.0      2.0  2000.000000   5.000000        1  ...   \n",
       "1                  6.0      2.0  1890.000000   5.000000        1  ...   \n",
       "2                  7.0      2.0  1874.729367   5.000000        1  ...   \n",
       "3                  7.0      1.0  1874.729367   5.000000        1  ...   \n",
       "4                  5.0      1.0  1874.729367   5.000000        1  ...   \n",
       "..                 ...      ...          ...        ...      ...  ...   \n",
       "596                7.0      2.0  1940.000000   5.000000        1  ...   \n",
       "597                7.0      2.0  1770.000000   5.000000        1  ...   \n",
       "598                7.0      2.0  2000.000000   5.000000        1  ...   \n",
       "599                7.0      2.0  1874.729367   4.934673        1  ...   \n",
       "600                7.0      2.0  2790.000000   4.934673        1  ...   \n",
       "\n",
       "     AUTOEXPERT  SPOTICAR ADVANCED  SPOTICAR ESSENTIAL  SPOTICAR PREMIUM  \\\n",
       "0             0                  0                   0                 1   \n",
       "1             0                  0                   0                 1   \n",
       "2             0                  0                   0                 1   \n",
       "3             0                  0                   0                 1   \n",
       "4             0                  0                   0                 1   \n",
       "..          ...                ...                 ...               ...   \n",
       "596           0                  0                   0                 1   \n",
       "597           0                  0                   0                 1   \n",
       "598           0                  0                   0                 1   \n",
       "599           0                  0                   0                 1   \n",
       "600           0                  0                   0                 1   \n",
       "\n",
       "     Ex-Auto-ï¿½cole  Ex-Import  Ex-Loueur  Ex-Particulier  Ex-Sociï¿½tï¿½  \\\n",
       "0                  0          0          0               1               0   \n",
       "1                  0          0          1               0               0   \n",
       "2                  0          0          1               0               0   \n",
       "3                  0          0          1               0               0   \n",
       "4                  0          0          1               0               0   \n",
       "..               ...        ...        ...             ...             ...   \n",
       "596                0          0          1               0               0   \n",
       "597                0          1          0               0               0   \n",
       "598                0          0          1               0               0   \n",
       "599                0          0          1               0               0   \n",
       "600                0          0          1               0               0   \n",
       "\n",
       "     Vï¿½hicule de direction  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "..                       ...  \n",
       "596                        0  \n",
       "597                        0  \n",
       "598                        0  \n",
       "599                        0  \n",
       "600                        0  \n",
       "\n",
       "[601 rows x 63 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trp_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr = KNeighborsRegressor()\n",
    "knr_gs = GridSearchCV(\n",
    "    knr,\n",
    "    {\n",
    "        \"n_neighbors\": range(5, 15),\n",
    "        \"weights\": (\"uniform\", \"distance\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.053869</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform'}</td>\n",
       "      <td>0.237296</td>\n",
       "      <td>0.138595</td>\n",
       "      <td>0.085176</td>\n",
       "      <td>0.199244</td>\n",
       "      <td>0.242035</td>\n",
       "      <td>0.180469</td>\n",
       "      <td>0.060343</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.010615</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.310453</td>\n",
       "      <td>0.242396</td>\n",
       "      <td>0.161994</td>\n",
       "      <td>0.256855</td>\n",
       "      <td>0.352684</td>\n",
       "      <td>0.264876</td>\n",
       "      <td>0.064718</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'uniform'}</td>\n",
       "      <td>0.226388</td>\n",
       "      <td>0.150351</td>\n",
       "      <td>0.076146</td>\n",
       "      <td>0.150914</td>\n",
       "      <td>0.250056</td>\n",
       "      <td>0.170771</td>\n",
       "      <td>0.061878</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'distance'}</td>\n",
       "      <td>0.320819</td>\n",
       "      <td>0.256992</td>\n",
       "      <td>0.164710</td>\n",
       "      <td>0.260437</td>\n",
       "      <td>0.362410</td>\n",
       "      <td>0.273074</td>\n",
       "      <td>0.066965</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'uniform'}</td>\n",
       "      <td>0.136164</td>\n",
       "      <td>0.192242</td>\n",
       "      <td>0.077164</td>\n",
       "      <td>0.164597</td>\n",
       "      <td>0.241459</td>\n",
       "      <td>0.162325</td>\n",
       "      <td>0.054953</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.000796      0.000398         0.036902        0.053869   \n",
       "1       0.000596      0.000486         0.010615        0.001336   \n",
       "2       0.000599      0.000489         0.006581        0.000797   \n",
       "3       0.000798      0.000399         0.007579        0.000488   \n",
       "4       0.000362      0.000448         0.006197        0.000723   \n",
       "\n",
       "  param_n_neighbors param_weights                                     params  \\\n",
       "0                 5       uniform   {'n_neighbors': 5, 'weights': 'uniform'}   \n",
       "1                 5      distance  {'n_neighbors': 5, 'weights': 'distance'}   \n",
       "2                 6       uniform   {'n_neighbors': 6, 'weights': 'uniform'}   \n",
       "3                 6      distance  {'n_neighbors': 6, 'weights': 'distance'}   \n",
       "4                 7       uniform   {'n_neighbors': 7, 'weights': 'uniform'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.237296           0.138595           0.085176           0.199244   \n",
       "1           0.310453           0.242396           0.161994           0.256855   \n",
       "2           0.226388           0.150351           0.076146           0.150914   \n",
       "3           0.320819           0.256992           0.164710           0.260437   \n",
       "4           0.136164           0.192242           0.077164           0.164597   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.242035         0.180469        0.060343               11  \n",
       "1           0.352684         0.264876        0.064718               10  \n",
       "2           0.250056         0.170771        0.061878               13  \n",
       "3           0.362410         0.273074        0.066965                2  \n",
       "4           0.241459         0.162325        0.054953               18  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knr_gs.fit(X_tr, y_tr)\n",
    "knr_df = pd.DataFrame(knr_gs.cv_results_)\n",
    "knr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_neighbors': 10, 'weights': 'distance'}, 0.27441340092389555)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knr_gs.best_params_, knr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr_gs = GridSearchCV(\n",
    "    rfr,\n",
    "    {   \n",
    "        \"n_estimators\": (8 , 16, 32, 64, 128, 256),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030977</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_estimators': 8}</td>\n",
       "      <td>0.863831</td>\n",
       "      <td>0.923225</td>\n",
       "      <td>0.915406</td>\n",
       "      <td>0.869892</td>\n",
       "      <td>0.919614</td>\n",
       "      <td>0.898394</td>\n",
       "      <td>0.025935</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053447</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_estimators': 16}</td>\n",
       "      <td>0.859975</td>\n",
       "      <td>0.910930</td>\n",
       "      <td>0.901864</td>\n",
       "      <td>0.866947</td>\n",
       "      <td>0.912811</td>\n",
       "      <td>0.890505</td>\n",
       "      <td>0.022498</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105126</td>\n",
       "      <td>0.010302</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>32</td>\n",
       "      <td>{'n_estimators': 32}</td>\n",
       "      <td>0.863968</td>\n",
       "      <td>0.920875</td>\n",
       "      <td>0.925860</td>\n",
       "      <td>0.879619</td>\n",
       "      <td>0.925305</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.026114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204340</td>\n",
       "      <td>0.014336</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>64</td>\n",
       "      <td>{'n_estimators': 64}</td>\n",
       "      <td>0.856954</td>\n",
       "      <td>0.923371</td>\n",
       "      <td>0.928749</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.929887</td>\n",
       "      <td>0.902459</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430837</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>128</td>\n",
       "      <td>{'n_estimators': 128}</td>\n",
       "      <td>0.862111</td>\n",
       "      <td>0.919943</td>\n",
       "      <td>0.929261</td>\n",
       "      <td>0.876534</td>\n",
       "      <td>0.927674</td>\n",
       "      <td>0.903105</td>\n",
       "      <td>0.028135</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.030977      0.001561         0.001136        0.000445   \n",
       "1       0.053447      0.001018         0.002006        0.000013   \n",
       "2       0.105126      0.010302         0.003179        0.000749   \n",
       "3       0.204340      0.014336         0.004864        0.000777   \n",
       "4       0.430837      0.021800         0.009987        0.001670   \n",
       "\n",
       "  param_n_estimators                 params  split0_test_score  \\\n",
       "0                  8    {'n_estimators': 8}           0.863831   \n",
       "1                 16   {'n_estimators': 16}           0.859975   \n",
       "2                 32   {'n_estimators': 32}           0.863968   \n",
       "3                 64   {'n_estimators': 64}           0.856954   \n",
       "4                128  {'n_estimators': 128}           0.862111   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.923225           0.915406           0.869892           0.919614   \n",
       "1           0.910930           0.901864           0.866947           0.912811   \n",
       "2           0.920875           0.925860           0.879619           0.925305   \n",
       "3           0.923371           0.928749           0.873333           0.929887   \n",
       "4           0.919943           0.929261           0.876534           0.927674   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.898394        0.025935                5  \n",
       "1         0.890505        0.022498                6  \n",
       "2         0.903125        0.026114                2  \n",
       "3         0.902459        0.030983                4  \n",
       "4         0.903105        0.028135                3  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_gs.fit(X_tr, y_tr)\n",
    "rfr_df = pd.DataFrame(rfr_gs.cv_results_)\n",
    "rfr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 256}, 0.9048408377007304)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_gs.best_params_, rfr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_epsilon</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.1}</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.057369</td>\n",
       "      <td>-0.201811</td>\n",
       "      <td>-0.029707</td>\n",
       "      <td>-0.115842</td>\n",
       "      <td>-0.080923</td>\n",
       "      <td>0.071524</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007984</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 1.0}</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.057370</td>\n",
       "      <td>-0.201811</td>\n",
       "      <td>-0.029701</td>\n",
       "      <td>-0.115827</td>\n",
       "      <td>-0.080919</td>\n",
       "      <td>0.071523</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 10}</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.056837</td>\n",
       "      <td>-0.201811</td>\n",
       "      <td>-0.029279</td>\n",
       "      <td>-0.116559</td>\n",
       "      <td>-0.080874</td>\n",
       "      <td>0.071692</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1.0, 'epsilon': 0.1}</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>-0.055183</td>\n",
       "      <td>-0.200572</td>\n",
       "      <td>-0.027467</td>\n",
       "      <td>-0.115196</td>\n",
       "      <td>-0.079428</td>\n",
       "      <td>0.071772</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008629</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.005003</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'epsilon': 1.0}</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>-0.055180</td>\n",
       "      <td>-0.200572</td>\n",
       "      <td>-0.027467</td>\n",
       "      <td>-0.115196</td>\n",
       "      <td>-0.079427</td>\n",
       "      <td>0.071773</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.009369      0.001486         0.005388        0.001955     0.1   \n",
       "1       0.007984      0.000621         0.003935        0.000644     0.1   \n",
       "2       0.008379      0.000488         0.004378        0.000497     0.1   \n",
       "3       0.009176      0.001162         0.004388        0.000488     1.0   \n",
       "4       0.008629      0.001687         0.005003        0.001116     1.0   \n",
       "\n",
       "  param_epsilon                      params  split0_test_score  \\\n",
       "0           0.1  {'C': 0.1, 'epsilon': 0.1}           0.000116   \n",
       "1           1.0  {'C': 0.1, 'epsilon': 1.0}           0.000116   \n",
       "2            10   {'C': 0.1, 'epsilon': 10}           0.000116   \n",
       "3           0.1  {'C': 1.0, 'epsilon': 0.1}           0.001278   \n",
       "4           1.0  {'C': 1.0, 'epsilon': 1.0}           0.001278   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -0.057369          -0.201811          -0.029707          -0.115842   \n",
       "1          -0.057370          -0.201811          -0.029701          -0.115827   \n",
       "2          -0.056837          -0.201811          -0.029279          -0.116559   \n",
       "3          -0.055183          -0.200572          -0.027467          -0.115196   \n",
       "4          -0.055180          -0.200572          -0.027467          -0.115196   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -0.080923        0.071524                9  \n",
       "1        -0.080919        0.071523                8  \n",
       "2        -0.080874        0.071692                7  \n",
       "3        -0.079428        0.071772                6  \n",
       "4        -0.079427        0.071773                5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr_gs = GridSearchCV(\n",
    "    svr,\n",
    "    {\n",
    "        \"C\": (0.1, 1.0, 10),\n",
    "        \"epsilon\": (0.1, 1.0, 10),\n",
    "    }\n",
    ")\n",
    "svr_gs.fit(X_tr, y_tr)\n",
    "\n",
    "svr_df = pd.DataFrame(svr_gs.cv_results_)\n",
    "svr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 10, 'epsilon': 0.1}, -0.0679771280241436)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_gs.best_params_, svr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(\n",
    "    [\n",
    "        (\"mise_echelle\", MinMaxScaler()),\n",
    "        (\"support_vecteurs\", SVR()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_gs = GridSearchCV(\n",
    "    pl,\n",
    "    {\n",
    "        \"support_vecteurs__C\": (0.1, 1.0, 10),\n",
    "        \"support_vecteurs__epsilon\": (0.1, 1.0, 10),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_support_vecteurs__C</th>\n",
       "      <th>param_support_vecteurs__epsilon</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'support_vecteurs__C': 0.1, 'support_vecteurs...</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>-0.057256</td>\n",
       "      <td>-0.201915</td>\n",
       "      <td>-0.029561</td>\n",
       "      <td>-0.115632</td>\n",
       "      <td>-0.080811</td>\n",
       "      <td>0.071610</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008577</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'support_vecteurs__C': 0.1, 'support_vecteurs...</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>-0.057221</td>\n",
       "      <td>-0.201915</td>\n",
       "      <td>-0.029556</td>\n",
       "      <td>-0.115663</td>\n",
       "      <td>-0.080809</td>\n",
       "      <td>0.071616</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008384</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'support_vecteurs__C': 0.1, 'support_vecteurs...</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>-0.056686</td>\n",
       "      <td>-0.201915</td>\n",
       "      <td>-0.029134</td>\n",
       "      <td>-0.116420</td>\n",
       "      <td>-0.080770</td>\n",
       "      <td>0.071787</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'support_vecteurs__C': 1.0, 'support_vecteurs...</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>-0.054037</td>\n",
       "      <td>-0.199610</td>\n",
       "      <td>-0.026008</td>\n",
       "      <td>-0.113175</td>\n",
       "      <td>-0.077928</td>\n",
       "      <td>0.071966</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.004791</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'support_vecteurs__C': 1.0, 'support_vecteurs...</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>-0.054045</td>\n",
       "      <td>-0.199610</td>\n",
       "      <td>-0.026008</td>\n",
       "      <td>-0.113175</td>\n",
       "      <td>-0.077930</td>\n",
       "      <td>0.071965</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.008177      0.000977         0.004787        0.000747   \n",
       "1       0.008577      0.000790         0.005180        0.001463   \n",
       "2       0.008384      0.000484         0.003990        0.000891   \n",
       "3       0.008373      0.000489         0.004778        0.000980   \n",
       "4       0.008773      0.000397         0.004791        0.000753   \n",
       "\n",
       "  param_support_vecteurs__C param_support_vecteurs__epsilon  \\\n",
       "0                       0.1                             0.1   \n",
       "1                       0.1                             1.0   \n",
       "2                       0.1                              10   \n",
       "3                       1.0                             0.1   \n",
       "4                       1.0                             1.0   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'support_vecteurs__C': 0.1, 'support_vecteurs...           0.000307   \n",
       "1  {'support_vecteurs__C': 0.1, 'support_vecteurs...           0.000307   \n",
       "2  {'support_vecteurs__C': 0.1, 'support_vecteurs...           0.000307   \n",
       "3  {'support_vecteurs__C': 1.0, 'support_vecteurs...           0.003189   \n",
       "4  {'support_vecteurs__C': 1.0, 'support_vecteurs...           0.003189   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -0.057256          -0.201915          -0.029561          -0.115632   \n",
       "1          -0.057221          -0.201915          -0.029556          -0.115663   \n",
       "2          -0.056686          -0.201915          -0.029134          -0.116420   \n",
       "3          -0.054037          -0.199610          -0.026008          -0.113175   \n",
       "4          -0.054045          -0.199610          -0.026008          -0.113175   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -0.080811        0.071610                9  \n",
       "1        -0.080809        0.071616                8  \n",
       "2        -0.080770        0.071787                7  \n",
       "3        -0.077928        0.071966                4  \n",
       "4        -0.077930        0.071965                5  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_gs.fit(X_tr, y_tr)\n",
    "\n",
    "pl_df = pd.DataFrame(pl_gs.cv_results_)\n",
    "pl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'support_vecteurs__C': 10, 'support_vecteurs__epsilon': 10},\n",
       " -0.04766514608492325)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_gs.best_params_, pl_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln = Pipeline(\n",
    "    [\n",
    "        (\"mise_echelle\", MinMaxScaler()),\n",
    "        (\"neurones\", MLPRegressor()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln_gs = GridSearchCV(\n",
    "    pln,\n",
    "    {\n",
    "        \"neurones__alpha\": 10.0 ** -np.arange(1, 7),\n",
    "        'neurones__hidden_layer_sizes': ((25,), (50, ), (100,), (20, 20)),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_neurones__alpha</th>\n",
       "      <th>param_neurones__hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.276860</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(25,)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-7.265260</td>\n",
       "      <td>-7.803490</td>\n",
       "      <td>-7.418769</td>\n",
       "      <td>-8.308542</td>\n",
       "      <td>-7.885371</td>\n",
       "      <td>-7.736286</td>\n",
       "      <td>0.367941</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.557897</td>\n",
       "      <td>0.022063</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-7.169583</td>\n",
       "      <td>-7.742505</td>\n",
       "      <td>-7.361349</td>\n",
       "      <td>-8.244487</td>\n",
       "      <td>-7.828612</td>\n",
       "      <td>-7.669307</td>\n",
       "      <td>0.375801</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.553783</td>\n",
       "      <td>0.028081</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-7.104080</td>\n",
       "      <td>-7.622723</td>\n",
       "      <td>-7.283237</td>\n",
       "      <td>-8.092599</td>\n",
       "      <td>-7.723177</td>\n",
       "      <td>-7.565163</td>\n",
       "      <td>0.345991</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.179531</td>\n",
       "      <td>0.012099</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-6.613025</td>\n",
       "      <td>-7.484969</td>\n",
       "      <td>-6.646206</td>\n",
       "      <td>-7.246459</td>\n",
       "      <td>-7.058851</td>\n",
       "      <td>-7.009902</td>\n",
       "      <td>0.338771</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.270261</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(25,)</td>\n",
       "      <td>{'neurones__alpha': 0.01, 'neurones__hidden_la...</td>\n",
       "      <td>-7.257464</td>\n",
       "      <td>-7.810626</td>\n",
       "      <td>-7.397353</td>\n",
       "      <td>-8.338590</td>\n",
       "      <td>-7.873456</td>\n",
       "      <td>-7.735498</td>\n",
       "      <td>0.382428</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.276860      0.008912         0.000604        0.000493   \n",
       "1       0.557897      0.022063         0.000923        0.000146   \n",
       "2       0.553783      0.028081         0.001001        0.000010   \n",
       "3       0.179531      0.012099         0.000395        0.000483   \n",
       "4       0.270261      0.001663         0.000817        0.000409   \n",
       "\n",
       "  param_neurones__alpha param_neurones__hidden_layer_sizes  \\\n",
       "0                   0.1                              (25,)   \n",
       "1                   0.1                              (50,)   \n",
       "2                   0.1                             (100,)   \n",
       "3                   0.1                           (20, 20)   \n",
       "4                  0.01                              (25,)   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -7.265260   \n",
       "1  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -7.169583   \n",
       "2  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -7.104080   \n",
       "3  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -6.613025   \n",
       "4  {'neurones__alpha': 0.01, 'neurones__hidden_la...          -7.257464   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -7.803490          -7.418769          -8.308542          -7.885371   \n",
       "1          -7.742505          -7.361349          -8.244487          -7.828612   \n",
       "2          -7.622723          -7.283237          -8.092599          -7.723177   \n",
       "3          -7.484969          -6.646206          -7.246459          -7.058851   \n",
       "4          -7.810626          -7.397353          -8.338590          -7.873456   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -7.736286        0.367941               23  \n",
       "1        -7.669307        0.375801               14  \n",
       "2        -7.565163        0.345991               10  \n",
       "3        -7.009902        0.338771                3  \n",
       "4        -7.735498        0.382428               22  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln_gs.fit(X_tr, y_tr)\n",
    "\n",
    "pln_df = pd.DataFrame(pln_gs.cv_results_)\n",
    "pln_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.913083383837953"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln_gs.best_params_\n",
    "\n",
    "pln_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neurones__alpha': 0.0001, 'neurones__hidden_layer_sizes': (20, 20)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai = en_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0629e+04, 2.0210e+03, 1.1000e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [5.1040e+03, 2.0220e+03, 1.8100e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [8.9000e+03, 2.0210e+03, 1.3100e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       ...,\n",
       "       [3.0000e+01, 2.0220e+03, 1.1000e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [3.0000e+01, 2.0220e+03, 1.1000e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [3.0000e+01, 2.0220e+03, 1.1000e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prix_prédits = essai.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prix_reels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([22990, 42790, 23990, 17290, 17490, 26980, 37390, 17990, 18490,\n",
       "        13790, 12280, 29790, 33790, 11480, 27290, 14990, 10990, 13990,\n",
       "        31990, 23990, 10990, 23990, 19990, 11990, 24990, 23490, 34990,\n",
       "        22990,  9790, 13990, 15990, 13790, 26790, 19390, 26790, 13990,\n",
       "        24990, 26990, 27990, 22890, 14990, 21990, 26990, 15790, 15790,\n",
       "        15790, 14990, 27790, 10990, 26990, 15490, 27990,  7490, 21990,\n",
       "         9990, 18990, 11990, 18890, 19990, 19890, 13990, 22990, 13990,\n",
       "        27990, 25990, 15980, 27490, 45990, 27490, 22990, 24990, 16990,\n",
       "        15990, 20990, 26990, 26990, 43990, 14490, 24990, 19990, 18990,\n",
       "        16490, 17990, 20990, 23990, 19490, 31990, 20490, 18990, 19790,\n",
       "        18990,  9790, 33990, 17490, 16990, 36990, 13990, 27490, 13990,\n",
       "        32990, 34990, 26890, 11990, 39000, 27900, 11500, 26900, 30900,\n",
       "        31900, 29500, 49000, 18900, 18800, 17900, 22400, 25900, 16500,\n",
       "        30500, 28500, 27900, 22500, 36500, 44990, 23900, 18900, 40900,\n",
       "        26900, 21000, 29500, 14900, 29500, 30900, 21000, 19500, 19300,\n",
       "        21100, 15500, 19800, 19900, 32900, 27900, 17500, 28500, 27490,\n",
       "        13500, 19500, 17900, 13490, 10990, 12490, 18990, 24990, 15990,\n",
       "        10990, 13490, 12490, 15990, 16490, 23990, 32990, 14990, 23990,\n",
       "        24990, 14490, 17490, 27990, 12990, 17490, 12990, 17490, 23990,\n",
       "        22990, 41990, 24990, 39790, 22900, 18490, 23490, 16490, 17990,\n",
       "        29490, 26490, 16490, 24490, 27990, 25490, 24990, 24990, 24990,\n",
       "        18990, 16990,  9990, 18490, 22990, 18990, 24990, 15990, 19990,\n",
       "        16990, 18990, 22990, 13850, 29490, 24990, 13490, 17990, 35990,\n",
       "        27990, 11990, 34900, 26990, 25990, 18990, 19990, 15990, 18990,\n",
       "        11990, 27990, 26990, 16490, 14200, 14500, 28990, 18990, 27900,\n",
       "        28900, 31500, 15499, 24990, 15990, 23490, 26499, 22490, 24995,\n",
       "        25999, 29100, 16500, 26890, 18995, 15990, 18990, 18300, 28900,\n",
       "        26990, 24990, 16990, 15990, 13500, 15980, 17990, 14900, 11500,\n",
       "        14900, 18990, 24300, 18340, 20150, 31350, 23990, 14990,  9600,\n",
       "        14900, 20990, 28900, 28900, 28900, 28900, 27900, 24300, 14500,\n",
       "        29900, 23195, 13450, 39990, 29250, 16150, 14050, 29250, 18250,\n",
       "        28850, 21350, 19950, 27250, 26850, 21250, 22450, 29650, 28250,\n",
       "        25990, 37188, 13790, 15990, 18790, 18990, 25490, 17990, 31990,\n",
       "        10790, 11990,  8990, 36290, 20999, 13899, 12299, 17999, 20999,\n",
       "        18499, 18490, 13899, 14499, 14199, 13999, 25499, 14499, 14499,\n",
       "        13999, 14499, 24999, 14499, 28799, 29499, 38999, 13285, 13200,\n",
       "        19485, 22295, 18490, 13995, 11325, 34985, 11485, 16990, 12490,\n",
       "         9890, 25490, 12490,  8490, 37980, 14980, 11780, 39990, 14780,\n",
       "        49990, 17980, 31390, 25250, 14980, 14950, 23950, 13980, 15980,\n",
       "        20950, 47490, 28480, 26490, 23880, 30990, 39590, 24780, 36990,\n",
       "        23900, 24950, 28450, 38250, 33213, 25890, 28600, 16950, 28450,\n",
       "        13850, 15880, 25480,  9950, 24480, 14280, 17480, 17950, 12480,\n",
       "        18280, 22780, 21250, 19480, 31780, 17280, 23980, 14350, 17440,\n",
       "        16780, 16280, 19480, 23480, 23250, 27242, 25480, 17480, 21980,\n",
       "        15450, 18834, 18280, 15250, 19780, 15750, 20250, 37480, 27980,\n",
       "        27450, 16200, 16250, 16200, 16250, 20250, 35780, 15980, 20150,\n",
       "        15700, 20150, 16600, 44980, 16980, 17280, 20980, 15280, 15480,\n",
       "        37980, 33890, 49990, 26780, 17980, 40980, 15280, 34490, 29990,\n",
       "        31490, 29990, 20388, 28990, 13990, 20990, 12490, 19490, 16990,\n",
       "        26990, 26990, 31990, 12490, 18799, 28990, 13890, 11490, 22490,\n",
       "        15990, 12490, 13490, 12990, 11890, 11990, 19990, 36490, 21990,\n",
       "        31990, 27390, 27990, 27390, 31990, 27990, 15990, 11990, 13490,\n",
       "        26490, 14490, 19990, 15990, 15990, 11990, 15990, 19990, 27990,\n",
       "        17990, 15990, 19990, 15990, 29990,  9990, 20990, 20990, 14490,\n",
       "        14900, 20990, 45900, 15490, 18490, 21490, 18490, 18490, 15990,\n",
       "        11290, 16990, 11490, 18990, 11490, 10890, 14990, 18490, 13990,\n",
       "        21990, 14990, 15990, 15490, 38490, 33990, 20490, 45990, 12990,\n",
       "        13990, 38990, 12990, 24990, 26490, 19990, 18990, 23990, 12490,\n",
       "        15490, 48990, 27990, 15490, 11990, 37290, 28990, 17490, 29490,\n",
       "        19900,  8990, 14700, 13900, 17290, 28900, 22900, 25900, 21490,\n",
       "        28900, 31900, 20490, 17900, 28900, 13900, 21900, 20900, 13490,\n",
       "        29900, 15900, 14900, 21790, 18900, 15490, 27489, 15489, 19889,\n",
       "        13989, 16989, 15489, 32960, 29000, 13490, 23950, 11378, 16989,\n",
       "        17389, 35489, 19990, 25989, 34689, 15889, 11989, 16989, 11999,\n",
       "        13889, 18989, 15889, 36849, 13999, 11999, 32989, 32989, 21589,\n",
       "        22979, 32489, 11399, 36790, 12879, 13799, 15799, 21489, 16989,\n",
       "        19989, 17579, 22689, 22689, 22689, 22689], dtype=int64),\n",
       " array([22032.16884637, 41493.97568329, 24969.01072275, 17015.3782826 ,\n",
       "        17126.27646582, 27114.10183904, 33576.76423118, 19583.24971472,\n",
       "        18458.24464883, 16119.24664827, 11553.52919896, 28559.24319469,\n",
       "        33350.51359537, 12961.59346727, 27344.15342119, 15604.64210085,\n",
       "        10332.40695653, 15868.1933297 , 35350.51151928, 24947.14173634,\n",
       "         9507.27973956, 24999.61094805, 20437.72395714, 16183.5785166 ,\n",
       "        27850.37764051, 24385.08499141, 37405.14574699, 23939.98606217,\n",
       "        11153.80307871, 11257.19463506, 16320.25719375, 12501.68882293,\n",
       "        26683.83113381, 18697.69449216, 27204.38577592, 13768.77143029,\n",
       "        26995.87023121, 31328.11651601, 30319.07857488, 22677.05061951,\n",
       "        15929.1929971 , 21785.09065053, 27350.29152896, 17481.89883403,\n",
       "        16997.2907344 , 17008.89317683, 16604.82248709, 28832.39067338,\n",
       "        11051.50005201, 28996.1101355 , 15901.17853315, 26686.1155067 ,\n",
       "         6650.5662699 , 23074.67351689, 11616.04192409, 20669.03596089,\n",
       "        11358.93640592, 20117.74131627, 20718.46461345, 22993.67238777,\n",
       "        14660.63925068, 23948.73624228, 13376.76084315, 29987.95737348,\n",
       "        27141.23274189, 16325.18439697, 25271.28647523, 46985.94534936,\n",
       "        28155.12638628, 23556.00680641, 26584.09624549, 16308.80218015,\n",
       "        14859.24238181, 21145.08940523, 26632.84303938, 24988.96406895,\n",
       "        40162.16637192, 13142.24710183, 24169.2926553 , 17940.32029912,\n",
       "        15902.2504726 , 15292.82517551, 18265.28574553, 20727.08287248,\n",
       "        23285.67704694, 15707.66116519, 28636.74769687, 18761.75969968,\n",
       "        14814.80873764, 17827.14308292, 15071.39516383,  4902.57402336,\n",
       "        30957.8890345 , 16162.94362214, 14104.33457989, 32241.5444019 ,\n",
       "        11940.93630392, 25277.3932859 , 13501.36295835, 30394.90920751,\n",
       "        32529.28850541, 23815.71941918, 12352.15895519, 33273.46400833,\n",
       "        29367.34218642,  7847.64494393, 25896.366726  , 28236.80585252,\n",
       "        29826.61015542, 26864.74683905, 46426.43789215, 17374.84490606,\n",
       "        16973.29088805, 18159.82012588, 19627.88377635, 24988.59238854,\n",
       "        18394.38708687, 29671.0862962 , 29974.49128361, 26528.60224143,\n",
       "        23105.87563573, 33013.28976272, 40992.68196919, 26710.57804033,\n",
       "        17374.84490606, 39811.56337394, 26769.88229728, 19892.59706936,\n",
       "        29213.24688099, 14401.38251957, 29807.33871942, 33284.30689278,\n",
       "        19030.31293024, 18374.52361096, 16718.91785975, 23105.87563573,\n",
       "        14556.50314409, 20783.48636758, 16767.55085198, 28680.73695063,\n",
       "        24227.70823932, 14483.97634384, 26335.98956639, 26766.84908071,\n",
       "        11837.55701326, 15883.42103534, 18980.83950275, 16300.94629872,\n",
       "        10782.14395941, 12550.02357793, 19667.49434723, 26319.09136745,\n",
       "        17739.97232954,  5415.99405466, 13348.09580941, 12804.52240446,\n",
       "        16729.67294472, 16935.62137146, 24301.92333544, 33750.37496652,\n",
       "        16163.44502529, 21408.28605127, 25411.03951085, 16409.10079139,\n",
       "        20527.16054165, 27587.89320749, 12070.82080825, 19445.49869893,\n",
       "        12070.82080825, 19445.49869893, 23855.83823108, 21972.213002  ,\n",
       "        41590.01322558, 24922.55460572, 40608.62028196, 21684.87692947,\n",
       "        19785.00624329, 24008.59340863, 14361.71637686, 16431.71071812,\n",
       "        27721.05898276, 28182.28720894, 17407.6352632 , 20188.75169754,\n",
       "        29213.42872829, 27613.29706664, 23740.66667812, 23892.34586549,\n",
       "        23790.13337879, 17721.90640933, 18354.03191447,  9721.06973939,\n",
       "        17744.53795967, 22580.21748946, 19790.49884426, 23187.57966636,\n",
       "        13803.70561034, 21341.79174113, 16754.22688999, 18694.82333065,\n",
       "        22743.55996813, 15857.62451575, 28010.40615463, 23095.03802971,\n",
       "        13084.78054452, 17749.76964721, 33612.1273641 , 27076.94358413,\n",
       "        12283.00674533, 32253.70464586, 27120.06397257, 25817.53255569,\n",
       "        18263.92149185, 22166.9350696 , 18773.52877903, 19905.92169013,\n",
       "        14192.75123877, 27961.84294222, 29890.97742311, 17480.48237594,\n",
       "        14772.02958685, 17044.13780605, 30257.86335952, 20402.85341452,\n",
       "        26897.8487709 , 26993.93366841, 30312.26793558, 15226.82177855,\n",
       "        26927.60914573, 15149.92589355, 23410.05318677, 26804.80943896,\n",
       "        23034.91999699, 25744.93674696, 27250.89428199, 29331.58262836,\n",
       "        17840.2253371 , 27112.4414427 , 20049.56946381, 15204.18641774,\n",
       "        20898.29371258, 19932.85028245, 28464.70939286, 28150.2745974 ,\n",
       "        26600.93438933, 16425.25525467, 14760.18758514, 13360.43137631,\n",
       "        16094.72225145, 17907.90046451, 17565.81231081, 11097.24832555,\n",
       "        17548.72128783, 16763.85918125, 23850.42255827, 18775.96613278,\n",
       "        20150.36773632, 33459.01546071, 23609.93550849, 12196.93891702,\n",
       "        12413.30617384, 16770.80556898, 21845.36463768, 26828.99834904,\n",
       "        26890.90120058, 26953.18307168, 26970.86773495, 27072.88970828,\n",
       "        24247.79193946, 15912.29543603, 27800.67582361, 19694.99121251,\n",
       "        12804.92965217, 36188.50519352, 27285.8405607 , 13214.93599921,\n",
       "        12524.53215897, 26445.18455212, 16919.3208199 , 29354.92888488,\n",
       "        19648.65952786, 22465.8382469 , 28140.84455085, 25177.54374892,\n",
       "        21472.27789784, 25488.27989623, 26511.11189397, 27220.68232053,\n",
       "        25046.13575117, 35741.5751152 , 13751.64897978, 14295.7714834 ,\n",
       "        17391.00123279, 19175.30466713, 23227.9439873 , 18468.98701533,\n",
       "        26275.76498031, 10716.84541485, 11969.23671064,  6737.20406084,\n",
       "        39883.0557719 , 22156.14441774, 14812.0474643 , 10008.30855428,\n",
       "        20337.84333505, 21613.73982728, 18149.14933876, 18248.2874153 ,\n",
       "        14509.14712572, 15670.83663141, 15085.57330775, 14777.240137  ,\n",
       "        27152.95704157, 15443.23422777, 15442.95632495, 14691.64607068,\n",
       "        15352.01262948, 24988.75023303, 15315.4684096 , 28583.48961142,\n",
       "        28632.02895614, 33529.25597384, 13994.70292254, 15593.27424773,\n",
       "        22826.93574239, 22127.83913393, 20905.85797306, 12580.58965014,\n",
       "         9349.39697002, 32412.63175153, 14143.77192575, 19471.06487019,\n",
       "        11381.37463788,  8398.04313168, 27228.0597585 , 18557.65322095,\n",
       "        10793.9776733 , 34116.51486406, 16196.15592088, 10829.27268464,\n",
       "        41784.44265501, 14288.85991997, 47211.2692821 , 17620.17805374,\n",
       "        29015.23940603, 26527.24057421, 16015.49374343, 15855.9080532 ,\n",
       "        25661.3236766 , 15511.06330186, 15739.69887159, 25223.50115704,\n",
       "        42227.63676511, 27260.59853917, 27093.25912808, 20165.88202077,\n",
       "        37816.38526655, 33815.48123374, 23903.26177152, 35745.63802905,\n",
       "        26771.7675065 , 27232.0337484 , 28689.92134502, 32794.62429307,\n",
       "        33695.91066041, 28788.74003233, 32520.10797563, 16870.83656911,\n",
       "        28766.89317526, 14025.74043849, 16084.16571463, 28368.2454253 ,\n",
       "         7381.80809545, 23446.35743253, 11536.49149595, 17575.89664829,\n",
       "        17221.28020771, 12173.16861696, 17421.90156122, 23246.6736923 ,\n",
       "        24065.65247669, 19446.31953463, 32790.33396716, 15557.08721146,\n",
       "        21591.70398464, 16290.68902283, 18341.68233261, 17585.83775694,\n",
       "        16914.67466894, 19909.96131916, 24834.55330663, 25310.99381372,\n",
       "        26538.8151698 , 27534.34759068, 17352.88572415, 22054.7485284 ,\n",
       "        16798.83800102, 19062.90589496, 19855.78031639, 16946.33491889,\n",
       "        22787.00394071, 17743.72526103, 22259.3903808 , 35922.43211305,\n",
       "        27921.16518744, 27976.23307591, 17681.0203421 , 17436.33150706,\n",
       "        17802.64065733, 17565.90369351, 22092.44026604, 39433.08055442,\n",
       "        17729.93123714, 21974.33157062, 17215.43201399, 20586.05037286,\n",
       "        16957.38155569, 46246.47519741, 20995.89838207, 19541.27648578,\n",
       "        22940.30266076, 16339.28914393, 16813.51093254, 36069.53234707,\n",
       "        29524.70014592, 47298.61765475, 25999.50451873, 19340.0237333 ,\n",
       "        35673.67302849, 17201.77399691, 34628.46859955, 29058.73801757,\n",
       "        29872.77022436, 30281.19260837, 21177.38626541, 28803.15680668,\n",
       "        13163.91275458, 22468.72975752, 13284.40144628, 19273.68174323,\n",
       "        17545.16781817, 23113.46873045, 20556.82859907, 33744.92857918,\n",
       "        14438.75190919, 20443.57817332, 29517.95222103, 13110.30164298,\n",
       "        10771.33901668, 22264.76101158, 16907.7419308 , 12767.03606919,\n",
       "        15004.76080173, 13223.36217979,  9559.61118202, 10128.76333836,\n",
       "        19482.01231752, 33286.21423001, 20716.54356512, 29462.87780285,\n",
       "        25204.63775844, 27452.1456553 , 25204.63775844, 29480.71883126,\n",
       "        27512.83747592, 16503.34197927, 14216.95786928, 11139.1274517 ,\n",
       "        27398.585185  , 15615.56788581, 20062.97861616, 15737.710729  ,\n",
       "        15841.22952675,  9553.37763458, 17114.54817843, 23097.12685309,\n",
       "        28727.22282806, 18591.29706113, 15974.55340117, 20503.62089186,\n",
       "        15546.07904296, 30226.67386925,  9162.36256032, 21472.59852422,\n",
       "        21464.92304344, 16063.35620498, 14302.48028767, 21640.78637447,\n",
       "        45513.24017073, 15925.02420759, 20788.51351038, 23805.34340449,\n",
       "        20915.93195002, 17927.15667457, 16538.57212523,  9355.5108319 ,\n",
       "        14672.32623213, 14015.58925336, 19037.7505824 , 13227.31792499,\n",
       "        12165.55273538, 18450.18746534, 20540.38456504, 13804.06295005,\n",
       "        19972.76177065, 14209.38257546, 16771.0869259 , 15168.42518227,\n",
       "        36352.83121308, 33874.96767658, 21608.38395494, 41500.74121545,\n",
       "        11762.62001974, 15935.36513524, 33804.66064334, 12817.50796478,\n",
       "        27078.34700164, 29584.85602916, 23756.32365274, 18974.26749387,\n",
       "        23041.19392526, 12893.74376409, 15760.14086834, 47190.00021904,\n",
       "        28029.42520134, 16054.44437391, 13918.51043058, 35468.40416891,\n",
       "        28206.86199364, 17762.85146388, 28702.87589289, 20363.02185447,\n",
       "         7938.69261812, 13665.91772598, 15031.39659026, 16452.6704087 ,\n",
       "        27110.57751781, 21437.41618919, 28892.45528113, 21291.08738605,\n",
       "        26991.62990163, 28838.47010812, 20516.42360344, 17354.83061311,\n",
       "        26395.28150284, 13856.53038285, 23392.13023915, 21077.54701866,\n",
       "        13550.80341177, 27911.85372663, 14609.13951443, 15313.38526179,\n",
       "        21788.10076555, 19626.89758566, 15605.32140116, 28274.11862797,\n",
       "        16514.19094459, 19751.48057943, 15908.09301886, 17723.45047011,\n",
       "        15707.63492943, 35812.61260692, 29718.10393244, 13480.76349607,\n",
       "        24815.34457945, 12390.58699428, 17256.2429482 , 17288.96600441,\n",
       "        33320.7085187 , 18959.63198587, 24482.37486813, 33019.72227032,\n",
       "        17806.07161166,  9178.79519879, 16881.36057539, 11887.32775948,\n",
       "        15854.50955505, 20198.77253246, 17806.07161166, 37846.75316983,\n",
       "        15296.06953979, 13798.99552229, 33695.91066041, 33695.91066041,\n",
       "        21881.75861905, 22318.68157058, 37601.16458134, 13031.92356682,\n",
       "        32732.82585253, 12844.81146571, 17969.30624957, 19802.0283495 ,\n",
       "        22558.40357678, 16853.32010235, 22011.60331406, 18157.42037493,\n",
       "        22440.42834914, 22440.42834914, 22810.93768265, 22810.93768265]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prix_reels,prix_prédits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prix_prédits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prix_reels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22032.16884637, 41493.97568329, 24969.01072275, 17015.3782826 ,\n",
       "       17126.27646582, 27114.10183904, 33576.76423118, 19583.24971472,\n",
       "       18458.24464883, 16119.24664827, 11553.52919896, 28559.24319469,\n",
       "       33350.51359537, 12961.59346727, 27344.15342119, 15604.64210085,\n",
       "       10332.40695653, 15868.1933297 , 35350.51151928, 24947.14173634,\n",
       "        9507.27973956, 24999.61094805, 20437.72395714, 16183.5785166 ,\n",
       "       27850.37764051, 24385.08499141, 37405.14574699, 23939.98606217,\n",
       "       11153.80307871, 11257.19463506, 16320.25719375, 12501.68882293,\n",
       "       26683.83113381, 18697.69449216, 27204.38577592, 13768.77143029,\n",
       "       26995.87023121, 31328.11651601, 30319.07857488, 22677.05061951,\n",
       "       15929.1929971 , 21785.09065053, 27350.29152896, 17481.89883403,\n",
       "       16997.2907344 , 17008.89317683, 16604.82248709, 28832.39067338,\n",
       "       11051.50005201, 28996.1101355 , 15901.17853315, 26686.1155067 ,\n",
       "        6650.5662699 , 23074.67351689, 11616.04192409, 20669.03596089,\n",
       "       11358.93640592, 20117.74131627, 20718.46461345, 22993.67238777,\n",
       "       14660.63925068, 23948.73624228, 13376.76084315, 29987.95737348,\n",
       "       27141.23274189, 16325.18439697, 25271.28647523, 46985.94534936,\n",
       "       28155.12638628, 23556.00680641, 26584.09624549, 16308.80218015,\n",
       "       14859.24238181, 21145.08940523, 26632.84303938, 24988.96406895,\n",
       "       40162.16637192, 13142.24710183, 24169.2926553 , 17940.32029912,\n",
       "       15902.2504726 , 15292.82517551, 18265.28574553, 20727.08287248,\n",
       "       23285.67704694, 15707.66116519, 28636.74769687, 18761.75969968,\n",
       "       14814.80873764, 17827.14308292, 15071.39516383,  4902.57402336,\n",
       "       30957.8890345 , 16162.94362214, 14104.33457989, 32241.5444019 ,\n",
       "       11940.93630392, 25277.3932859 , 13501.36295835, 30394.90920751,\n",
       "       32529.28850541, 23815.71941918, 12352.15895519, 33273.46400833,\n",
       "       29367.34218642,  7847.64494393, 25896.366726  , 28236.80585252,\n",
       "       29826.61015542, 26864.74683905, 46426.43789215, 17374.84490606,\n",
       "       16973.29088805, 18159.82012588, 19627.88377635, 24988.59238854,\n",
       "       18394.38708687, 29671.0862962 , 29974.49128361, 26528.60224143,\n",
       "       23105.87563573, 33013.28976272, 40992.68196919, 26710.57804033,\n",
       "       17374.84490606, 39811.56337394, 26769.88229728, 19892.59706936,\n",
       "       29213.24688099, 14401.38251957, 29807.33871942, 33284.30689278,\n",
       "       19030.31293024, 18374.52361096, 16718.91785975, 23105.87563573,\n",
       "       14556.50314409, 20783.48636758, 16767.55085198, 28680.73695063,\n",
       "       24227.70823932, 14483.97634384, 26335.98956639, 26766.84908071,\n",
       "       11837.55701326, 15883.42103534, 18980.83950275, 16300.94629872,\n",
       "       10782.14395941, 12550.02357793, 19667.49434723, 26319.09136745,\n",
       "       17739.97232954,  5415.99405466, 13348.09580941, 12804.52240446,\n",
       "       16729.67294472, 16935.62137146, 24301.92333544, 33750.37496652,\n",
       "       16163.44502529, 21408.28605127, 25411.03951085, 16409.10079139,\n",
       "       20527.16054165, 27587.89320749, 12070.82080825, 19445.49869893,\n",
       "       12070.82080825, 19445.49869893, 23855.83823108, 21972.213002  ,\n",
       "       41590.01322558, 24922.55460572, 40608.62028196, 21684.87692947,\n",
       "       19785.00624329, 24008.59340863, 14361.71637686, 16431.71071812,\n",
       "       27721.05898276, 28182.28720894, 17407.6352632 , 20188.75169754,\n",
       "       29213.42872829, 27613.29706664, 23740.66667812, 23892.34586549,\n",
       "       23790.13337879, 17721.90640933, 18354.03191447,  9721.06973939,\n",
       "       17744.53795967, 22580.21748946, 19790.49884426, 23187.57966636,\n",
       "       13803.70561034, 21341.79174113, 16754.22688999, 18694.82333065,\n",
       "       22743.55996813, 15857.62451575, 28010.40615463, 23095.03802971,\n",
       "       13084.78054452, 17749.76964721, 33612.1273641 , 27076.94358413,\n",
       "       12283.00674533, 32253.70464586, 27120.06397257, 25817.53255569,\n",
       "       18263.92149185, 22166.9350696 , 18773.52877903, 19905.92169013,\n",
       "       14192.75123877, 27961.84294222, 29890.97742311, 17480.48237594,\n",
       "       14772.02958685, 17044.13780605, 30257.86335952, 20402.85341452,\n",
       "       26897.8487709 , 26993.93366841, 30312.26793558, 15226.82177855,\n",
       "       26927.60914573, 15149.92589355, 23410.05318677, 26804.80943896,\n",
       "       23034.91999699, 25744.93674696, 27250.89428199, 29331.58262836,\n",
       "       17840.2253371 , 27112.4414427 , 20049.56946381, 15204.18641774,\n",
       "       20898.29371258, 19932.85028245, 28464.70939286, 28150.2745974 ,\n",
       "       26600.93438933, 16425.25525467, 14760.18758514, 13360.43137631,\n",
       "       16094.72225145, 17907.90046451, 17565.81231081, 11097.24832555,\n",
       "       17548.72128783, 16763.85918125, 23850.42255827, 18775.96613278,\n",
       "       20150.36773632, 33459.01546071, 23609.93550849, 12196.93891702,\n",
       "       12413.30617384, 16770.80556898, 21845.36463768, 26828.99834904,\n",
       "       26890.90120058, 26953.18307168, 26970.86773495, 27072.88970828,\n",
       "       24247.79193946, 15912.29543603, 27800.67582361, 19694.99121251,\n",
       "       12804.92965217, 36188.50519352, 27285.8405607 , 13214.93599921,\n",
       "       12524.53215897, 26445.18455212, 16919.3208199 , 29354.92888488,\n",
       "       19648.65952786, 22465.8382469 , 28140.84455085, 25177.54374892,\n",
       "       21472.27789784, 25488.27989623, 26511.11189397, 27220.68232053,\n",
       "       25046.13575117, 35741.5751152 , 13751.64897978, 14295.7714834 ,\n",
       "       17391.00123279, 19175.30466713, 23227.9439873 , 18468.98701533,\n",
       "       26275.76498031, 10716.84541485, 11969.23671064,  6737.20406084,\n",
       "       39883.0557719 , 22156.14441774, 14812.0474643 , 10008.30855428,\n",
       "       20337.84333505, 21613.73982728, 18149.14933876, 18248.2874153 ,\n",
       "       14509.14712572, 15670.83663141, 15085.57330775, 14777.240137  ,\n",
       "       27152.95704157, 15443.23422777, 15442.95632495, 14691.64607068,\n",
       "       15352.01262948, 24988.75023303, 15315.4684096 , 28583.48961142,\n",
       "       28632.02895614, 33529.25597384, 13994.70292254, 15593.27424773,\n",
       "       22826.93574239, 22127.83913393, 20905.85797306, 12580.58965014,\n",
       "        9349.39697002, 32412.63175153, 14143.77192575, 19471.06487019,\n",
       "       11381.37463788,  8398.04313168, 27228.0597585 , 18557.65322095,\n",
       "       10793.9776733 , 34116.51486406, 16196.15592088, 10829.27268464,\n",
       "       41784.44265501, 14288.85991997, 47211.2692821 , 17620.17805374,\n",
       "       29015.23940603, 26527.24057421, 16015.49374343, 15855.9080532 ,\n",
       "       25661.3236766 , 15511.06330186, 15739.69887159, 25223.50115704,\n",
       "       42227.63676511, 27260.59853917, 27093.25912808, 20165.88202077,\n",
       "       37816.38526655, 33815.48123374, 23903.26177152, 35745.63802905,\n",
       "       26771.7675065 , 27232.0337484 , 28689.92134502, 32794.62429307,\n",
       "       33695.91066041, 28788.74003233, 32520.10797563, 16870.83656911,\n",
       "       28766.89317526, 14025.74043849, 16084.16571463, 28368.2454253 ,\n",
       "        7381.80809545, 23446.35743253, 11536.49149595, 17575.89664829,\n",
       "       17221.28020771, 12173.16861696, 17421.90156122, 23246.6736923 ,\n",
       "       24065.65247669, 19446.31953463, 32790.33396716, 15557.08721146,\n",
       "       21591.70398464, 16290.68902283, 18341.68233261, 17585.83775694,\n",
       "       16914.67466894, 19909.96131916, 24834.55330663, 25310.99381372,\n",
       "       26538.8151698 , 27534.34759068, 17352.88572415, 22054.7485284 ,\n",
       "       16798.83800102, 19062.90589496, 19855.78031639, 16946.33491889,\n",
       "       22787.00394071, 17743.72526103, 22259.3903808 , 35922.43211305,\n",
       "       27921.16518744, 27976.23307591, 17681.0203421 , 17436.33150706,\n",
       "       17802.64065733, 17565.90369351, 22092.44026604, 39433.08055442,\n",
       "       17729.93123714, 21974.33157062, 17215.43201399, 20586.05037286,\n",
       "       16957.38155569, 46246.47519741, 20995.89838207, 19541.27648578,\n",
       "       22940.30266076, 16339.28914393, 16813.51093254, 36069.53234707,\n",
       "       29524.70014592, 47298.61765475, 25999.50451873, 19340.0237333 ,\n",
       "       35673.67302849, 17201.77399691, 34628.46859955, 29058.73801757,\n",
       "       29872.77022436, 30281.19260837, 21177.38626541, 28803.15680668,\n",
       "       13163.91275458, 22468.72975752, 13284.40144628, 19273.68174323,\n",
       "       17545.16781817, 23113.46873045, 20556.82859907, 33744.92857918,\n",
       "       14438.75190919, 20443.57817332, 29517.95222103, 13110.30164298,\n",
       "       10771.33901668, 22264.76101158, 16907.7419308 , 12767.03606919,\n",
       "       15004.76080173, 13223.36217979,  9559.61118202, 10128.76333836,\n",
       "       19482.01231752, 33286.21423001, 20716.54356512, 29462.87780285,\n",
       "       25204.63775844, 27452.1456553 , 25204.63775844, 29480.71883126,\n",
       "       27512.83747592, 16503.34197927, 14216.95786928, 11139.1274517 ,\n",
       "       27398.585185  , 15615.56788581, 20062.97861616, 15737.710729  ,\n",
       "       15841.22952675,  9553.37763458, 17114.54817843, 23097.12685309,\n",
       "       28727.22282806, 18591.29706113, 15974.55340117, 20503.62089186,\n",
       "       15546.07904296, 30226.67386925,  9162.36256032, 21472.59852422,\n",
       "       21464.92304344, 16063.35620498, 14302.48028767, 21640.78637447,\n",
       "       45513.24017073, 15925.02420759, 20788.51351038, 23805.34340449,\n",
       "       20915.93195002, 17927.15667457, 16538.57212523,  9355.5108319 ,\n",
       "       14672.32623213, 14015.58925336, 19037.7505824 , 13227.31792499,\n",
       "       12165.55273538, 18450.18746534, 20540.38456504, 13804.06295005,\n",
       "       19972.76177065, 14209.38257546, 16771.0869259 , 15168.42518227,\n",
       "       36352.83121308, 33874.96767658, 21608.38395494, 41500.74121545,\n",
       "       11762.62001974, 15935.36513524, 33804.66064334, 12817.50796478,\n",
       "       27078.34700164, 29584.85602916, 23756.32365274, 18974.26749387,\n",
       "       23041.19392526, 12893.74376409, 15760.14086834, 47190.00021904,\n",
       "       28029.42520134, 16054.44437391, 13918.51043058, 35468.40416891,\n",
       "       28206.86199364, 17762.85146388, 28702.87589289, 20363.02185447,\n",
       "        7938.69261812, 13665.91772598, 15031.39659026, 16452.6704087 ,\n",
       "       27110.57751781, 21437.41618919, 28892.45528113, 21291.08738605,\n",
       "       26991.62990163, 28838.47010812, 20516.42360344, 17354.83061311,\n",
       "       26395.28150284, 13856.53038285, 23392.13023915, 21077.54701866,\n",
       "       13550.80341177, 27911.85372663, 14609.13951443, 15313.38526179,\n",
       "       21788.10076555, 19626.89758566, 15605.32140116, 28274.11862797,\n",
       "       16514.19094459, 19751.48057943, 15908.09301886, 17723.45047011,\n",
       "       15707.63492943, 35812.61260692, 29718.10393244, 13480.76349607,\n",
       "       24815.34457945, 12390.58699428, 17256.2429482 , 17288.96600441,\n",
       "       33320.7085187 , 18959.63198587, 24482.37486813, 33019.72227032,\n",
       "       17806.07161166,  9178.79519879, 16881.36057539, 11887.32775948,\n",
       "       15854.50955505, 20198.77253246, 17806.07161166, 37846.75316983,\n",
       "       15296.06953979, 13798.99552229, 33695.91066041, 33695.91066041,\n",
       "       21881.75861905, 22318.68157058, 37601.16458134, 13031.92356682,\n",
       "       32732.82585253, 12844.81146571, 17969.30624957, 19802.0283495 ,\n",
       "       22558.40357678, 16853.32010235, 22011.60331406, 18157.42037493,\n",
       "       22440.42834914, 22440.42834914, 22810.93768265, 22810.93768265])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prix_prédits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22990, 42790, 23990, 17290, 17490, 26980, 37390, 17990, 18490,\n",
       "       13790, 12280, 29790, 33790, 11480, 27290, 14990, 10990, 13990,\n",
       "       31990, 23990, 10990, 23990, 19990, 11990, 24990, 23490, 34990,\n",
       "       22990,  9790, 13990, 15990, 13790, 26790, 19390, 26790, 13990,\n",
       "       24990, 26990, 27990, 22890, 14990, 21990, 26990, 15790, 15790,\n",
       "       15790, 14990, 27790, 10990, 26990, 15490, 27990,  7490, 21990,\n",
       "        9990, 18990, 11990, 18890, 19990, 19890, 13990, 22990, 13990,\n",
       "       27990, 25990, 15980, 27490, 45990, 27490, 22990, 24990, 16990,\n",
       "       15990, 20990, 26990, 26990, 43990, 14490, 24990, 19990, 18990,\n",
       "       16490, 17990, 20990, 23990, 19490, 31990, 20490, 18990, 19790,\n",
       "       18990,  9790, 33990, 17490, 16990, 36990, 13990, 27490, 13990,\n",
       "       32990, 34990, 26890, 11990, 39000, 27900, 11500, 26900, 30900,\n",
       "       31900, 29500, 49000, 18900, 18800, 17900, 22400, 25900, 16500,\n",
       "       30500, 28500, 27900, 22500, 36500, 44990, 23900, 18900, 40900,\n",
       "       26900, 21000, 29500, 14900, 29500, 30900, 21000, 19500, 19300,\n",
       "       21100, 15500, 19800, 19900, 32900, 27900, 17500, 28500, 27490,\n",
       "       13500, 19500, 17900, 13490, 10990, 12490, 18990, 24990, 15990,\n",
       "       10990, 13490, 12490, 15990, 16490, 23990, 32990, 14990, 23990,\n",
       "       24990, 14490, 17490, 27990, 12990, 17490, 12990, 17490, 23990,\n",
       "       22990, 41990, 24990, 39790, 22900, 18490, 23490, 16490, 17990,\n",
       "       29490, 26490, 16490, 24490, 27990, 25490, 24990, 24990, 24990,\n",
       "       18990, 16990,  9990, 18490, 22990, 18990, 24990, 15990, 19990,\n",
       "       16990, 18990, 22990, 13850, 29490, 24990, 13490, 17990, 35990,\n",
       "       27990, 11990, 34900, 26990, 25990, 18990, 19990, 15990, 18990,\n",
       "       11990, 27990, 26990, 16490, 14200, 14500, 28990, 18990, 27900,\n",
       "       28900, 31500, 15499, 24990, 15990, 23490, 26499, 22490, 24995,\n",
       "       25999, 29100, 16500, 26890, 18995, 15990, 18990, 18300, 28900,\n",
       "       26990, 24990, 16990, 15990, 13500, 15980, 17990, 14900, 11500,\n",
       "       14900, 18990, 24300, 18340, 20150, 31350, 23990, 14990,  9600,\n",
       "       14900, 20990, 28900, 28900, 28900, 28900, 27900, 24300, 14500,\n",
       "       29900, 23195, 13450, 39990, 29250, 16150, 14050, 29250, 18250,\n",
       "       28850, 21350, 19950, 27250, 26850, 21250, 22450, 29650, 28250,\n",
       "       25990, 37188, 13790, 15990, 18790, 18990, 25490, 17990, 31990,\n",
       "       10790, 11990,  8990, 36290, 20999, 13899, 12299, 17999, 20999,\n",
       "       18499, 18490, 13899, 14499, 14199, 13999, 25499, 14499, 14499,\n",
       "       13999, 14499, 24999, 14499, 28799, 29499, 38999, 13285, 13200,\n",
       "       19485, 22295, 18490, 13995, 11325, 34985, 11485, 16990, 12490,\n",
       "        9890, 25490, 12490,  8490, 37980, 14980, 11780, 39990, 14780,\n",
       "       49990, 17980, 31390, 25250, 14980, 14950, 23950, 13980, 15980,\n",
       "       20950, 47490, 28480, 26490, 23880, 30990, 39590, 24780, 36990,\n",
       "       23900, 24950, 28450, 38250, 33213, 25890, 28600, 16950, 28450,\n",
       "       13850, 15880, 25480,  9950, 24480, 14280, 17480, 17950, 12480,\n",
       "       18280, 22780, 21250, 19480, 31780, 17280, 23980, 14350, 17440,\n",
       "       16780, 16280, 19480, 23480, 23250, 27242, 25480, 17480, 21980,\n",
       "       15450, 18834, 18280, 15250, 19780, 15750, 20250, 37480, 27980,\n",
       "       27450, 16200, 16250, 16200, 16250, 20250, 35780, 15980, 20150,\n",
       "       15700, 20150, 16600, 44980, 16980, 17280, 20980, 15280, 15480,\n",
       "       37980, 33890, 49990, 26780, 17980, 40980, 15280, 34490, 29990,\n",
       "       31490, 29990, 20388, 28990, 13990, 20990, 12490, 19490, 16990,\n",
       "       26990, 26990, 31990, 12490, 18799, 28990, 13890, 11490, 22490,\n",
       "       15990, 12490, 13490, 12990, 11890, 11990, 19990, 36490, 21990,\n",
       "       31990, 27390, 27990, 27390, 31990, 27990, 15990, 11990, 13490,\n",
       "       26490, 14490, 19990, 15990, 15990, 11990, 15990, 19990, 27990,\n",
       "       17990, 15990, 19990, 15990, 29990,  9990, 20990, 20990, 14490,\n",
       "       14900, 20990, 45900, 15490, 18490, 21490, 18490, 18490, 15990,\n",
       "       11290, 16990, 11490, 18990, 11490, 10890, 14990, 18490, 13990,\n",
       "       21990, 14990, 15990, 15490, 38490, 33990, 20490, 45990, 12990,\n",
       "       13990, 38990, 12990, 24990, 26490, 19990, 18990, 23990, 12490,\n",
       "       15490, 48990, 27990, 15490, 11990, 37290, 28990, 17490, 29490,\n",
       "       19900,  8990, 14700, 13900, 17290, 28900, 22900, 25900, 21490,\n",
       "       28900, 31900, 20490, 17900, 28900, 13900, 21900, 20900, 13490,\n",
       "       29900, 15900, 14900, 21790, 18900, 15490, 27489, 15489, 19889,\n",
       "       13989, 16989, 15489, 32960, 29000, 13490, 23950, 11378, 16989,\n",
       "       17389, 35489, 19990, 25989, 34689, 15889, 11989, 16989, 11999,\n",
       "       13889, 18989, 15889, 36849, 13999, 11999, 32989, 32989, 21589,\n",
       "       22979, 32489, 11399, 36790, 12879, 13799, 15799, 21489, 16989,\n",
       "       19989, 17579, 22689, 22689, 22689, 22689], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prix_reels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif : maximiser le surplus de l'acheteur, i.e, si l'acheteur à un budget R, et n contraintes, quel véhicule maximiserait son surplus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_finale = conversion_df.data_frame_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_finale['prix_predits'] = prix_prédits\n",
    "data_finale['surplus_conso'] = data_finale['prix'] - data_finale['prix_predits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prix</th>\n",
       "      <th>kilometrage</th>\n",
       "      <th>date_mise_circulation</th>\n",
       "      <th>puissance</th>\n",
       "      <th>nb_places</th>\n",
       "      <th>puissance_fiscale</th>\n",
       "      <th>critair</th>\n",
       "      <th>ptac</th>\n",
       "      <th>nb_portes</th>\n",
       "      <th>BERLINGO</th>\n",
       "      <th>...</th>\n",
       "      <th>SPOTICAR PREMIUM</th>\n",
       "      <th>Ex-Auto-école</th>\n",
       "      <th>Ex-Import</th>\n",
       "      <th>Ex-Loueur</th>\n",
       "      <th>Ex-Particulier</th>\n",
       "      <th>Ex-Société</th>\n",
       "      <th>Véhicule de direction</th>\n",
       "      <th>Citroen</th>\n",
       "      <th>prix_predits</th>\n",
       "      <th>surplus_conso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22990</td>\n",
       "      <td>20629.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22032.168846</td>\n",
       "      <td>957.831154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42790</td>\n",
       "      <td>5104.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>181.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41493.975683</td>\n",
       "      <td>1296.024317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23990</td>\n",
       "      <td>8900.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24969.010723</td>\n",
       "      <td>-979.010723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17290</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17015.378283</td>\n",
       "      <td>274.621717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17490</td>\n",
       "      <td>37377.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17126.276466</td>\n",
       "      <td>363.723534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>17579</td>\n",
       "      <td>10598.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18157.420375</td>\n",
       "      <td>-578.420375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>22689</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22440.428349</td>\n",
       "      <td>248.571651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>22689</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22440.428349</td>\n",
       "      <td>248.571651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>22689</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22810.937683</td>\n",
       "      <td>-121.937683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>22689</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22810.937683</td>\n",
       "      <td>-121.937683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prix  kilometrage  date_mise_circulation  puissance  nb_places  \\\n",
       "0    22990      20629.0                   2021      110.0        5.0   \n",
       "1    42790       5104.0                   2022      181.0        5.0   \n",
       "2    23990       8900.0                   2021      131.0        5.0   \n",
       "3    17290       1305.0                   2021       83.0        5.0   \n",
       "4    17490      37377.0                   2019      110.0        5.0   \n",
       "..     ...          ...                    ...        ...        ...   \n",
       "595  17579      10598.0                   2018      110.0        5.0   \n",
       "596  22689         30.0                   2022      110.0        5.0   \n",
       "597  22689         30.0                   2022      110.0        5.0   \n",
       "598  22689         30.0                   2022      110.0        5.0   \n",
       "599  22689         30.0                   2022      110.0        5.0   \n",
       "\n",
       "     puissance_fiscale  critair    ptac  nb_portes  BERLINGO  ...  \\\n",
       "0                  6.0      2.0  1835.0        5.0         0  ...   \n",
       "1                 10.0      1.0  2300.0        5.0         0  ...   \n",
       "2                  7.0      1.0  1735.0        5.0         0  ...   \n",
       "3                  4.0      1.0  1540.0        5.0         0  ...   \n",
       "4                  5.0      1.0  1600.0        5.0         0  ...   \n",
       "..                 ...      ...     ...        ...       ...  ...   \n",
       "595                5.0      1.0  1795.0        5.0         0  ...   \n",
       "596                6.0      1.0  1610.0        5.0         0  ...   \n",
       "597                6.0      1.0  1610.0        5.0         0  ...   \n",
       "598                6.0      1.0  1610.0        5.0         0  ...   \n",
       "599                6.0      1.0  1610.0        5.0         0  ...   \n",
       "\n",
       "     SPOTICAR PREMIUM  Ex-Auto-école  Ex-Import  Ex-Loueur  Ex-Particulier  \\\n",
       "0                   1              0          1          0               0   \n",
       "1                   1              0          0          1               0   \n",
       "2                   1              0          1          0               0   \n",
       "3                   1              0          1          0               0   \n",
       "4                   1              0          1          0               0   \n",
       "..                ...            ...        ...        ...             ...   \n",
       "595                 1              0          0          0               1   \n",
       "596                 1              0          1          0               0   \n",
       "597                 1              0          1          0               0   \n",
       "598                 1              0          1          0               0   \n",
       "599                 1              0          1          0               0   \n",
       "\n",
       "     Ex-Société  Véhicule de direction  Citroen  prix_predits  surplus_conso  \n",
       "0             0                      0        1  22032.168846     957.831154  \n",
       "1             0                      0        1  41493.975683    1296.024317  \n",
       "2             0                      0        1  24969.010723    -979.010723  \n",
       "3             0                      0        1  17015.378283     274.621717  \n",
       "4             0                      0        1  17126.276466     363.723534  \n",
       "..          ...                    ...      ...           ...            ...  \n",
       "595           0                      0        1  18157.420375    -578.420375  \n",
       "596           0                      0        1  22440.428349     248.571651  \n",
       "597           0                      0        1  22440.428349     248.571651  \n",
       "598           0                      0        1  22810.937683    -121.937683  \n",
       "599           0                      0        1  22810.937683    -121.937683  \n",
       "\n",
       "[600 rows x 67 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_finale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95d745ba7d4956a2c972602a1881faa5aacde8c57f39878a3d2b517a3ec985cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
