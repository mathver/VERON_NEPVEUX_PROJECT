{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serde import serde\n",
    "from serde.json import to_json, from_json\n",
    "from dataclasses import dataclass\n",
    "from time import sleep\n",
    "from scrapping import Voiture\n",
    "import sklearn\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récuperation du json et conversion en quelque chose d'utilisable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"donnees.json\", \"r\") as fichier:\n",
    "    contenu_fichier = fichier.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstitution = from_json(list[Voiture],contenu_fichier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Voiture(modele='308', carburant='Diesel', prix=20290, kilometrage=75967, garantie_kilometrage='non garanti', boite_de_vitesse='Automatique', transmission=2, couleur='Blanc', garantie='SPOTICAR PREMIUM', date_mise_circulation=2019, puissance=130, silhouette='Berline', nb_places=5, utilisation_prec='Ex-Loueur', puissance_fiscale=6, critair=2, ptac=1890, nb_portes=5)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstitution[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion en base de données panda et nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reconstitution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prix</th>\n",
       "      <th>kilometrage</th>\n",
       "      <th>date_mise_circulation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26750.178333</td>\n",
       "      <td>28932.145000</td>\n",
       "      <td>2020.473333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8835.590982</td>\n",
       "      <td>29263.082939</td>\n",
       "      <td>1.738100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7490.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19721.750000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26240.000000</td>\n",
       "      <td>19521.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33524.750000</td>\n",
       "      <td>41282.500000</td>\n",
       "      <td>2022.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59980.000000</td>\n",
       "      <td>176600.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               prix    kilometrage  date_mise_circulation\n",
       "count    600.000000     600.000000             600.000000\n",
       "mean   26750.178333   28932.145000            2020.473333\n",
       "std     8835.590982   29263.082939               1.738100\n",
       "min     7490.000000       3.000000            2011.000000\n",
       "25%    19721.750000    7000.000000            2019.000000\n",
       "50%    26240.000000   19521.000000            2021.000000\n",
       "75%    33524.750000   41282.500000            2022.000000\n",
       "max    59980.000000  176600.000000            2022.000000"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modele</th>\n",
       "      <th>carburant</th>\n",
       "      <th>prix</th>\n",
       "      <th>kilometrage</th>\n",
       "      <th>garantie_kilometrage</th>\n",
       "      <th>boite_de_vitesse</th>\n",
       "      <th>transmission</th>\n",
       "      <th>couleur</th>\n",
       "      <th>garantie</th>\n",
       "      <th>date_mise_circulation</th>\n",
       "      <th>puissance</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>nb_places</th>\n",
       "      <th>utilisation_prec</th>\n",
       "      <th>puissance_fiscale</th>\n",
       "      <th>critair</th>\n",
       "      <th>ptac</th>\n",
       "      <th>nb_portes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>308</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>20290</td>\n",
       "      <td>75967</td>\n",
       "      <td>non garanti</td>\n",
       "      <td>Automatique</td>\n",
       "      <td>2</td>\n",
       "      <td>Blanc</td>\n",
       "      <td>SPOTICAR PREMIUM</td>\n",
       "      <td>2019</td>\n",
       "      <td>130</td>\n",
       "      <td>Berline</td>\n",
       "      <td>5</td>\n",
       "      <td>Ex-Loueur</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1890</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3008</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>31900</td>\n",
       "      <td>29066</td>\n",
       "      <td>non garanti</td>\n",
       "      <td>Manuelle</td>\n",
       "      <td>NA</td>\n",
       "      <td>Gris</td>\n",
       "      <td>SPOTICAR PREMIUM</td>\n",
       "      <td>2021</td>\n",
       "      <td>130</td>\n",
       "      <td>SUV-4x4</td>\n",
       "      <td>5</td>\n",
       "      <td>NA</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3008</td>\n",
       "      <td>Essence</td>\n",
       "      <td>33920</td>\n",
       "      <td>31997</td>\n",
       "      <td>non garanti</td>\n",
       "      <td>Automatique</td>\n",
       "      <td>NA</td>\n",
       "      <td>Gris</td>\n",
       "      <td>SPOTICAR PREMIUM</td>\n",
       "      <td>2021</td>\n",
       "      <td>130</td>\n",
       "      <td>SUV-4x4</td>\n",
       "      <td>5</td>\n",
       "      <td>NA</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>Essence</td>\n",
       "      <td>21980</td>\n",
       "      <td>40952</td>\n",
       "      <td>non garanti</td>\n",
       "      <td>Manuelle</td>\n",
       "      <td>NA</td>\n",
       "      <td>Gris</td>\n",
       "      <td>SPOTICAR PREMIUM</td>\n",
       "      <td>2021</td>\n",
       "      <td>100</td>\n",
       "      <td>SUV-4x4</td>\n",
       "      <td>5</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>Essence</td>\n",
       "      <td>22990</td>\n",
       "      <td>7901</td>\n",
       "      <td>non garanti</td>\n",
       "      <td>Manuelle</td>\n",
       "      <td>NA</td>\n",
       "      <td>Gris</td>\n",
       "      <td>SPOTICAR PREMIUM</td>\n",
       "      <td>2021</td>\n",
       "      <td>100</td>\n",
       "      <td>SUV-4x4</td>\n",
       "      <td>5</td>\n",
       "      <td>Ex-Particulier</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modele carburant   prix  kilometrage garantie_kilometrage boite_de_vitesse  \\\n",
       "0    308    Diesel  20290        75967          non garanti      Automatique   \n",
       "1   3008    Diesel  31900        29066          non garanti         Manuelle   \n",
       "2   3008   Essence  33920        31997          non garanti      Automatique   \n",
       "3   2008   Essence  21980        40952          non garanti         Manuelle   \n",
       "4   2008   Essence  22990         7901          non garanti         Manuelle   \n",
       "\n",
       "  transmission couleur          garantie  date_mise_circulation puissance  \\\n",
       "0            2   Blanc  SPOTICAR PREMIUM                   2019       130   \n",
       "1           NA    Gris  SPOTICAR PREMIUM                   2021       130   \n",
       "2           NA    Gris  SPOTICAR PREMIUM                   2021       130   \n",
       "3           NA    Gris  SPOTICAR PREMIUM                   2021       100   \n",
       "4           NA    Gris  SPOTICAR PREMIUM                   2021       100   \n",
       "\n",
       "  silhouette nb_places utilisation_prec puissance_fiscale critair  ptac  \\\n",
       "0    Berline         5        Ex-Loueur                 6       2  1890   \n",
       "1    SUV-4x4         5               NA                 7       2    NA   \n",
       "2    SUV-4x4         5               NA                 7       1    NA   \n",
       "3    SUV-4x4         5               NA                 5       1    NA   \n",
       "4    SUV-4x4         5   Ex-Particulier                 5       1    NA   \n",
       "\n",
       "  nb_portes  \n",
       "0         5  \n",
       "1         5  \n",
       "2         5  \n",
       "3         5  \n",
       "4         5  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modele : ['308' '3008' '2008' '208' '108' '308 SW' '5008' '508' 'RIFTER' 'BOXER'\n",
      " '508 SW' 'TRAVELLER' 'PARTNER' 'EXPERT' '4008'] \n",
      "carburant : ['Diesel' 'Essence' 'Electrique' 'Hybride rechargeable'] \n",
      "prix : [20290 31900 33920 21980 22990 21990 34390 17890 32990 20490 18990 11990\n",
      " 26290 33490 17490 32490 25990 26590 22490 17690 34490 36990 38790 32590\n",
      " 28990 25290 16990 22190 23980 33790 38490 22390 26990 29990 38980 31690\n",
      " 24590 35990 38290 28790 26190 23790 26299 21490 31290 35690 22290 46790\n",
      " 15490 28980 33091 30790 40490 28490 36390 17990 39790 23220 59980 38990\n",
      " 24790 23290 32480 20480 34990 27790 23990 15480 23390 52890 29290 27590\n",
      " 27990 26490 15290 27690 39990 42580 36490 32390 28690 32300 24990 19290\n",
      " 42590 46290 31580 52190 37990 28590 39390 39690 38280 24490 23150 26390\n",
      " 37180 21590 35299 38499 37099 24199 42199 14790 14799 37490 39631 47490\n",
      " 37599 14590 33990 28390 16490 18480 17980 22980 39290 22180 27980 12480\n",
      " 19280 33480 12280 22280 33980 31780 40980 24280 15380 18580 32290 38480\n",
      " 34480 24980 42780 30490 40290 37290 39980 40580 22480 36480 25490 39190\n",
      " 41490 27490 39499 40799 28480 10390 15999 15799 24999 19999 20499 16499\n",
      " 17290 16390 30890 25090 16290 29890 26790 21780 17280 20890 31990 18890\n",
      " 18880 19480 35090 19390 18490 14990 22610 12990 14490 19490 20990 21890\n",
      " 20590 26890 42999 37499  8900  7990  7490 19799 20799 31799 10799 13499\n",
      " 13799 29799 17999 33799 17799 28999 39999 26499 26999 23999 32499 17199\n",
      " 12799 10490 37790 28799 42899 29790 18999 49999 30290 16699 26399 21999\n",
      " 41290 33999 29499 37999 13490 43990 44990 13990 34999 22399 19990 24890\n",
      " 33500 30990 45490 10990 18790 29690 15690 23490 35490 11390 15990 23480\n",
      " 12360 41990 31490 11490 28499 18499 14999 25999 37998 44799 20999 31499\n",
      " 36799 41998 18299 19399 15333 33299 36299 13999 27999 32299 11999 34299\n",
      " 29999 24290 15499 31699 23799 33599 16985 23985 21185 21895 34685 14500\n",
      " 18900 30690 11790 17300 43900 31700 20000 28500 32900 20500 38890  8990\n",
      " 28290 20690 13980 17780 11083 34780 14290 12490 12290 17790] \n",
      "kilometrage : [ 75967  29066  31997  40952   7901  19050  24889  19422  38139  50816\n",
      "  45494  15101  19615  35954  62777   5097  31569  17539  12287  19939\n",
      "  38473  24378   3840   7000  50869  26133   4073  20609  54218  18835\n",
      "  24956  37973    500   8118   5598  46265  20962   5851   7210   2930\n",
      "  23635     10  32891     99    100  15317  75124   9356  10325  39055\n",
      "  50730  25329  16075  45474  11797  11761  16540  27944   3867  28420\n",
      "   9990   9500  19363  13955   4038      7     15  11751  35597   6952\n",
      "      6  39694   6437   8922   9000  12072  15117  24797  30506  30682\n",
      "  16162  58891  24352  29004  32747  20453  15463  38208   7087   6710\n",
      "  27079  22000   9989  38949   5993   2171  32619  28167  21253   5492\n",
      "  10114   1095   1909   4626  15000   7138     25  11563   9840   6396\n",
      "  82020  18000  18753   2741  19542   5590  26853  14572  46452   6890\n",
      "   8500   8000  11346  46487  59922  26000  16850  11000  17580  14800\n",
      "  72488  62190  78538  27275  10979   2851  13768  31430  16594   7642\n",
      "  26349  91300  32386  67054  28243  29215  51669  27702  29803   3108\n",
      "  19978  20764  42788  21077  48240  18600   8987   7257  45615  45026\n",
      "  40680  66080  29784   4927  35044  19431    782   6782  23472   3957\n",
      "  29605   4042   2917  39339  22632   3641  16950  18737  77503  19561\n",
      "  34242  16064  22350  25745   7312   5270  16914  30372  23423  50521\n",
      "  32698  12131  15696  27452  31891   3013   3205 101090  50681  62019\n",
      " 131104  38024  75000  96451  31725 119902  66250 108760  44900  32895\n",
      "   5656  55191     11    114  32604   9223  41269  22690  20696  31037\n",
      "  21805  32506  21036  12020  17022  40025  70929   3583  31512  18999\n",
      "  26691  40743   5178  59187  48094  24590  18270  10031  10734  24000\n",
      "  85460  29967  47307  87729  78858  98047  54435  99070  22242  47000\n",
      "  49391  84034  85849  96847  75254   5188  42689  28300  16210  22308\n",
      "  12000 176600 133319 103638 128103 103613  62500  92981 100150  22500\n",
      "  73677  22834  21408  15970  77000  40626  44158  31069  26150  26275\n",
      "   5000  55201   8165  40523  41704   1007  13200  53543  15573   6150\n",
      "  45449   7500   5642   8220  69989  86971  12130   5430  59537  10357\n",
      "  17667   8373  14653  40730   5844   6512  19323   9512   3296   6629\n",
      "   7386  47592  10673   3795  12232  11049  21555  15600  12003   6125\n",
      "  19930  69400   2240   3433   5756   4887  43486  10658  10258  56200\n",
      "  64400  45300  45500  94646  82544  36000  25705      5      3  29395\n",
      "  33061     50  92210  60935  53262  73831 141125 128370    966  27460\n",
      "  28195  54908   3000   1200  30426  35901  30250  26119  31266  41323\n",
      "  41450   6000  22069 102649   1000   2500   9009  20208   3350  12250\n",
      "   9850  11545  11800  91500   2000  71426  41167  35317  45509  19500\n",
      "  46500  47315  52450  12804   4175  82720  41117  66524 109837  58797\n",
      " 106513  78551  42152  45634  44835   6502  44913   2638  88300  72203\n",
      "  60525  21560   7706  19797   6410  25254   4036   5207  30516   1754\n",
      "  88198  68397  26136  32365   3640   5419   6043   9524   4070  65500\n",
      "   2114   9010  20447     52    916  86222  10485  60172  69613  85239\n",
      "  61617   7283  32400  31436  70607  57926  29130  41831  39505   5983\n",
      "  93450  25550  33850  75700   5595  59250  51401  20814  49252  75347\n",
      "  40845  94216  23700 116403  84233  63859  84923   7183   4920 123145\n",
      "  26415  47815   1500   3801  22346  59550   6971  55088  19785   2655\n",
      "   6332 121955  60541 104788  46997  66487 125256  14453   8556  14364\n",
      "  28566  43016  37868   4290  30057  23222  16378   4861  37994  16606\n",
      "  57430  41203  11519 110315  31481  16777  17220   8260  18320  15700\n",
      "  37905  21482  39695  48476  66543  40733  20790   5505  17370  16459\n",
      "   7310  45284  15500  16302  33445  14000   9007   3254   2535  21164] \n",
      "garantie_kilometrage : ['non garanti' 'garanti'] \n",
      "boite_de_vitesse : ['Automatique' 'Manuelle'] \n",
      "transmission : [2 'NA' 4] \n",
      "couleur : ['Blanc' 'Gris' 'Noir' 'Bleu' 'Rouge' 'Orange' 'Jaune' 'NA' 'Vert' 'Sable'\n",
      " 'Brun'] \n",
      "garantie : ['SPOTICAR PREMIUM' 'SPOTICAR ADVANCED' 'AUTOEXPERT' 'SPOTICAR ESSENTIAL'] \n",
      "date_mise_circulation : [2019 2021 2022 2020 2018 2017 2016 2014 2011 2015 2013] \n",
      "puissance : [130 100 131 102 110 72 'NA' 136 109 163 177 75 82 140 181 150 200 128 68\n",
      " 92 6 120 112 99 160 95 180 179 155 225 115 67 145] \n",
      "silhouette : ['Berline' 'SUV-4x4' 'Citadine' 'Break' 'Familiale' 'Utilitaire'] \n",
      "nb_places : [5 'NA' 7 3 8 4 2 6] \n",
      "utilisation_prec : ['Ex-Loueur' 'NA' 'Ex-Particulier' 'Ex-Import' 'Ex-Auto-école'\n",
      " 'Véhicule de direction' 'Ex-Société'] \n",
      "puissance_fiscale : [6 7 5 4 8 10 9 11 'NA' 3 13] \n",
      "critair : [2 1 0 'NA'] \n",
      "ptac : [1890 'NA' 2000 1595 1750 1680 1240 1715 1770 1940 1752 1645 2160 2030\n",
      " 1980 1910 1990 2140 1870 1730 2125 1710 1775 1625 2285 1950 1510 2020\n",
      " 1580 3300 2270 2090 2120 2360 1790 2200 2280 1840 2230 2257 1665 2339\n",
      " 3100 2146 1930 1880 1630 1515 1655 1970 2290 3500 1692 1855 1810 1656\n",
      " 1780 1700 1550 1975 1785 2250 1520 1635 1546 1920 1593 2695 3000 2610\n",
      " 2730 2790 1850 1960 1900 1582 1748 2180 1650 1731 1830 1690 2060 2001\n",
      " 2225 2830] \n",
      "nb_portes : [5 4 3 'NA'] \n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    col_selec = f\"df.{i}.unique()\"\n",
    "    \n",
    "    print(f\"{i} : {eval(col_selec)} \")\n",
    "# retourne toutes les modalités pour chaque variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarques sur les variables :\n",
    "\n",
    "- modele : enlever les espaces, ou supprimer les variables peu occurentes (<=1)\n",
    "- carburant : même remarque\n",
    "- même remarque pour toutes les variables textuelles\n",
    "- utilisation précédente : regrouper par pro/loueur/part/ ne sait pas ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de dummys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = conversion_df.data_frame_pandas('donnees.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modele                    object\n",
       "carburant                 object\n",
       "prix                       int64\n",
       "kilometrage                int64\n",
       "garantie_kilometrage      object\n",
       "boite_de_vitesse          object\n",
       "transmission             float64\n",
       "couleur                   object\n",
       "garantie                  object\n",
       "date_mise_circulation      int64\n",
       "puissance                float64\n",
       "silhouette                object\n",
       "nb_places                float64\n",
       "utilisation_prec          object\n",
       "puissance_fiscale        float64\n",
       "critair                  float64\n",
       "ptac                     float64\n",
       "nb_portes                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1890.000000\n",
       "1      1874.729367\n",
       "2      1874.729367\n",
       "3      1874.729367\n",
       "4      1874.729367\n",
       "          ...     \n",
       "595    1940.000000\n",
       "596    1770.000000\n",
       "597    2000.000000\n",
       "598    1874.729367\n",
       "599    2790.000000\n",
       "Name: ptac, Length: 600, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ptac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modele                    string\n",
       "carburant                 string\n",
       "prix                       Int64\n",
       "kilometrage                Int64\n",
       "garantie_kilometrage      string\n",
       "boite_de_vitesse          string\n",
       "transmission             Float64\n",
       "couleur                   string\n",
       "garantie                  string\n",
       "date_mise_circulation      Int64\n",
       "puissance                Float64\n",
       "silhouette                string\n",
       "nb_places                Float64\n",
       "utilisation_prec          string\n",
       "puissance_fiscale        Float64\n",
       "critair                  Float64\n",
       "ptac                     Float64\n",
       "nb_portes                Float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.convert_dtypes().dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passage sous numpy + ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'conversion_df' from 'c:\\\\Users\\\\mathi\\\\Documents\\\\Cours\\\\M2\\\\Machine Learning\\\\VERON_NEPVEUX_PROJECT\\\\veron_nepveux_project\\\\conversion_df.py'>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "import conversion_df\n",
    "\n",
    "reload(conversion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = conversion_df.data_frame_modele('donnees.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.5967e+04, 2.0190e+03, 1.3000e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [2.9066e+04, 2.0210e+03, 1.3000e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [3.1997e+04, 2.0210e+03, 1.3000e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       ...,\n",
       "       [2.1164e+04, 2.0220e+03, 1.3100e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [1.0000e+01, 2.0220e+03, 1.4500e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [1.0000e+01, 2.0220e+03, 1.7700e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.436e+08, tolerance: 2.699e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.475e+08, tolerance: 2.967e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.757e+08, tolerance: 3.014e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.016e+08, tolerance: 2.903e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.161e+08, tolerance: 2.893e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.526e+08, tolerance: 2.699e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.540e+08, tolerance: 2.967e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.797e+08, tolerance: 3.014e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.090e+08, tolerance: 2.903e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.190e+08, tolerance: 2.893e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.497e+08, tolerance: 2.699e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.544e+08, tolerance: 2.967e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.804e+08, tolerance: 3.014e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.095e+08, tolerance: 2.903e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.209e+08, tolerance: 2.893e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.498e+08, tolerance: 2.699e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.561e+08, tolerance: 2.967e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.823e+08, tolerance: 3.014e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.114e+08, tolerance: 2.903e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.234e+08, tolerance: 2.893e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.519e+08, tolerance: 2.699e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.575e+08, tolerance: 2.967e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.828e+08, tolerance: 3.014e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.123e+08, tolerance: 2.903e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.251e+08, tolerance: 2.893e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.427e+08, tolerance: 2.699e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.525e+08, tolerance: 2.967e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.718e+08, tolerance: 3.014e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.039e+08, tolerance: 2.903e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.178e+08, tolerance: 2.893e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.741e+08, tolerance: 2.699e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.743e+08, tolerance: 2.967e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.919e+07, tolerance: 3.014e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.342e+08, tolerance: 2.903e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.123e+08, tolerance: 2.893e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.781e+08, tolerance: 2.903e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.723e+08, tolerance: 3.621e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017353</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 0.01}</td>\n",
       "      <td>0.931773</td>\n",
       "      <td>0.909541</td>\n",
       "      <td>0.921335</td>\n",
       "      <td>0.934228</td>\n",
       "      <td>0.915186</td>\n",
       "      <td>0.922413</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014362</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 0.25}</td>\n",
       "      <td>0.931670</td>\n",
       "      <td>0.909574</td>\n",
       "      <td>0.921492</td>\n",
       "      <td>0.933577</td>\n",
       "      <td>0.916206</td>\n",
       "      <td>0.922504</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020543</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 0.5}</td>\n",
       "      <td>0.931117</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.921478</td>\n",
       "      <td>0.932954</td>\n",
       "      <td>0.917505</td>\n",
       "      <td>0.922509</td>\n",
       "      <td>0.008704</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034707</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 0.75}</td>\n",
       "      <td>0.929390</td>\n",
       "      <td>0.909147</td>\n",
       "      <td>0.921198</td>\n",
       "      <td>0.933079</td>\n",
       "      <td>0.919150</td>\n",
       "      <td>0.922393</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051465</td>\n",
       "      <td>0.038298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0.015625, 'l1_ratio': 1}</td>\n",
       "      <td>0.926210</td>\n",
       "      <td>0.906920</td>\n",
       "      <td>0.924817</td>\n",
       "      <td>0.941423</td>\n",
       "      <td>0.917169</td>\n",
       "      <td>0.923308</td>\n",
       "      <td>0.011359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.017353      0.001620         0.000000        0.000000    0.015625   \n",
       "1       0.014362      0.001493         0.000200        0.000399    0.015625   \n",
       "2       0.020543      0.002570         0.000399        0.000488    0.015625   \n",
       "3       0.034707      0.004009         0.000399        0.000489    0.015625   \n",
       "4       0.051465      0.038298         0.000000        0.000000    0.015625   \n",
       "\n",
       "  param_l1_ratio                                 params  split0_test_score  \\\n",
       "0           0.01  {'alpha': 0.015625, 'l1_ratio': 0.01}           0.931773   \n",
       "1           0.25  {'alpha': 0.015625, 'l1_ratio': 0.25}           0.931670   \n",
       "2            0.5   {'alpha': 0.015625, 'l1_ratio': 0.5}           0.931117   \n",
       "3           0.75  {'alpha': 0.015625, 'l1_ratio': 0.75}           0.929390   \n",
       "4              1     {'alpha': 0.015625, 'l1_ratio': 1}           0.926210   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.909541           0.921335           0.934228           0.915186   \n",
       "1           0.909574           0.921492           0.933577           0.916206   \n",
       "2           0.909489           0.921478           0.932954           0.917505   \n",
       "3           0.909147           0.921198           0.933079           0.919150   \n",
       "4           0.906920           0.924817           0.941423           0.917169   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.922413        0.009447                8  \n",
       "1         0.922504        0.009105                7  \n",
       "2         0.922509        0.008704                5  \n",
       "3         0.922393        0.008373               11  \n",
       "4         0.923308        0.011359                1  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = ElasticNet()\n",
    "en_gs = GridSearchCV(\n",
    "    en,\n",
    "    {\n",
    "        \"alpha\": [2 ** p  for p in range(-6, 6)],\n",
    "        \"l1_ratio\": (0.01, 0.25, 0.5, 0.75, 1),\n",
    "    }\n",
    ")\n",
    "en_gs.fit(X_tr, y_tr) #problème vient du fit\n",
    "en_df = pd.DataFrame(en_gs.cv_results_)\n",
    "en_df.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 0.015625, 'l1_ratio': 1}, 0.9233077299957747)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_gs.best_params_, en_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr = KNeighborsRegressor()\n",
    "knr_gs = GridSearchCV(\n",
    "    knr,\n",
    "    {\n",
    "        \"n_neighbors\": range(5, 15),\n",
    "        \"weights\": (\"uniform\", \"distance\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform'}</td>\n",
       "      <td>0.494067</td>\n",
       "      <td>0.453842</td>\n",
       "      <td>0.432240</td>\n",
       "      <td>0.587952</td>\n",
       "      <td>0.486897</td>\n",
       "      <td>0.491000</td>\n",
       "      <td>0.053403</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.523950</td>\n",
       "      <td>0.517758</td>\n",
       "      <td>0.492073</td>\n",
       "      <td>0.641959</td>\n",
       "      <td>0.566547</td>\n",
       "      <td>0.548457</td>\n",
       "      <td>0.052521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007982</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'uniform'}</td>\n",
       "      <td>0.468571</td>\n",
       "      <td>0.443095</td>\n",
       "      <td>0.386004</td>\n",
       "      <td>0.581147</td>\n",
       "      <td>0.477782</td>\n",
       "      <td>0.471320</td>\n",
       "      <td>0.063540</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'distance'}</td>\n",
       "      <td>0.513022</td>\n",
       "      <td>0.515401</td>\n",
       "      <td>0.465952</td>\n",
       "      <td>0.644959</td>\n",
       "      <td>0.563534</td>\n",
       "      <td>0.540573</td>\n",
       "      <td>0.060637</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'uniform'}</td>\n",
       "      <td>0.449932</td>\n",
       "      <td>0.420647</td>\n",
       "      <td>0.381347</td>\n",
       "      <td>0.563723</td>\n",
       "      <td>0.441715</td>\n",
       "      <td>0.451473</td>\n",
       "      <td>0.060935</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.000398      0.000488         0.008778        0.001467   \n",
       "1       0.000997      0.000632         0.011016        0.001025   \n",
       "2       0.000000      0.000000         0.007982        0.000631   \n",
       "3       0.000598      0.000488         0.008777        0.001323   \n",
       "4       0.000797      0.000399         0.006783        0.000746   \n",
       "\n",
       "  param_n_neighbors param_weights                                     params  \\\n",
       "0                 5       uniform   {'n_neighbors': 5, 'weights': 'uniform'}   \n",
       "1                 5      distance  {'n_neighbors': 5, 'weights': 'distance'}   \n",
       "2                 6       uniform   {'n_neighbors': 6, 'weights': 'uniform'}   \n",
       "3                 6      distance  {'n_neighbors': 6, 'weights': 'distance'}   \n",
       "4                 7       uniform   {'n_neighbors': 7, 'weights': 'uniform'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.494067           0.453842           0.432240           0.587952   \n",
       "1           0.523950           0.517758           0.492073           0.641959   \n",
       "2           0.468571           0.443095           0.386004           0.581147   \n",
       "3           0.513022           0.515401           0.465952           0.644959   \n",
       "4           0.449932           0.420647           0.381347           0.563723   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.486897         0.491000        0.053403               11  \n",
       "1           0.566547         0.548457        0.052521                1  \n",
       "2           0.477782         0.471320        0.063540               12  \n",
       "3           0.563534         0.540573        0.060637                2  \n",
       "4           0.441715         0.451473        0.060935               14  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knr_gs.fit(X_tr, y_tr)\n",
    "knr_df = pd.DataFrame(knr_gs.cv_results_)\n",
    "knr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_neighbors': 5, 'weights': 'distance'}, 0.5484572926127578)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knr_gs.best_params_, knr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr_gs = GridSearchCV(\n",
    "    rfr,\n",
    "    {   \n",
    "        \"n_estimators\": (8 , 16, 32, 64, 128, 256),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025133</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_estimators': 8}</td>\n",
       "      <td>0.849297</td>\n",
       "      <td>0.916370</td>\n",
       "      <td>0.880615</td>\n",
       "      <td>0.912923</td>\n",
       "      <td>0.863324</td>\n",
       "      <td>0.884506</td>\n",
       "      <td>0.026557</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050878</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_estimators': 16}</td>\n",
       "      <td>0.835263</td>\n",
       "      <td>0.920619</td>\n",
       "      <td>0.877547</td>\n",
       "      <td>0.928286</td>\n",
       "      <td>0.872412</td>\n",
       "      <td>0.886826</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110691</td>\n",
       "      <td>0.011127</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>32</td>\n",
       "      <td>{'n_estimators': 32}</td>\n",
       "      <td>0.839848</td>\n",
       "      <td>0.921811</td>\n",
       "      <td>0.868258</td>\n",
       "      <td>0.930395</td>\n",
       "      <td>0.872537</td>\n",
       "      <td>0.886570</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.188696</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.004350</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>64</td>\n",
       "      <td>{'n_estimators': 64}</td>\n",
       "      <td>0.844031</td>\n",
       "      <td>0.925591</td>\n",
       "      <td>0.864014</td>\n",
       "      <td>0.938529</td>\n",
       "      <td>0.871117</td>\n",
       "      <td>0.888656</td>\n",
       "      <td>0.036763</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.383240</td>\n",
       "      <td>0.021314</td>\n",
       "      <td>0.008585</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>128</td>\n",
       "      <td>{'n_estimators': 128}</td>\n",
       "      <td>0.843311</td>\n",
       "      <td>0.924525</td>\n",
       "      <td>0.867993</td>\n",
       "      <td>0.939612</td>\n",
       "      <td>0.873027</td>\n",
       "      <td>0.889693</td>\n",
       "      <td>0.036346</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.025133      0.002705         0.001002        0.000009   \n",
       "1       0.050878      0.002279         0.001577        0.000772   \n",
       "2       0.110691      0.011127         0.003010        0.000627   \n",
       "3       0.188696      0.009290         0.004350        0.000451   \n",
       "4       0.383240      0.021314         0.008585        0.000481   \n",
       "\n",
       "  param_n_estimators                 params  split0_test_score  \\\n",
       "0                  8    {'n_estimators': 8}           0.849297   \n",
       "1                 16   {'n_estimators': 16}           0.835263   \n",
       "2                 32   {'n_estimators': 32}           0.839848   \n",
       "3                 64   {'n_estimators': 64}           0.844031   \n",
       "4                128  {'n_estimators': 128}           0.843311   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.916370           0.880615           0.912923           0.863324   \n",
       "1           0.920619           0.877547           0.928286           0.872412   \n",
       "2           0.921811           0.868258           0.930395           0.872537   \n",
       "3           0.925591           0.864014           0.938529           0.871117   \n",
       "4           0.924525           0.867993           0.939612           0.873027   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.884506        0.026557                6  \n",
       "1         0.886826        0.034098                4  \n",
       "2         0.886570        0.034286                5  \n",
       "3         0.888656        0.036763                3  \n",
       "4         0.889693        0.036346                2  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_gs.fit(X_tr, y_tr)\n",
    "rfr_df = pd.DataFrame(rfr_gs.cv_results_)\n",
    "rfr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 256}, 0.8931274764122259)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_gs.best_params_, rfr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_epsilon</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.1}</td>\n",
       "      <td>-0.008121</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.023442</td>\n",
       "      <td>-0.004581</td>\n",
       "      <td>-0.068792</td>\n",
       "      <td>-0.021058</td>\n",
       "      <td>0.025106</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009565</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 1.0}</td>\n",
       "      <td>-0.008121</td>\n",
       "      <td>-0.000356</td>\n",
       "      <td>-0.023442</td>\n",
       "      <td>-0.004578</td>\n",
       "      <td>-0.068792</td>\n",
       "      <td>-0.021058</td>\n",
       "      <td>0.025107</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008577</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 10}</td>\n",
       "      <td>-0.008121</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>-0.023442</td>\n",
       "      <td>-0.004438</td>\n",
       "      <td>-0.068792</td>\n",
       "      <td>-0.021042</td>\n",
       "      <td>0.025115</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1.0, 'epsilon': 0.1}</td>\n",
       "      <td>-0.004013</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>-0.018785</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>-0.066298</td>\n",
       "      <td>-0.017025</td>\n",
       "      <td>0.025796</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'epsilon': 1.0}</td>\n",
       "      <td>-0.004013</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>-0.018785</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>-0.066298</td>\n",
       "      <td>-0.017025</td>\n",
       "      <td>0.025796</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.010337      0.000730         0.005820        0.001596     0.1   \n",
       "1       0.009565      0.000496         0.004602        0.000491     0.1   \n",
       "2       0.008577      0.000502         0.004388        0.000489     0.1   \n",
       "3       0.008767      0.000378         0.003987        0.000007     1.0   \n",
       "4       0.008786      0.000400         0.004379        0.000497     1.0   \n",
       "\n",
       "  param_epsilon                      params  split0_test_score  \\\n",
       "0           0.1  {'C': 0.1, 'epsilon': 0.1}          -0.008121   \n",
       "1           1.0  {'C': 0.1, 'epsilon': 1.0}          -0.008121   \n",
       "2            10   {'C': 0.1, 'epsilon': 10}          -0.008121   \n",
       "3           0.1  {'C': 1.0, 'epsilon': 0.1}          -0.004013   \n",
       "4           1.0  {'C': 1.0, 'epsilon': 1.0}          -0.004013   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -0.000357          -0.023442          -0.004581          -0.068792   \n",
       "1          -0.000356          -0.023442          -0.004578          -0.068792   \n",
       "2          -0.000416          -0.023442          -0.004438          -0.068792   \n",
       "3           0.003434          -0.018785           0.000536          -0.066298   \n",
       "4           0.003434          -0.018785           0.000536          -0.066298   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -0.021058        0.025106                9  \n",
       "1        -0.021058        0.025107                8  \n",
       "2        -0.021042        0.025115                7  \n",
       "3        -0.017025        0.025796                5  \n",
       "4        -0.017025        0.025796                5  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr_gs = GridSearchCV(\n",
    "    svr,\n",
    "    {\n",
    "        \"C\": (0.1, 1.0, 10),\n",
    "        \"epsilon\": (0.1, 1.0, 10),\n",
    "    }\n",
    ")\n",
    "svr_gs.fit(X_tr, y_tr)\n",
    "\n",
    "svr_df = pd.DataFrame(svr_gs.cv_results_)\n",
    "svr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 10, 'epsilon': 0.1}, 0.024925707301698474)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_gs.best_params_, svr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(\n",
    "    [\n",
    "        (\"mise_echelle\", MinMaxScaler()),\n",
    "        (\"support_vecteurs\", SVR()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_gs = GridSearchCV(\n",
    "    pl,\n",
    "    {\n",
    "        \"support_vecteurs__C\": (0.1, 1.0, 10),\n",
    "        \"support_vecteurs__epsilon\": (0.1, 1.0, 10),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_support_vecteurs__C</th>\n",
       "      <th>param_support_vecteurs__epsilon</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010987</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'support_vecteurs__C': 0.1, 'support_vecteurs...</td>\n",
       "      <td>-0.008303</td>\n",
       "      <td>-0.000492</td>\n",
       "      <td>-0.023633</td>\n",
       "      <td>-0.004830</td>\n",
       "      <td>-0.068732</td>\n",
       "      <td>-0.021198</td>\n",
       "      <td>0.025013</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'support_vecteurs__C': 0.1, 'support_vecteurs...</td>\n",
       "      <td>-0.008303</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>-0.023633</td>\n",
       "      <td>-0.004822</td>\n",
       "      <td>-0.068732</td>\n",
       "      <td>-0.021197</td>\n",
       "      <td>0.025014</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'support_vecteurs__C': 0.1, 'support_vecteurs...</td>\n",
       "      <td>-0.008303</td>\n",
       "      <td>-0.000554</td>\n",
       "      <td>-0.023633</td>\n",
       "      <td>-0.004678</td>\n",
       "      <td>-0.068732</td>\n",
       "      <td>-0.021180</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009552</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.005590</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'support_vecteurs__C': 1.0, 'support_vecteurs...</td>\n",
       "      <td>-0.005810</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-0.020682</td>\n",
       "      <td>-0.001944</td>\n",
       "      <td>-0.065684</td>\n",
       "      <td>-0.018404</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009387</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'support_vecteurs__C': 1.0, 'support_vecteurs...</td>\n",
       "      <td>-0.005810</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-0.020682</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>-0.065684</td>\n",
       "      <td>-0.018404</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.010987      0.001410         0.004785        0.000731   \n",
       "1       0.009589      0.000500         0.004182        0.000385   \n",
       "2       0.009380      0.001362         0.004583        0.000485   \n",
       "3       0.009552      0.000503         0.005590        0.000492   \n",
       "4       0.009387      0.000479         0.004577        0.000480   \n",
       "\n",
       "  param_support_vecteurs__C param_support_vecteurs__epsilon  \\\n",
       "0                       0.1                             0.1   \n",
       "1                       0.1                             1.0   \n",
       "2                       0.1                              10   \n",
       "3                       1.0                             0.1   \n",
       "4                       1.0                             1.0   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'support_vecteurs__C': 0.1, 'support_vecteurs...          -0.008303   \n",
       "1  {'support_vecteurs__C': 0.1, 'support_vecteurs...          -0.008303   \n",
       "2  {'support_vecteurs__C': 0.1, 'support_vecteurs...          -0.008303   \n",
       "3  {'support_vecteurs__C': 1.0, 'support_vecteurs...          -0.005810   \n",
       "4  {'support_vecteurs__C': 1.0, 'support_vecteurs...          -0.005810   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -0.000492          -0.023633          -0.004830          -0.068732   \n",
       "1          -0.000494          -0.023633          -0.004822          -0.068732   \n",
       "2          -0.000554          -0.023633          -0.004678          -0.068732   \n",
       "3           0.002099          -0.020682          -0.001944          -0.065684   \n",
       "4           0.002099          -0.020682          -0.001943          -0.065684   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -0.021198        0.025013                9  \n",
       "1        -0.021197        0.025014                8  \n",
       "2        -0.021180        0.025023                7  \n",
       "3        -0.018404        0.024862                6  \n",
       "4        -0.018404        0.024862                5  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_gs.fit(X_tr, y_tr)\n",
    "\n",
    "pl_df = pd.DataFrame(pl_gs.cv_results_)\n",
    "pl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'support_vecteurs__C': 10, 'support_vecteurs__epsilon': 10},\n",
       " 0.009145706160399225)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_gs.best_params_, pl_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln = Pipeline(\n",
    "    [\n",
    "        (\"mise_echelle\", MinMaxScaler()),\n",
    "        (\"neurones\", MLPRegressor()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln_gs = GridSearchCV(\n",
    "    pln,\n",
    "    {\n",
    "        \"neurones__alpha\": 10.0 ** -np.arange(1, 7),\n",
    "        'neurones__hidden_layer_sizes': ((25,), (50, ), (100,), (20, 20)),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_neurones__alpha</th>\n",
       "      <th>param_neurones__hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.265284</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(25,)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-6.371930</td>\n",
       "      <td>-9.413385</td>\n",
       "      <td>-10.806891</td>\n",
       "      <td>-8.847154</td>\n",
       "      <td>-9.456761</td>\n",
       "      <td>-8.979224</td>\n",
       "      <td>1.454120</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.492616</td>\n",
       "      <td>0.029562</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-6.320893</td>\n",
       "      <td>-9.387310</td>\n",
       "      <td>-10.720110</td>\n",
       "      <td>-8.793714</td>\n",
       "      <td>-9.387221</td>\n",
       "      <td>-8.921850</td>\n",
       "      <td>1.445570</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.604582</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-6.260621</td>\n",
       "      <td>-9.223860</td>\n",
       "      <td>-10.604714</td>\n",
       "      <td>-8.666408</td>\n",
       "      <td>-9.310104</td>\n",
       "      <td>-8.813141</td>\n",
       "      <td>1.425643</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.163496</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-5.881779</td>\n",
       "      <td>-8.492671</td>\n",
       "      <td>-10.359269</td>\n",
       "      <td>-8.088452</td>\n",
       "      <td>-8.686230</td>\n",
       "      <td>-8.301680</td>\n",
       "      <td>1.436622</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.268477</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(25,)</td>\n",
       "      <td>{'neurones__alpha': 0.01, 'neurones__hidden_la...</td>\n",
       "      <td>-6.366901</td>\n",
       "      <td>-9.422666</td>\n",
       "      <td>-10.772455</td>\n",
       "      <td>-8.854116</td>\n",
       "      <td>-9.474903</td>\n",
       "      <td>-8.978208</td>\n",
       "      <td>1.448992</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.265284      0.006475         0.000399        0.000488   \n",
       "1       0.492616      0.029562         0.000399        0.000488   \n",
       "2       0.604582      0.011835         0.000804        0.000402   \n",
       "3       0.163496      0.005173         0.000991        0.000013   \n",
       "4       0.268477      0.007605         0.000198        0.000395   \n",
       "\n",
       "  param_neurones__alpha param_neurones__hidden_layer_sizes  \\\n",
       "0                   0.1                              (25,)   \n",
       "1                   0.1                              (50,)   \n",
       "2                   0.1                             (100,)   \n",
       "3                   0.1                           (20, 20)   \n",
       "4                  0.01                              (25,)   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -6.371930   \n",
       "1  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -6.320893   \n",
       "2  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -6.260621   \n",
       "3  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -5.881779   \n",
       "4  {'neurones__alpha': 0.01, 'neurones__hidden_la...          -6.366901   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -9.413385         -10.806891          -8.847154          -9.456761   \n",
       "1          -9.387310         -10.720110          -8.793714          -9.387221   \n",
       "2          -9.223860         -10.604714          -8.666408          -9.310104   \n",
       "3          -8.492671         -10.359269          -8.088452          -8.686230   \n",
       "4          -9.422666         -10.772455          -8.854116          -9.474903   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -8.979224        1.454120               22  \n",
       "1        -8.921850        1.445570               17  \n",
       "2        -8.813141        1.425643               11  \n",
       "3        -8.301680        1.436622                6  \n",
       "4        -8.978208        1.448992               21  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln_gs.fit(X_tr, y_tr)\n",
    "\n",
    "pln_df = pd.DataFrame(pln_gs.cv_results_)\n",
    "pln_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.050881234562514"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln_gs.best_params_\n",
    "\n",
    "pln_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neurones__alpha': 1e-06, 'neurones__hidden_layer_sizes': (20, 20)}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai = en_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "prix_prédits = essai.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "prix_reels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20290, 31900, 33920, 21980, 22990, 21990, 34390, 17890, 32990,\n",
       "        20490, 18990, 11990, 26290, 33490, 17490, 32490, 25990, 26590,\n",
       "        26290, 22490, 17690, 34490, 36990, 38790, 18990, 32590, 28990,\n",
       "        25290, 16990, 22190, 23980, 33790, 38490, 22390, 22490, 26990,\n",
       "        29990, 38980, 25990, 31690, 24590, 35990, 38290, 28790, 32490,\n",
       "        26190, 34490, 23790, 26299, 38290, 35990, 21490, 25990, 16990,\n",
       "        31290, 35690, 22290, 46790, 15490, 28980, 21990, 21990, 33091,\n",
       "        30790, 40490, 28490, 36390, 17990, 39790, 17990, 38490, 23220,\n",
       "        22190, 59980, 38990, 24790, 23290, 32480, 20480, 34990, 24590,\n",
       "        27790, 38980, 28490, 23990, 26590, 22190, 15480, 23390, 34490,\n",
       "        52890, 29290, 27590, 27990, 26490, 34490, 32490, 15290, 35690,\n",
       "        27690, 35690, 39990, 42580, 36490, 26190, 32390, 35990, 28690,\n",
       "        32300, 28990, 24990, 26590, 19290, 29990, 42590, 46290, 31580,\n",
       "        52190, 42590, 37990, 28590, 19290, 39390, 39990, 39690, 26990,\n",
       "        40490, 38280, 24490, 23150, 26390, 37180, 21590, 35299, 24490,\n",
       "        38499, 37990, 37099, 24199, 34990, 42199, 36490, 38990, 14790,\n",
       "        14799, 38490, 37490, 39631, 47490, 34990, 37599, 39690, 16990,\n",
       "        28990, 14590, 18990, 22390, 25290, 24490, 33990, 17490, 28390,\n",
       "        34990, 22990, 16490, 18480, 17980, 22980, 25290, 23790, 20480,\n",
       "        39290, 22180, 27980, 12480, 34990, 19280, 33480, 12280, 18480,\n",
       "        22280, 33980, 31780, 40980, 24280, 15380, 15490, 26990, 18580,\n",
       "        32290, 38480, 34480, 22180, 29990, 22980, 24980, 42780, 30490,\n",
       "        40290, 37290, 29290, 28490, 39980, 40580, 22480, 22990, 23990,\n",
       "        33990, 28490, 26990, 36490, 28990, 36480, 28490, 37490, 28990,\n",
       "        25490, 39190, 23990, 38990, 15490, 41490, 27490, 36490, 39499,\n",
       "        35990, 40799, 28480, 17490, 18990, 22990, 10390, 24990, 15999,\n",
       "        15799, 24999, 19999, 20499, 16499, 21980, 16490, 20490, 17290,\n",
       "        16390, 22990, 30890, 25090, 17980, 22390, 16290, 29890, 18990,\n",
       "        26790, 21780, 17280, 27490, 20890, 25990, 31990, 18890, 42590,\n",
       "        18880, 19480, 26990, 35090, 17490, 28490, 17890, 19390, 24990,\n",
       "        18490, 14990, 22610, 24990, 21490, 23990, 12990, 14490, 18990,\n",
       "        17490, 17990, 21490, 24990, 25990, 26990, 19490, 20990, 21890,\n",
       "        20590, 26890, 38490, 26990, 32990, 26190, 23990, 38790, 33990,\n",
       "        25990, 24990, 42999, 37499,  8900,  7990,  7490,  7990,  7490,\n",
       "        17490,  7490, 18990, 27990, 22990, 19799, 20799, 31799, 10799,\n",
       "        13499, 13799, 29799, 17999, 31799, 33799, 17799, 24999, 28999,\n",
       "        28999, 39999, 26499, 26999, 23999, 32499, 17199, 12799, 19490,\n",
       "        28490, 17990, 19490, 26490, 10490, 37790, 28799, 17890, 42899,\n",
       "        31990, 29790, 18999, 49999, 26490, 34990, 29990, 28490, 30290,\n",
       "        23999, 40490, 19490, 27490, 36990, 16699, 26399, 21999, 38490,\n",
       "        41290, 37490, 33490, 33990, 21490, 31990, 36490, 33999, 39990,\n",
       "        36990, 36490, 29499, 37999, 18990, 20490, 29790, 33999, 31290,\n",
       "        18490, 13490, 31290, 43990, 44990, 43990, 13990, 34999, 24990,\n",
       "        28999, 22399, 19990, 38990, 33990, 16490, 16990, 24890, 22990,\n",
       "        33500, 31990, 33990, 23990, 20990, 22990, 28990, 30990, 23990,\n",
       "        45490, 16990, 30990, 10990, 13490, 14990, 36990, 27490, 25990,\n",
       "        18790, 29690, 34990, 22990, 27990, 15690, 23490, 25990, 30890,\n",
       "        27490, 25490, 36490, 35490, 26490, 11390, 15990, 33990, 23480,\n",
       "        12360, 43990, 34990, 41490, 29990, 30990, 41990, 20990, 41990,\n",
       "        31490, 14490, 31990, 28990, 18990, 32490, 20990, 35490, 11490,\n",
       "        21490, 19990, 29990, 24990, 20990, 10990, 19990, 20990, 14490,\n",
       "        22490, 20990, 28499, 18499, 14999, 26999, 25999, 15999, 37998,\n",
       "        17999, 15799, 29799, 29499, 44799, 20999, 31499, 36799, 26499,\n",
       "        38499, 41998, 21999, 18299, 19399, 15333, 24999, 18999, 33299,\n",
       "        33299, 33299, 36299, 33299, 13999, 33299, 24999, 27999, 32299,\n",
       "        33299, 15999, 11999, 18499, 13999, 34299, 27999, 27490, 29990,\n",
       "        16499, 29999, 25999, 24290, 20499, 23999, 15499, 18999, 31699,\n",
       "        23799, 33599, 16985, 23985, 21185, 21895, 34685, 23990, 14500,\n",
       "        23490, 18900, 12990, 11990, 11490, 30690, 14590, 11790, 26490,\n",
       "        17300, 43900, 31700, 20000, 28500, 32900, 20500, 32990, 38890,\n",
       "        11990,  8990, 28290, 20690, 17990, 27490, 36990, 23490, 14990,\n",
       "        21990, 13980, 17780, 11083, 13980, 34780, 17990, 22990, 22990,\n",
       "        14290, 12990, 38490, 12490, 24990, 32990, 37990, 22990, 26490,\n",
       "        31490, 25990, 26990, 24490, 22990, 17990, 17990, 26990, 18490,\n",
       "        35490, 24990, 12290, 22490, 21490, 28990, 16490, 12490, 33990,\n",
       "        37490, 17990, 34990, 27490, 12490, 22990, 17990, 22990, 17790,\n",
       "        32990, 33990, 31490, 37490, 36490, 38990], dtype=int64),\n",
       " array([21037.86247711, 30276.13931246, 30087.99496474, 20720.6902187 ,\n",
       "        24219.18811635, 22881.93035411, 34911.2432658 , 18567.38496696,\n",
       "        33837.93300547, 18303.64431675, 20030.39942208, 13749.90766034,\n",
       "        26574.27192306, 33963.36711385, 17331.57327316, 31605.43343999,\n",
       "        25823.50124032, 25993.13139676, 30016.36168973, 21212.42877819,\n",
       "        18195.90129318, 34911.8442702 , 38210.14590932, 35789.62109964,\n",
       "        19857.3385501 , 32617.05085461, 30113.70606557, 27229.33058545,\n",
       "        16905.83798747, 23488.35714219, 24507.67497479, 32380.32568231,\n",
       "        36375.79066291, 22394.72518269, 22601.20085944, 29745.87901137,\n",
       "        27536.37795691, 36120.44814934, 27590.67302229, 29513.80596491,\n",
       "        25813.15438974, 34065.67582121, 36914.66780641, 32614.3042414 ,\n",
       "        31658.8654705 , 27170.69768025, 34089.81979117, 24297.39388954,\n",
       "        26792.04754076, 36423.81670242, 37927.39308826, 20107.59715134,\n",
       "        28468.88389092, 16803.02434698, 31278.4800103 , 33838.05279206,\n",
       "        22213.89509595, 38201.40208234, 16280.54430337, 29923.15669882,\n",
       "        19287.26601023, 23912.67075527, 36362.04318131, 31712.13939189,\n",
       "        42756.27189415, 30567.04901559, 36382.69269394, 17869.13666647,\n",
       "        37002.87431179, 18081.79366391, 36090.72206268, 25655.71297545,\n",
       "        23643.26915799, 42498.88018703, 36485.68661987, 25086.19297161,\n",
       "        22520.43480424, 32465.21806555, 20448.57993608, 31453.44440016,\n",
       "        23552.21944781, 28682.01830274, 36072.43436101, 29780.23194535,\n",
       "        24231.41168807, 27489.12152725, 24224.06191867, 17506.42304316,\n",
       "        24037.16556348, 35331.7079275 , 46523.00822793, 27813.12974206,\n",
       "        28481.73495318, 29535.69635052, 24893.71304076, 35326.90123561,\n",
       "        32596.09319893, 17310.75416896, 34039.3357115 , 25424.9158006 ,\n",
       "        32040.13895622, 40387.34824242, 40459.50533363, 33496.43577732,\n",
       "        26180.68385711, 33583.69006772, 39886.74990602, 26668.59583003,\n",
       "        34065.67582121, 28796.98471321, 24831.02565675, 29070.60619772,\n",
       "        20850.43866667, 28026.82785884, 40518.03423624, 46333.22980807,\n",
       "        31618.52609181, 52182.45477395, 40588.98976642, 36224.67326988,\n",
       "        29610.91796839, 20107.2294078 , 40020.60811182, 40706.22627598,\n",
       "        40443.96518394, 25932.03053877, 43128.00378279, 42814.53988504,\n",
       "        25005.1892766 , 24023.8048038 , 28976.34899274, 40931.42656734,\n",
       "        19734.0195931 , 36315.79417901, 26006.90430301, 36334.06561656,\n",
       "        36889.16443592, 35789.62109964, 24548.10444712, 34568.85266365,\n",
       "        35830.88877413, 36295.03997397, 40038.38796176, 14928.98682345,\n",
       "        13828.1928881 , 40947.72353229, 41751.02029532, 35789.62109964,\n",
       "        45497.10338277, 40811.23449124, 35789.62109964, 37881.29406654,\n",
       "        15944.79743868, 28786.0103922 , 17716.70781366, 21843.99241346,\n",
       "        22160.30974175, 24733.57141513, 23445.73798288, 33139.93749576,\n",
       "        20517.66406897, 30114.06734997, 34791.61846896, 22983.11916959,\n",
       "        15051.5285958 , 16975.60633782, 18961.47494538, 22221.99397231,\n",
       "        24028.43568337, 21824.65096381, 21370.25484   , 41257.81129815,\n",
       "        24137.32377762, 24749.07220917, 14812.23447816, 39052.96159729,\n",
       "        20560.72128165, 34021.05184831, 14827.85656265, 19247.02925412,\n",
       "        23705.78540457, 32024.52322635, 29159.27411837, 40973.43728394,\n",
       "        21953.57053969, 17150.58754861, 15911.5620603 , 26840.9098809 ,\n",
       "        22427.73037803, 31927.8394022 , 37050.00243332, 33901.63486848,\n",
       "        24182.14210904, 33009.22605302, 24280.73947662, 27511.19103576,\n",
       "        41188.24865943, 32173.02578297, 41181.28420208, 36711.51452353,\n",
       "        28978.44379098, 29780.23194535, 42748.48182458, 38493.78956995,\n",
       "        23642.80422578, 23305.94263659, 25231.0540496 , 33945.99738536,\n",
       "        31274.09755525, 26433.4827027 , 33606.79953042, 29730.9268228 ,\n",
       "        36603.06906971, 30854.65030849, 37407.54071987, 29059.97363546,\n",
       "        24574.54126724, 36334.06561656, 23761.95503856, 40704.17566459,\n",
       "        17942.11213595, 38886.41749622, 28119.80144079, 40506.31334499,\n",
       "        38302.9224493 , 36703.64878347, 35789.62109964, 34094.73729756,\n",
       "        17672.24830631, 18776.74802062, 26304.08043753,  9440.59028818,\n",
       "        28495.70353518, 17617.05198652, 16805.73121296, 23430.09566556,\n",
       "        20885.52156758, 22926.10415973, 20178.98887482, 21973.77731224,\n",
       "        16294.41152032, 22596.44864148, 16466.374577  , 20646.58449584,\n",
       "        23050.53126074, 31983.73752594, 27182.51591176, 19940.93858852,\n",
       "        22304.18723713, 16099.14067309, 31742.09794769, 20485.23835488,\n",
       "        27435.98188217, 21686.44044667, 20605.5080398 , 25780.07635665,\n",
       "        20377.73616175, 26333.4185455 , 33002.66656375, 17754.76722481,\n",
       "        41218.89227178, 20576.36678623, 22146.06135995, 24558.54536492,\n",
       "        36315.79417901, 17446.43893689, 28006.16227566, 18308.82140767,\n",
       "        20107.2294078 , 25573.01917262, 20130.88565549, 17439.11444565,\n",
       "        25067.76108379, 22282.72141515, 18253.35746232, 19676.07492967,\n",
       "         7457.53584002, 13226.59595363, 12969.92596631, 16766.39886984,\n",
       "        17187.58358725, 17046.68640244, 22864.84616843, 22614.13841805,\n",
       "        23036.27693953, 14232.81993778, 17771.28539583, 21092.48558951,\n",
       "        20736.75932708, 27919.97899181, 36525.44061008, 27013.88814441,\n",
       "        31731.97052683, 27170.69768025, 25235.18971052, 38466.79203402,\n",
       "        34631.76368906, 27397.70440797, 25131.41078385, 45697.1040662 ,\n",
       "        36334.06561656,  8893.74669852,  5931.33438058,  6892.03245392,\n",
       "         6358.70625753,  6894.08082373, 17582.32952374,  7765.2115361 ,\n",
       "        16960.05578822, 30877.74547089, 21139.13716181, 20415.83331826,\n",
       "        19608.53233108, 31788.79063495, 11099.48423049, 11953.22092316,\n",
       "        13286.81879512, 32099.29007375, 22174.55097302, 31747.52296046,\n",
       "        31264.45738367, 15359.25421553, 28417.5406121 , 27168.10970945,\n",
       "        27157.8678604 , 42361.69192682, 26669.44563053, 28100.67014508,\n",
       "        24224.06191867, 35667.01918941, 22368.89675893, 13109.16123429,\n",
       "        22700.94876273, 28989.59306667, 18911.52737377, 20845.46505146,\n",
       "        30204.90740508,  6997.15871454, 39692.04959446, 30833.26223666,\n",
       "        17184.07152708, 42538.18752829, 31973.59668489, 29121.63858782,\n",
       "        19139.4859502 , 45983.87583946, 30011.96546167, 33616.63807009,\n",
       "        32315.96528277, 28788.15819613, 31347.3987426 , 23302.69240125,\n",
       "        38609.25097493, 19727.38287492, 28321.75774812, 36703.99886474,\n",
       "        22708.50429496, 26804.67355751, 24617.71350104, 36416.958945  ,\n",
       "        39929.23864003, 36171.15456792, 34529.46338223, 34215.1070448 ,\n",
       "        22454.7014507 , 32909.28546794, 36579.20511642, 33209.82867977,\n",
       "        40657.07757887, 35948.2919327 , 36003.95311757, 28851.33527647,\n",
       "        36068.4178747 , 20367.00339598, 20043.14193061, 31285.22985219,\n",
       "        31930.44439132, 31934.02218018, 23241.05972094, 10882.54343376,\n",
       "        31749.16200607, 44309.22216466, 44077.61996751, 44148.82130207,\n",
       "        16184.82987538, 36089.58303432, 29261.24962367, 34274.2291624 ,\n",
       "        24378.27224037, 20056.0445731 , 38469.31566419, 34168.38748086,\n",
       "        18028.37117469, 16058.14967066, 28108.40153869, 24036.86269691,\n",
       "        30362.19414206, 33374.44372992, 34346.82004914, 25875.41110676,\n",
       "        19232.53687404, 23504.23051204, 28522.04564157, 33374.6075995 ,\n",
       "        22607.38066546, 40741.04993859, 20187.07992682, 32142.08786151,\n",
       "         8510.88282604, 18027.27044458, 18820.69076254, 40458.41033431,\n",
       "        27422.89260917, 25749.06523359, 21087.98402167, 30372.89458027,\n",
       "        34027.54300139, 24331.52332987, 24788.69049877, 16029.71632334,\n",
       "        24262.81171525, 25508.14142446, 31072.32928835, 26953.257875  ,\n",
       "        23059.50066139, 34525.10410593, 34203.03796405, 25939.00870009,\n",
       "         7885.5553974 , 19844.4605127 , 32070.53540243, 22066.24478801,\n",
       "        12907.72233155, 43901.03293116, 35232.44561262, 40045.67065819,\n",
       "        31194.32187437, 29275.31163071, 37181.70736018, 22663.30655665,\n",
       "        43737.16334644, 32789.99809708, 14484.31341652, 30044.90885387,\n",
       "        32193.22582615, 18966.05362253, 31867.68985437, 24728.95325505,\n",
       "        33163.65246513, 14105.03247558, 24036.53450313, 21201.62302808,\n",
       "        24141.52162559, 25087.00775997, 21996.98546151,  9637.15463117,\n",
       "        19339.52389442, 21229.86607081, 17031.28828522, 22525.52469565,\n",
       "        21718.69668395, 27489.82250302, 20564.36843356, 15586.29480729,\n",
       "        21889.01891973, 25487.50359789, 19840.60102959, 36693.10665611,\n",
       "        19658.03695038, 15785.15068495, 30371.1753785 , 31225.6335397 ,\n",
       "        41237.77908699, 19697.81844687, 31941.66473203, 36950.11598381,\n",
       "        25294.28569414, 34289.07899612, 41947.73879419, 21466.66123679,\n",
       "        19366.54633938, 20988.9371629 , 17219.83198831, 23689.85563388,\n",
       "        19229.77168262, 29496.89993683, 31447.42362667, 32228.03506608,\n",
       "        33977.90582092, 31557.95366156, 15500.73210445, 29580.66475548,\n",
       "        22731.58007255, 29571.99551158, 30415.95915857, 32360.82051359,\n",
       "        16417.16209579, 15086.24795929, 17356.55204113, 14184.0659955 ,\n",
       "        31931.87659303, 30644.72762603, 31848.20932065, 33539.92935444,\n",
       "        18745.5272363 , 31594.23722596, 23452.32257965, 22590.00952898,\n",
       "        23644.79267692, 20145.74677628, 17329.50715524, 23931.2507025 ,\n",
       "        31493.71900495, 22502.31261461, 34144.22832436, 13791.55827646,\n",
       "        21846.17736134, 21114.11205606, 22038.35066711, 33593.60302977,\n",
       "        24231.87164784, 17543.91415202, 25909.10946802, 24235.70983935,\n",
       "        11712.02718416,  9593.68256891,  8179.77890772, 28758.76176672,\n",
       "        15785.91718034,  8997.73393985, 27930.69754309, 17111.66247663,\n",
       "        42778.98664073, 33018.00480888, 21491.74653073, 28187.0182625 ,\n",
       "        34538.76992602, 16986.20800888, 33116.99435552, 39436.28609705,\n",
       "        13438.29855106,  8854.96675095, 29779.77269401, 23451.6618908 ,\n",
       "        18111.38303236, 28323.72734425, 35788.43846428, 25507.7239115 ,\n",
       "        18924.04579458, 22863.92909757, 13389.95489141, 19319.31551963,\n",
       "         6087.53505425, 17069.46374533, 37970.88772692, 19987.71936961,\n",
       "        21502.43011889, 22812.07586992, 16526.52750626, 11442.06784868,\n",
       "        36611.34379207, 13301.6110519 , 25471.90431386, 33190.25379162,\n",
       "        36969.28410044, 16611.07302471, 26259.02046304, 32298.12908923,\n",
       "        24483.00259552, 29305.555056  , 22281.33427349, 18628.74377938,\n",
       "        19272.86576713, 17567.18656925, 30063.43164829, 19146.44038252,\n",
       "        35585.81323867, 21005.71290766, 12658.58680145, 20672.60460719,\n",
       "        18336.26174565, 28358.70285021, 16624.58206723, 11207.32466857,\n",
       "        27239.23755998, 38074.99612896, 19265.54610975, 35560.6858909 ,\n",
       "        29596.8251841 , 10834.43942854, 22883.77673583, 18918.43348945,\n",
       "        17178.97211303, 18029.19018682, 32022.8845305 , 32300.88377923,\n",
       "        31991.82341548, 35719.62720977, 32783.4468213 , 39786.65201477]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prix_reels,prix_prédits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prix_prédits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prix_reels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21037.86247711, 30276.13931246, 30087.99496474, 20720.6902187 ,\n",
       "       24219.18811635, 22881.93035411, 34911.2432658 , 18567.38496696,\n",
       "       33837.93300547, 18303.64431675, 20030.39942208, 13749.90766034,\n",
       "       26574.27192306, 33963.36711385, 17331.57327316, 31605.43343999,\n",
       "       25823.50124032, 25993.13139676, 30016.36168973, 21212.42877819,\n",
       "       18195.90129318, 34911.8442702 , 38210.14590932, 35789.62109964,\n",
       "       19857.3385501 , 32617.05085461, 30113.70606557, 27229.33058545,\n",
       "       16905.83798747, 23488.35714219, 24507.67497479, 32380.32568231,\n",
       "       36375.79066291, 22394.72518269, 22601.20085944, 29745.87901137,\n",
       "       27536.37795691, 36120.44814934, 27590.67302229, 29513.80596491,\n",
       "       25813.15438974, 34065.67582121, 36914.66780641, 32614.3042414 ,\n",
       "       31658.8654705 , 27170.69768025, 34089.81979117, 24297.39388954,\n",
       "       26792.04754076, 36423.81670242, 37927.39308826, 20107.59715134,\n",
       "       28468.88389092, 16803.02434698, 31278.4800103 , 33838.05279206,\n",
       "       22213.89509595, 38201.40208234, 16280.54430337, 29923.15669882,\n",
       "       19287.26601023, 23912.67075527, 36362.04318131, 31712.13939189,\n",
       "       42756.27189415, 30567.04901559, 36382.69269394, 17869.13666647,\n",
       "       37002.87431179, 18081.79366391, 36090.72206268, 25655.71297545,\n",
       "       23643.26915799, 42498.88018703, 36485.68661987, 25086.19297161,\n",
       "       22520.43480424, 32465.21806555, 20448.57993608, 31453.44440016,\n",
       "       23552.21944781, 28682.01830274, 36072.43436101, 29780.23194535,\n",
       "       24231.41168807, 27489.12152725, 24224.06191867, 17506.42304316,\n",
       "       24037.16556348, 35331.7079275 , 46523.00822793, 27813.12974206,\n",
       "       28481.73495318, 29535.69635052, 24893.71304076, 35326.90123561,\n",
       "       32596.09319893, 17310.75416896, 34039.3357115 , 25424.9158006 ,\n",
       "       32040.13895622, 40387.34824242, 40459.50533363, 33496.43577732,\n",
       "       26180.68385711, 33583.69006772, 39886.74990602, 26668.59583003,\n",
       "       34065.67582121, 28796.98471321, 24831.02565675, 29070.60619772,\n",
       "       20850.43866667, 28026.82785884, 40518.03423624, 46333.22980807,\n",
       "       31618.52609181, 52182.45477395, 40588.98976642, 36224.67326988,\n",
       "       29610.91796839, 20107.2294078 , 40020.60811182, 40706.22627598,\n",
       "       40443.96518394, 25932.03053877, 43128.00378279, 42814.53988504,\n",
       "       25005.1892766 , 24023.8048038 , 28976.34899274, 40931.42656734,\n",
       "       19734.0195931 , 36315.79417901, 26006.90430301, 36334.06561656,\n",
       "       36889.16443592, 35789.62109964, 24548.10444712, 34568.85266365,\n",
       "       35830.88877413, 36295.03997397, 40038.38796176, 14928.98682345,\n",
       "       13828.1928881 , 40947.72353229, 41751.02029532, 35789.62109964,\n",
       "       45497.10338277, 40811.23449124, 35789.62109964, 37881.29406654,\n",
       "       15944.79743868, 28786.0103922 , 17716.70781366, 21843.99241346,\n",
       "       22160.30974175, 24733.57141513, 23445.73798288, 33139.93749576,\n",
       "       20517.66406897, 30114.06734997, 34791.61846896, 22983.11916959,\n",
       "       15051.5285958 , 16975.60633782, 18961.47494538, 22221.99397231,\n",
       "       24028.43568337, 21824.65096381, 21370.25484   , 41257.81129815,\n",
       "       24137.32377762, 24749.07220917, 14812.23447816, 39052.96159729,\n",
       "       20560.72128165, 34021.05184831, 14827.85656265, 19247.02925412,\n",
       "       23705.78540457, 32024.52322635, 29159.27411837, 40973.43728394,\n",
       "       21953.57053969, 17150.58754861, 15911.5620603 , 26840.9098809 ,\n",
       "       22427.73037803, 31927.8394022 , 37050.00243332, 33901.63486848,\n",
       "       24182.14210904, 33009.22605302, 24280.73947662, 27511.19103576,\n",
       "       41188.24865943, 32173.02578297, 41181.28420208, 36711.51452353,\n",
       "       28978.44379098, 29780.23194535, 42748.48182458, 38493.78956995,\n",
       "       23642.80422578, 23305.94263659, 25231.0540496 , 33945.99738536,\n",
       "       31274.09755525, 26433.4827027 , 33606.79953042, 29730.9268228 ,\n",
       "       36603.06906971, 30854.65030849, 37407.54071987, 29059.97363546,\n",
       "       24574.54126724, 36334.06561656, 23761.95503856, 40704.17566459,\n",
       "       17942.11213595, 38886.41749622, 28119.80144079, 40506.31334499,\n",
       "       38302.9224493 , 36703.64878347, 35789.62109964, 34094.73729756,\n",
       "       17672.24830631, 18776.74802062, 26304.08043753,  9440.59028818,\n",
       "       28495.70353518, 17617.05198652, 16805.73121296, 23430.09566556,\n",
       "       20885.52156758, 22926.10415973, 20178.98887482, 21973.77731224,\n",
       "       16294.41152032, 22596.44864148, 16466.374577  , 20646.58449584,\n",
       "       23050.53126074, 31983.73752594, 27182.51591176, 19940.93858852,\n",
       "       22304.18723713, 16099.14067309, 31742.09794769, 20485.23835488,\n",
       "       27435.98188217, 21686.44044667, 20605.5080398 , 25780.07635665,\n",
       "       20377.73616175, 26333.4185455 , 33002.66656375, 17754.76722481,\n",
       "       41218.89227178, 20576.36678623, 22146.06135995, 24558.54536492,\n",
       "       36315.79417901, 17446.43893689, 28006.16227566, 18308.82140767,\n",
       "       20107.2294078 , 25573.01917262, 20130.88565549, 17439.11444565,\n",
       "       25067.76108379, 22282.72141515, 18253.35746232, 19676.07492967,\n",
       "        7457.53584002, 13226.59595363, 12969.92596631, 16766.39886984,\n",
       "       17187.58358725, 17046.68640244, 22864.84616843, 22614.13841805,\n",
       "       23036.27693953, 14232.81993778, 17771.28539583, 21092.48558951,\n",
       "       20736.75932708, 27919.97899181, 36525.44061008, 27013.88814441,\n",
       "       31731.97052683, 27170.69768025, 25235.18971052, 38466.79203402,\n",
       "       34631.76368906, 27397.70440797, 25131.41078385, 45697.1040662 ,\n",
       "       36334.06561656,  8893.74669852,  5931.33438058,  6892.03245392,\n",
       "        6358.70625753,  6894.08082373, 17582.32952374,  7765.2115361 ,\n",
       "       16960.05578822, 30877.74547089, 21139.13716181, 20415.83331826,\n",
       "       19608.53233108, 31788.79063495, 11099.48423049, 11953.22092316,\n",
       "       13286.81879512, 32099.29007375, 22174.55097302, 31747.52296046,\n",
       "       31264.45738367, 15359.25421553, 28417.5406121 , 27168.10970945,\n",
       "       27157.8678604 , 42361.69192682, 26669.44563053, 28100.67014508,\n",
       "       24224.06191867, 35667.01918941, 22368.89675893, 13109.16123429,\n",
       "       22700.94876273, 28989.59306667, 18911.52737377, 20845.46505146,\n",
       "       30204.90740508,  6997.15871454, 39692.04959446, 30833.26223666,\n",
       "       17184.07152708, 42538.18752829, 31973.59668489, 29121.63858782,\n",
       "       19139.4859502 , 45983.87583946, 30011.96546167, 33616.63807009,\n",
       "       32315.96528277, 28788.15819613, 31347.3987426 , 23302.69240125,\n",
       "       38609.25097493, 19727.38287492, 28321.75774812, 36703.99886474,\n",
       "       22708.50429496, 26804.67355751, 24617.71350104, 36416.958945  ,\n",
       "       39929.23864003, 36171.15456792, 34529.46338223, 34215.1070448 ,\n",
       "       22454.7014507 , 32909.28546794, 36579.20511642, 33209.82867977,\n",
       "       40657.07757887, 35948.2919327 , 36003.95311757, 28851.33527647,\n",
       "       36068.4178747 , 20367.00339598, 20043.14193061, 31285.22985219,\n",
       "       31930.44439132, 31934.02218018, 23241.05972094, 10882.54343376,\n",
       "       31749.16200607, 44309.22216466, 44077.61996751, 44148.82130207,\n",
       "       16184.82987538, 36089.58303432, 29261.24962367, 34274.2291624 ,\n",
       "       24378.27224037, 20056.0445731 , 38469.31566419, 34168.38748086,\n",
       "       18028.37117469, 16058.14967066, 28108.40153869, 24036.86269691,\n",
       "       30362.19414206, 33374.44372992, 34346.82004914, 25875.41110676,\n",
       "       19232.53687404, 23504.23051204, 28522.04564157, 33374.6075995 ,\n",
       "       22607.38066546, 40741.04993859, 20187.07992682, 32142.08786151,\n",
       "        8510.88282604, 18027.27044458, 18820.69076254, 40458.41033431,\n",
       "       27422.89260917, 25749.06523359, 21087.98402167, 30372.89458027,\n",
       "       34027.54300139, 24331.52332987, 24788.69049877, 16029.71632334,\n",
       "       24262.81171525, 25508.14142446, 31072.32928835, 26953.257875  ,\n",
       "       23059.50066139, 34525.10410593, 34203.03796405, 25939.00870009,\n",
       "        7885.5553974 , 19844.4605127 , 32070.53540243, 22066.24478801,\n",
       "       12907.72233155, 43901.03293116, 35232.44561262, 40045.67065819,\n",
       "       31194.32187437, 29275.31163071, 37181.70736018, 22663.30655665,\n",
       "       43737.16334644, 32789.99809708, 14484.31341652, 30044.90885387,\n",
       "       32193.22582615, 18966.05362253, 31867.68985437, 24728.95325505,\n",
       "       33163.65246513, 14105.03247558, 24036.53450313, 21201.62302808,\n",
       "       24141.52162559, 25087.00775997, 21996.98546151,  9637.15463117,\n",
       "       19339.52389442, 21229.86607081, 17031.28828522, 22525.52469565,\n",
       "       21718.69668395, 27489.82250302, 20564.36843356, 15586.29480729,\n",
       "       21889.01891973, 25487.50359789, 19840.60102959, 36693.10665611,\n",
       "       19658.03695038, 15785.15068495, 30371.1753785 , 31225.6335397 ,\n",
       "       41237.77908699, 19697.81844687, 31941.66473203, 36950.11598381,\n",
       "       25294.28569414, 34289.07899612, 41947.73879419, 21466.66123679,\n",
       "       19366.54633938, 20988.9371629 , 17219.83198831, 23689.85563388,\n",
       "       19229.77168262, 29496.89993683, 31447.42362667, 32228.03506608,\n",
       "       33977.90582092, 31557.95366156, 15500.73210445, 29580.66475548,\n",
       "       22731.58007255, 29571.99551158, 30415.95915857, 32360.82051359,\n",
       "       16417.16209579, 15086.24795929, 17356.55204113, 14184.0659955 ,\n",
       "       31931.87659303, 30644.72762603, 31848.20932065, 33539.92935444,\n",
       "       18745.5272363 , 31594.23722596, 23452.32257965, 22590.00952898,\n",
       "       23644.79267692, 20145.74677628, 17329.50715524, 23931.2507025 ,\n",
       "       31493.71900495, 22502.31261461, 34144.22832436, 13791.55827646,\n",
       "       21846.17736134, 21114.11205606, 22038.35066711, 33593.60302977,\n",
       "       24231.87164784, 17543.91415202, 25909.10946802, 24235.70983935,\n",
       "       11712.02718416,  9593.68256891,  8179.77890772, 28758.76176672,\n",
       "       15785.91718034,  8997.73393985, 27930.69754309, 17111.66247663,\n",
       "       42778.98664073, 33018.00480888, 21491.74653073, 28187.0182625 ,\n",
       "       34538.76992602, 16986.20800888, 33116.99435552, 39436.28609705,\n",
       "       13438.29855106,  8854.96675095, 29779.77269401, 23451.6618908 ,\n",
       "       18111.38303236, 28323.72734425, 35788.43846428, 25507.7239115 ,\n",
       "       18924.04579458, 22863.92909757, 13389.95489141, 19319.31551963,\n",
       "        6087.53505425, 17069.46374533, 37970.88772692, 19987.71936961,\n",
       "       21502.43011889, 22812.07586992, 16526.52750626, 11442.06784868,\n",
       "       36611.34379207, 13301.6110519 , 25471.90431386, 33190.25379162,\n",
       "       36969.28410044, 16611.07302471, 26259.02046304, 32298.12908923,\n",
       "       24483.00259552, 29305.555056  , 22281.33427349, 18628.74377938,\n",
       "       19272.86576713, 17567.18656925, 30063.43164829, 19146.44038252,\n",
       "       35585.81323867, 21005.71290766, 12658.58680145, 20672.60460719,\n",
       "       18336.26174565, 28358.70285021, 16624.58206723, 11207.32466857,\n",
       "       27239.23755998, 38074.99612896, 19265.54610975, 35560.6858909 ,\n",
       "       29596.8251841 , 10834.43942854, 22883.77673583, 18918.43348945,\n",
       "       17178.97211303, 18029.19018682, 32022.8845305 , 32300.88377923,\n",
       "       31991.82341548, 35719.62720977, 32783.4468213 , 39786.65201477])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prix_prédits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20290, 31900, 33920, 21980, 22990, 21990, 34390, 17890, 32990,\n",
       "       20490, 18990, 11990, 26290, 33490, 17490, 32490, 25990, 26590,\n",
       "       26290, 22490, 17690, 34490, 36990, 38790, 18990, 32590, 28990,\n",
       "       25290, 16990, 22190, 23980, 33790, 38490, 22390, 22490, 26990,\n",
       "       29990, 38980, 25990, 31690, 24590, 35990, 38290, 28790, 32490,\n",
       "       26190, 34490, 23790, 26299, 38290, 35990, 21490, 25990, 16990,\n",
       "       31290, 35690, 22290, 46790, 15490, 28980, 21990, 21990, 33091,\n",
       "       30790, 40490, 28490, 36390, 17990, 39790, 17990, 38490, 23220,\n",
       "       22190, 59980, 38990, 24790, 23290, 32480, 20480, 34990, 24590,\n",
       "       27790, 38980, 28490, 23990, 26590, 22190, 15480, 23390, 34490,\n",
       "       52890, 29290, 27590, 27990, 26490, 34490, 32490, 15290, 35690,\n",
       "       27690, 35690, 39990, 42580, 36490, 26190, 32390, 35990, 28690,\n",
       "       32300, 28990, 24990, 26590, 19290, 29990, 42590, 46290, 31580,\n",
       "       52190, 42590, 37990, 28590, 19290, 39390, 39990, 39690, 26990,\n",
       "       40490, 38280, 24490, 23150, 26390, 37180, 21590, 35299, 24490,\n",
       "       38499, 37990, 37099, 24199, 34990, 42199, 36490, 38990, 14790,\n",
       "       14799, 38490, 37490, 39631, 47490, 34990, 37599, 39690, 16990,\n",
       "       28990, 14590, 18990, 22390, 25290, 24490, 33990, 17490, 28390,\n",
       "       34990, 22990, 16490, 18480, 17980, 22980, 25290, 23790, 20480,\n",
       "       39290, 22180, 27980, 12480, 34990, 19280, 33480, 12280, 18480,\n",
       "       22280, 33980, 31780, 40980, 24280, 15380, 15490, 26990, 18580,\n",
       "       32290, 38480, 34480, 22180, 29990, 22980, 24980, 42780, 30490,\n",
       "       40290, 37290, 29290, 28490, 39980, 40580, 22480, 22990, 23990,\n",
       "       33990, 28490, 26990, 36490, 28990, 36480, 28490, 37490, 28990,\n",
       "       25490, 39190, 23990, 38990, 15490, 41490, 27490, 36490, 39499,\n",
       "       35990, 40799, 28480, 17490, 18990, 22990, 10390, 24990, 15999,\n",
       "       15799, 24999, 19999, 20499, 16499, 21980, 16490, 20490, 17290,\n",
       "       16390, 22990, 30890, 25090, 17980, 22390, 16290, 29890, 18990,\n",
       "       26790, 21780, 17280, 27490, 20890, 25990, 31990, 18890, 42590,\n",
       "       18880, 19480, 26990, 35090, 17490, 28490, 17890, 19390, 24990,\n",
       "       18490, 14990, 22610, 24990, 21490, 23990, 12990, 14490, 18990,\n",
       "       17490, 17990, 21490, 24990, 25990, 26990, 19490, 20990, 21890,\n",
       "       20590, 26890, 38490, 26990, 32990, 26190, 23990, 38790, 33990,\n",
       "       25990, 24990, 42999, 37499,  8900,  7990,  7490,  7990,  7490,\n",
       "       17490,  7490, 18990, 27990, 22990, 19799, 20799, 31799, 10799,\n",
       "       13499, 13799, 29799, 17999, 31799, 33799, 17799, 24999, 28999,\n",
       "       28999, 39999, 26499, 26999, 23999, 32499, 17199, 12799, 19490,\n",
       "       28490, 17990, 19490, 26490, 10490, 37790, 28799, 17890, 42899,\n",
       "       31990, 29790, 18999, 49999, 26490, 34990, 29990, 28490, 30290,\n",
       "       23999, 40490, 19490, 27490, 36990, 16699, 26399, 21999, 38490,\n",
       "       41290, 37490, 33490, 33990, 21490, 31990, 36490, 33999, 39990,\n",
       "       36990, 36490, 29499, 37999, 18990, 20490, 29790, 33999, 31290,\n",
       "       18490, 13490, 31290, 43990, 44990, 43990, 13990, 34999, 24990,\n",
       "       28999, 22399, 19990, 38990, 33990, 16490, 16990, 24890, 22990,\n",
       "       33500, 31990, 33990, 23990, 20990, 22990, 28990, 30990, 23990,\n",
       "       45490, 16990, 30990, 10990, 13490, 14990, 36990, 27490, 25990,\n",
       "       18790, 29690, 34990, 22990, 27990, 15690, 23490, 25990, 30890,\n",
       "       27490, 25490, 36490, 35490, 26490, 11390, 15990, 33990, 23480,\n",
       "       12360, 43990, 34990, 41490, 29990, 30990, 41990, 20990, 41990,\n",
       "       31490, 14490, 31990, 28990, 18990, 32490, 20990, 35490, 11490,\n",
       "       21490, 19990, 29990, 24990, 20990, 10990, 19990, 20990, 14490,\n",
       "       22490, 20990, 28499, 18499, 14999, 26999, 25999, 15999, 37998,\n",
       "       17999, 15799, 29799, 29499, 44799, 20999, 31499, 36799, 26499,\n",
       "       38499, 41998, 21999, 18299, 19399, 15333, 24999, 18999, 33299,\n",
       "       33299, 33299, 36299, 33299, 13999, 33299, 24999, 27999, 32299,\n",
       "       33299, 15999, 11999, 18499, 13999, 34299, 27999, 27490, 29990,\n",
       "       16499, 29999, 25999, 24290, 20499, 23999, 15499, 18999, 31699,\n",
       "       23799, 33599, 16985, 23985, 21185, 21895, 34685, 23990, 14500,\n",
       "       23490, 18900, 12990, 11990, 11490, 30690, 14590, 11790, 26490,\n",
       "       17300, 43900, 31700, 20000, 28500, 32900, 20500, 32990, 38890,\n",
       "       11990,  8990, 28290, 20690, 17990, 27490, 36990, 23490, 14990,\n",
       "       21990, 13980, 17780, 11083, 13980, 34780, 17990, 22990, 22990,\n",
       "       14290, 12990, 38490, 12490, 24990, 32990, 37990, 22990, 26490,\n",
       "       31490, 25990, 26990, 24490, 22990, 17990, 17990, 26990, 18490,\n",
       "       35490, 24990, 12290, 22490, 21490, 28990, 16490, 12490, 33990,\n",
       "       37490, 17990, 34990, 27490, 12490, 22990, 17990, 22990, 17790,\n",
       "       32990, 33990, 31490, 37490, 36490, 38990], dtype=int64)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prix_reels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif : maximiser le surplus de l'acheteur, i.e, si l'acheteur à un budget R, et n contraintes, quel véhicule maximiserait son surplus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_finale = conversion_df.data_frame_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_finale['prix_predits'] = prix_prédits\n",
    "data_finale['surplus_conso'] = data_finale['prix'] - data_finale['prix_predits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prix</th>\n",
       "      <th>kilometrage</th>\n",
       "      <th>date_mise_circulation</th>\n",
       "      <th>puissance</th>\n",
       "      <th>nb_places</th>\n",
       "      <th>puissance_fiscale</th>\n",
       "      <th>critair</th>\n",
       "      <th>ptac</th>\n",
       "      <th>nb_portes</th>\n",
       "      <th>prix_predits</th>\n",
       "      <th>...</th>\n",
       "      <th>AUTOEXPERT</th>\n",
       "      <th>SPOTICAR ADVANCED</th>\n",
       "      <th>SPOTICAR ESSENTIAL</th>\n",
       "      <th>SPOTICAR PREMIUM</th>\n",
       "      <th>Ex-Auto-école</th>\n",
       "      <th>Ex-Import</th>\n",
       "      <th>Ex-Loueur</th>\n",
       "      <th>Ex-Particulier</th>\n",
       "      <th>Ex-Société</th>\n",
       "      <th>Véhicule de direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20290</td>\n",
       "      <td>75967</td>\n",
       "      <td>2019</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1890.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21037.862477</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31900</td>\n",
       "      <td>29066</td>\n",
       "      <td>2021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1874.729367</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30276.139312</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33920</td>\n",
       "      <td>31997</td>\n",
       "      <td>2021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1874.729367</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30087.994965</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21980</td>\n",
       "      <td>40952</td>\n",
       "      <td>2021</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1874.729367</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20720.690219</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22990</td>\n",
       "      <td>7901</td>\n",
       "      <td>2021</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1874.729367</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>24219.188116</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>33990</td>\n",
       "      <td>3254</td>\n",
       "      <td>2022</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>32300.883779</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>31490</td>\n",
       "      <td>2535</td>\n",
       "      <td>2022</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1770.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>31991.823415</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>37490</td>\n",
       "      <td>21164</td>\n",
       "      <td>2022</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>35719.627210</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>36490</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1874.729367</td>\n",
       "      <td>4.934673</td>\n",
       "      <td>32783.446821</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>38990</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>177.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2790.000000</td>\n",
       "      <td>4.934673</td>\n",
       "      <td>39786.652015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prix  kilometrage  date_mise_circulation  puissance  nb_places  \\\n",
       "0    20290        75967                   2019      130.0        5.0   \n",
       "1    31900        29066                   2021      130.0        5.0   \n",
       "2    33920        31997                   2021      130.0        5.0   \n",
       "3    21980        40952                   2021      100.0        5.0   \n",
       "4    22990         7901                   2021      100.0        5.0   \n",
       "..     ...          ...                    ...        ...        ...   \n",
       "595  33990         3254                   2022      131.0        5.0   \n",
       "596  31490         2535                   2022      131.0        5.0   \n",
       "597  37490        21164                   2022      131.0        5.0   \n",
       "598  36490           10                   2022      145.0        3.0   \n",
       "599  38990           10                   2022      177.0        6.0   \n",
       "\n",
       "     puissance_fiscale  critair         ptac  nb_portes  prix_predits  ...  \\\n",
       "0                  6.0      2.0  1890.000000   5.000000  21037.862477  ...   \n",
       "1                  7.0      2.0  1874.729367   5.000000  30276.139312  ...   \n",
       "2                  7.0      1.0  1874.729367   5.000000  30087.994965  ...   \n",
       "3                  5.0      1.0  1874.729367   5.000000  20720.690219  ...   \n",
       "4                  5.0      1.0  1874.729367   5.000000  24219.188116  ...   \n",
       "..                 ...      ...          ...        ...           ...  ...   \n",
       "595                7.0      2.0  1940.000000   5.000000  32300.883779  ...   \n",
       "596                7.0      2.0  1770.000000   5.000000  31991.823415  ...   \n",
       "597                7.0      2.0  2000.000000   5.000000  35719.627210  ...   \n",
       "598                7.0      2.0  1874.729367   4.934673  32783.446821  ...   \n",
       "599                7.0      2.0  2790.000000   4.934673  39786.652015  ...   \n",
       "\n",
       "     AUTOEXPERT  SPOTICAR ADVANCED  SPOTICAR ESSENTIAL  SPOTICAR PREMIUM  \\\n",
       "0             0                  0                   0                 1   \n",
       "1             0                  0                   0                 1   \n",
       "2             0                  0                   0                 1   \n",
       "3             0                  0                   0                 1   \n",
       "4             0                  0                   0                 1   \n",
       "..          ...                ...                 ...               ...   \n",
       "595           0                  0                   0                 1   \n",
       "596           0                  0                   0                 1   \n",
       "597           0                  0                   0                 1   \n",
       "598           0                  0                   0                 1   \n",
       "599           0                  0                   0                 1   \n",
       "\n",
       "     Ex-Auto-école  Ex-Import  Ex-Loueur  Ex-Particulier  Ex-Société  \\\n",
       "0                0          0          1               0           0   \n",
       "1                0          0          1               0           0   \n",
       "2                0          0          1               0           0   \n",
       "3                0          0          1               0           0   \n",
       "4                0          0          0               1           0   \n",
       "..             ...        ...        ...             ...         ...   \n",
       "595              0          0          1               0           0   \n",
       "596              0          1          0               0           0   \n",
       "597              0          0          1               0           0   \n",
       "598              0          0          1               0           0   \n",
       "599              0          0          1               0           0   \n",
       "\n",
       "     Véhicule de direction  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "..                     ...  \n",
       "595                      0  \n",
       "596                      0  \n",
       "597                      0  \n",
       "598                      0  \n",
       "599                      0  \n",
       "\n",
       "[600 rows x 63 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [173], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m newdf \u001b[39m=\u001b[39mdata_finale\u001b[39m.\u001b[39mloc[\n\u001b[0;32m      2\u001b[0m     (data_finale[\u001b[39m\"\u001b[39m\u001b[39m208\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m \n\u001b[0;32m      3\u001b[0m     (data_finale[\u001b[39m\"\u001b[39m\u001b[39mEssence\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m&\u001b[39m \n\u001b[0;32m      4\u001b[0m     (data_finale[\u001b[39m'\u001b[39m\u001b[39mGris\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m&\u001b[39m\n\u001b[0;32m      5\u001b[0m     (data_finale[\u001b[39m\"\u001b[39m\u001b[39mCitadine\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m&\u001b[39m\n\u001b[1;32m----> 6\u001b[0m     (data_finale[\u001b[39m'\u001b[39;49m\u001b[39m2\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m&\u001b[39m\n\u001b[0;32m      7\u001b[0m     (data_finale\u001b[39m.\u001b[39mdate_mise_circulation \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2017\u001b[39m) \n\u001b[0;32m      8\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3804\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3806\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '2'"
     ]
    }
   ],
   "source": [
    "newdf =data_finale.loc[\n",
    "    (data_finale[\"208\"] == 1) & \n",
    "    (data_finale[\"Essence\"]) & \n",
    "    (data_finale['Gris']) &\n",
    "    (data_finale[\"Citadine\"]) &\n",
    "    (data_finale['2']) &\n",
    "    (data_finale.date_mise_circulation >= 2017) \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modele</th>\n",
       "      <th>carburant</th>\n",
       "      <th>prix</th>\n",
       "      <th>kilometrage</th>\n",
       "      <th>garantie_kilometrage</th>\n",
       "      <th>boite_de_vitesse</th>\n",
       "      <th>transmission</th>\n",
       "      <th>couleur</th>\n",
       "      <th>garantie</th>\n",
       "      <th>date_mise_circulation</th>\n",
       "      <th>puissance</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>nb_places</th>\n",
       "      <th>utilisation_prec</th>\n",
       "      <th>puissance_fiscale</th>\n",
       "      <th>critair</th>\n",
       "      <th>ptac</th>\n",
       "      <th>nb_portes</th>\n",
       "      <th>prix_predits</th>\n",
       "      <th>surplus_conso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [modele, carburant, prix, kilometrage, garantie_kilometrage, boite_de_vitesse, transmission, couleur, garantie, date_mise_circulation, puissance, silhouette, nb_places, utilisation_prec, puissance_fiscale, critair, ptac, nb_portes, prix_predits, surplus_conso]\n",
       "Index: []"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meilleur_choix = newdf.loc[newdf['surplus_conso'] == newdf['surplus_conso'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_meilleures = newdf.sort_values(by = 'surplus_conso', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modele</th>\n",
       "      <th>carburant</th>\n",
       "      <th>prix</th>\n",
       "      <th>kilometrage</th>\n",
       "      <th>garantie_kilometrage</th>\n",
       "      <th>boite_de_vitesse</th>\n",
       "      <th>transmission</th>\n",
       "      <th>couleur</th>\n",
       "      <th>garantie</th>\n",
       "      <th>date_mise_circulation</th>\n",
       "      <th>puissance</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>nb_places</th>\n",
       "      <th>utilisation_prec</th>\n",
       "      <th>puissance_fiscale</th>\n",
       "      <th>critair</th>\n",
       "      <th>ptac</th>\n",
       "      <th>nb_portes</th>\n",
       "      <th>prix_predits</th>\n",
       "      <th>surplus_conso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [modele, carburant, prix, kilometrage, garantie_kilometrage, boite_de_vitesse, transmission, couleur, garantie, date_mise_circulation, puissance, silhouette, nb_places, utilisation_prec, puissance_fiscale, critair, ptac, nb_portes, prix_predits, surplus_conso]\n",
       "Index: []"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_meilleures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_meilleures.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95d745ba7d4956a2c972602a1881faa5aacde8c57f39878a3d2b517a3ec985cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
