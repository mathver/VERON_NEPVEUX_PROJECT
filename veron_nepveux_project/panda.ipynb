{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serde import serde\n",
    "from serde.json import to_json, from_json\n",
    "from dataclasses import dataclass\n",
    "from time import sleep\n",
    "from scrapping import Voiture\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import conversion_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récuperation du json et conversion en quelque chose d'utilisable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion en base de données panda et nettoyage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarques sur les variables :\n",
    "\n",
    "- modele : enlever les espaces, ou supprimer les variables peu occurentes (<=1)\n",
    "- carburant : même remarque\n",
    "- même remarque pour toutes les variables textuelles\n",
    "- utilisation précédente : regrouper par pro/loueur/part/ ne sait pas ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de dummys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = conversion_df.data_frame_pandas('donnees_citroen.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marque                    object\n",
       "modele                    object\n",
       "carburant                 object\n",
       "prix                       int64\n",
       "kilometrage              float64\n",
       "garantie_kilometrage      object\n",
       "boite_de_vitesse          object\n",
       "transmission             float64\n",
       "couleur                   object\n",
       "garantie                  object\n",
       "date_mise_circulation      int64\n",
       "puissance                float64\n",
       "silhouette                object\n",
       "nb_places                float64\n",
       "utilisation_prec          object\n",
       "puissance_fiscale        float64\n",
       "critair                  float64\n",
       "ptac                     float64\n",
       "nb_portes                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1835.0\n",
       "1      2300.0\n",
       "2      1735.0\n",
       "3      1540.0\n",
       "4      1600.0\n",
       "        ...  \n",
       "595    1795.0\n",
       "596    1610.0\n",
       "597    1610.0\n",
       "598    1610.0\n",
       "599    1610.0\n",
       "Name: ptac, Length: 600, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ptac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marque                   string\n",
       "modele                   string\n",
       "carburant                string\n",
       "prix                      Int64\n",
       "kilometrage               Int64\n",
       "garantie_kilometrage     string\n",
       "boite_de_vitesse         string\n",
       "transmission              Int64\n",
       "couleur                  string\n",
       "garantie                 string\n",
       "date_mise_circulation     Int64\n",
       "puissance                 Int64\n",
       "silhouette               string\n",
       "nb_places                 Int64\n",
       "utilisation_prec         string\n",
       "puissance_fiscale         Int64\n",
       "critair                   Int64\n",
       "ptac                      Int64\n",
       "nb_portes                 Int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.convert_dtypes().dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passage sous numpy + ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "import conversion_df\n",
    "import pandas as pd\n",
    "\n",
    "conversion_df = reload(conversion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trp = conversion_df.data_frame_pandas('donnees_temp.json')\n",
    "df = conversion_df.data_frame_pandas('donnees_peugeot.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marque</th>\n",
       "      <th>modele</th>\n",
       "      <th>carburant</th>\n",
       "      <th>prix</th>\n",
       "      <th>kilometrage</th>\n",
       "      <th>garantie_kilometrage</th>\n",
       "      <th>boite_de_vitesse</th>\n",
       "      <th>transmission</th>\n",
       "      <th>couleur</th>\n",
       "      <th>garantie</th>\n",
       "      <th>date_mise_circulation</th>\n",
       "      <th>puissance</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>nb_places</th>\n",
       "      <th>utilisation_prec</th>\n",
       "      <th>puissance_fiscale</th>\n",
       "      <th>critair</th>\n",
       "      <th>ptac</th>\n",
       "      <th>nb_portes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peugeot</td>\n",
       "      <td>2008</td>\n",
       "      <td>Essence</td>\n",
       "      <td>30000</td>\n",
       "      <td>60000</td>\n",
       "      <td>garantie</td>\n",
       "      <td>Automatique</td>\n",
       "      <td>2</td>\n",
       "      <td>Noir</td>\n",
       "      <td>SPOTICAR PREMIUM</td>\n",
       "      <td>2020</td>\n",
       "      <td>130</td>\n",
       "      <td>SUV-4x4</td>\n",
       "      <td>5</td>\n",
       "      <td>Ex-Particulier</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    marque  modele carburant   prix  kilometrage garantie_kilometrage  \\\n",
       "0  Peugeot    2008   Essence  30000        60000             garantie   \n",
       "\n",
       "  boite_de_vitesse  transmission couleur          garantie  \\\n",
       "0      Automatique             2    Noir  SPOTICAR PREMIUM   \n",
       "\n",
       "   date_mise_circulation  puissance silhouette  nb_places utilisation_prec  \\\n",
       "0                   2020        130    SUV-4x4          5   Ex-Particulier   \n",
       "\n",
       "   puissance_fiscale  critair  ptac  nb_portes  \n",
       "0                  6        2  1500          3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trp_fin = pd.concat([df,trp], ignore_index=True)\n",
    "trp_fin_cat = conversion_df.data_frame_dummies(trp_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prix</th>\n",
       "      <th>kilometrage</th>\n",
       "      <th>date_mise_circulation</th>\n",
       "      <th>puissance</th>\n",
       "      <th>nb_places</th>\n",
       "      <th>puissance_fiscale</th>\n",
       "      <th>critair</th>\n",
       "      <th>ptac</th>\n",
       "      <th>nb_portes</th>\n",
       "      <th>Peugeot</th>\n",
       "      <th>...</th>\n",
       "      <th>AUTOEXPERT</th>\n",
       "      <th>SPOTICAR ADVANCED</th>\n",
       "      <th>SPOTICAR ESSENTIAL</th>\n",
       "      <th>SPOTICAR PREMIUM</th>\n",
       "      <th>Ex-Auto-ï¿½cole</th>\n",
       "      <th>Ex-Import</th>\n",
       "      <th>Ex-Loueur</th>\n",
       "      <th>Ex-Particulier</th>\n",
       "      <th>Ex-Sociï¿½tï¿½</th>\n",
       "      <th>Vï¿½hicule de direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20290</td>\n",
       "      <td>75967</td>\n",
       "      <td>2019</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31900</td>\n",
       "      <td>29066</td>\n",
       "      <td>2021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33920</td>\n",
       "      <td>31997</td>\n",
       "      <td>2021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21980</td>\n",
       "      <td>40952</td>\n",
       "      <td>2021</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22990</td>\n",
       "      <td>7901</td>\n",
       "      <td>2021</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>31490</td>\n",
       "      <td>2535</td>\n",
       "      <td>2022</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1770.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>37490</td>\n",
       "      <td>21164</td>\n",
       "      <td>2022</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>36490</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>38990</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>177.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>21990</td>\n",
       "      <td>19050</td>\n",
       "      <td>2021</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>601 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prix  kilometrage  date_mise_circulation  puissance  nb_places  \\\n",
       "0    20290        75967                   2019      130.0        5.0   \n",
       "1    31900        29066                   2021      130.0        5.0   \n",
       "2    33920        31997                   2021      130.0        5.0   \n",
       "3    21980        40952                   2021      100.0        5.0   \n",
       "4    22990         7901                   2021      100.0        5.0   \n",
       "..     ...          ...                    ...        ...        ...   \n",
       "596  31490         2535                   2022      131.0        5.0   \n",
       "597  37490        21164                   2022      131.0        5.0   \n",
       "598  36490           10                   2022      145.0        3.0   \n",
       "599  38990           10                   2022      177.0        6.0   \n",
       "600  21990        19050                   2021      100.0        5.0   \n",
       "\n",
       "     puissance_fiscale  critair    ptac  nb_portes  Peugeot  ...  AUTOEXPERT  \\\n",
       "0                  6.0      2.0  1890.0        5.0        1  ...           0   \n",
       "1                  7.0      2.0  1875.0        5.0        1  ...           0   \n",
       "2                  7.0      1.0  1875.0        5.0        1  ...           0   \n",
       "3                  5.0      1.0  1875.0        5.0        1  ...           0   \n",
       "4                  5.0      1.0  1875.0        5.0        1  ...           0   \n",
       "..                 ...      ...     ...        ...      ...  ...         ...   \n",
       "596                7.0      2.0  1770.0        5.0        1  ...           0   \n",
       "597                7.0      2.0  2000.0        5.0        1  ...           0   \n",
       "598                7.0      2.0  1875.0        5.0        1  ...           0   \n",
       "599                7.0      2.0  2790.0        5.0        1  ...           0   \n",
       "600                5.0      1.0    1800        5.0        1  ...           0   \n",
       "\n",
       "     SPOTICAR ADVANCED  SPOTICAR ESSENTIAL  SPOTICAR PREMIUM  Ex-Auto-ï¿½cole  \\\n",
       "0                    0                   0                 1                0   \n",
       "1                    0                   0                 1                0   \n",
       "2                    0                   0                 1                0   \n",
       "3                    0                   0                 1                0   \n",
       "4                    0                   0                 1                0   \n",
       "..                 ...                 ...               ...              ...   \n",
       "596                  0                   0                 1                0   \n",
       "597                  0                   0                 1                0   \n",
       "598                  0                   0                 1                0   \n",
       "599                  0                   0                 1                0   \n",
       "600                  0                   0                 1                0   \n",
       "\n",
       "     Ex-Import  Ex-Loueur  Ex-Particulier  Ex-Sociï¿½tï¿½  \\\n",
       "0            0          1               0               0   \n",
       "1            0          1               0               0   \n",
       "2            0          1               0               0   \n",
       "3            0          1               0               0   \n",
       "4            0          0               1               0   \n",
       "..         ...        ...             ...             ...   \n",
       "596          1          0               0               0   \n",
       "597          0          1               0               0   \n",
       "598          0          1               0               0   \n",
       "599          0          1               0               0   \n",
       "600          0          1               0               0   \n",
       "\n",
       "     Vï¿½hicule de direction  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "..                       ...  \n",
       "596                        0  \n",
       "597                        0  \n",
       "598                        0  \n",
       "599                        0  \n",
       "600                        0  \n",
       "\n",
       "[601 rows x 61 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trp_fin_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = trp_fin_cat.loc[:, trp_fin_cat.columns != 'prix'].to_numpy()\n",
    "y_pred = trp_fin_cat['prix'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = conversion_df.data_frame_dummies(df)\n",
    "X = df_cat.loc[:, df_cat.columns != 'prix'].to_numpy()\n",
    "y = df_cat['prix'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['prix', 'kilometrage', 'date_mise_circulation', 'puissance',\n",
       "       'nb_places', 'puissance_fiscale', 'critair', 'ptac', 'nb_portes',\n",
       "       'Peugeot', '108', '2008', '208', '3008', '308', '308 SW', '4008',\n",
       "       '5008', '508', '508 SW', 'BOXER', 'EXPERT', 'PARTNER', 'RIFTER',\n",
       "       'TRAVELLER', 'garanti', 'non garanti', 'Diesel', 'Electrique',\n",
       "       'Essence', 'Hybride rechargeable', 'Automatique', 'Manuelle',\n",
       "       'Blanc', 'Bleu', 'Brun', 'Gris', 'Jaune', 'Noir', 'Orange',\n",
       "       'Rouge', 'Sable', 'Vert', 'Berline', 'Break', 'Citadine',\n",
       "       'Familiale', 'SUV-4x4', 'Utilitaire', 2.0, 4.0, 'AUTOEXPERT',\n",
       "       'SPOTICAR ADVANCED', 'SPOTICAR ESSENTIAL', 'SPOTICAR PREMIUM',\n",
       "       'Ex-Auto-ï¿½cole', 'Ex-Import', 'Ex-Loueur', 'Ex-Particulier',\n",
       "       'Ex-Sociï¿½tï¿½', 'Vï¿½hicule de direction'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trp_fin_cat.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.484e+08, tolerance: 2.731e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.787e+08, tolerance: 2.769e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.808e+08, tolerance: 2.926e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.477e+08, tolerance: 2.749e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.928e+08, tolerance: 2.752e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.479e+08, tolerance: 2.731e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.789e+08, tolerance: 2.769e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.813e+08, tolerance: 2.926e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.475e+08, tolerance: 2.749e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.935e+08, tolerance: 2.752e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.470e+08, tolerance: 2.731e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.734e+08, tolerance: 2.769e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.821e+08, tolerance: 2.926e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.467e+08, tolerance: 2.749e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.924e+08, tolerance: 2.752e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.042e+08, tolerance: 2.731e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.595e+08, tolerance: 2.769e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.830e+08, tolerance: 2.926e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.428e+08, tolerance: 2.749e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.594e+08, tolerance: 2.752e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.550e+08, tolerance: 2.731e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.721e+08, tolerance: 2.769e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.858e+08, tolerance: 2.926e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.400e+08, tolerance: 2.749e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.876e+08, tolerance: 2.752e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.973e+08, tolerance: 2.731e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.787e+08, tolerance: 2.769e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.796e+08, tolerance: 2.926e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.292e+08, tolerance: 2.749e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.795e+08, tolerance: 2.752e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e+08, tolerance: 2.731e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.471e+08, tolerance: 2.769e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.960e+08, tolerance: 2.926e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.611e+08, tolerance: 2.749e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.547e+08, tolerance: 2.752e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.679e+08, tolerance: 2.731e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.918e+08, tolerance: 2.769e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.468e+08, tolerance: 2.926e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.843e+08, tolerance: 2.749e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.956e+08, tolerance: 2.752e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.632e+08, tolerance: 2.731e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.320e+07, tolerance: 2.769e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+08, tolerance: 2.926e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.771e+07, tolerance: 2.752e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.620e+08, tolerance: 2.731e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.404e+06, tolerance: 2.731e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.214e+06, tolerance: 2.731e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "en = ElasticNet()\n",
    "en_gs = GridSearchCV(\n",
    "    en,\n",
    "    {\n",
    "        \"alpha\": [2 ** p  for p in range(-6, 6)],\n",
    "        \"l1_ratio\": (0.01, 0.25, 0.5, 0.75, 1),\n",
    "    }\n",
    ")\n",
    "en_gs.fit(X_tr, y_tr) #problème vient du fit\n",
    "en_df = pd.DataFrame(en_gs.cv_results_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 16, 'l1_ratio': 1}, 0.9104061866860143)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_gs.best_params_, en_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23278.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(en_gs.best_estimator_.predict(X_pred)).iloc[-1][0].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20290, 31900, 33920, 21980, 22990, 21990, 34390, 17890, 32990,\n",
       "       20490, 18990, 11990, 26290, 33490, 17490, 32490, 25990, 26590,\n",
       "       26290, 22490, 17690, 34490, 36990, 38790, 18990, 32590, 28990,\n",
       "       25290, 16990, 22190, 23980, 33790, 38490, 22390, 22490, 26990,\n",
       "       29990, 38980, 25990, 31690, 24590, 35990, 38290, 28790, 32490,\n",
       "       26190, 34490, 23790, 26299, 38290, 35990, 21490, 25990, 16990,\n",
       "       31290, 35690, 22290, 46790, 15490, 28980, 21990, 21990, 33091,\n",
       "       30790, 40490, 28490, 36390, 17990, 39790, 17990, 38490, 23220,\n",
       "       22190, 59980, 38990, 24790, 23290, 32480, 20480, 34990, 24590,\n",
       "       27790, 38980, 28490, 23990, 26590, 22190, 15480, 23390, 34490,\n",
       "       52890, 29290, 27590, 27990, 26490, 34490, 32490, 15290, 35690,\n",
       "       27690, 35690, 39990, 42580, 36490, 26190, 32390, 35990, 28690,\n",
       "       32300, 28990, 24990, 26590, 19290, 29990, 42590, 46290, 31580,\n",
       "       52190, 42590, 37990, 28590, 19290, 39390, 39990, 39690, 26990,\n",
       "       40490, 38280, 24490, 23150, 26390, 37180, 21590, 35299, 24490,\n",
       "       38499, 37990, 37099, 24199, 34990, 42199, 36490, 38990, 14790,\n",
       "       14799, 38490, 37490, 39631, 47490, 34990, 37599, 39690, 16990,\n",
       "       28990, 14590, 18990, 22390, 25290, 24490, 33990, 17490, 28390,\n",
       "       34990, 22990, 16490, 18480, 17980, 22980, 25290, 23790, 20480,\n",
       "       39290, 22180, 27980, 12480, 34990, 19280, 33480, 12280, 18480,\n",
       "       22280, 33980, 31780, 40980, 24280, 15380, 15490, 26990, 18580,\n",
       "       32290, 38480, 34480, 22180, 29990, 22980, 24980, 42780, 30490,\n",
       "       40290, 37290, 29290, 28490, 39980, 40580, 22480, 22990, 23990,\n",
       "       33990, 28490, 26990, 36490, 28990, 36480, 28490, 37490, 28990,\n",
       "       25490, 39190, 23990, 38990, 15490, 41490, 27490, 36490, 39499,\n",
       "       35990, 40799, 28480, 17490, 18990, 22990, 10390, 24990, 15999,\n",
       "       15799, 24999, 19999, 20499, 16499, 21980, 16490, 20490, 17290,\n",
       "       16390, 22990, 30890, 25090, 17980, 22390, 16290, 29890, 18990,\n",
       "       26790, 21780, 17280, 27490, 20890, 25990, 31990, 18890, 42590,\n",
       "       18880, 19480, 26990, 35090, 17490, 28490, 17890, 19390, 24990,\n",
       "       18490, 14990, 22610, 24990, 21490, 23990, 12990, 14490, 18990,\n",
       "       17490, 17990, 21490, 24990, 25990, 26990, 19490, 20990, 21890,\n",
       "       20590, 26890, 38490, 26990, 32990, 26190, 23990, 38790, 33990,\n",
       "       25990, 24990, 42999, 37499,  8900,  7990,  7490,  7990,  7490,\n",
       "       17490,  7490, 18990, 27990, 22990, 19799, 20799, 31799, 10799,\n",
       "       13499, 13799, 29799, 17999, 31799, 33799, 17799, 24999, 28999,\n",
       "       28999, 39999, 26499, 26999, 23999, 32499, 17199, 12799, 19490,\n",
       "       28490, 17990, 19490, 26490, 10490, 37790, 28799, 17890, 42899,\n",
       "       31990, 29790, 18999, 49999, 26490, 34990, 29990, 28490, 30290,\n",
       "       23999, 40490, 19490, 27490, 36990, 16699, 26399, 21999, 38490,\n",
       "       41290, 37490, 33490, 33990, 21490, 31990, 36490, 33999, 39990,\n",
       "       36990, 36490, 29499, 37999, 18990, 20490, 29790, 33999, 31290,\n",
       "       18490, 13490, 31290, 43990, 44990, 43990, 13990, 34999, 24990,\n",
       "       28999, 22399, 19990, 38990, 33990, 16490, 16990, 24890, 22990,\n",
       "       33500, 31990, 33990, 23990, 20990, 22990, 28990, 30990, 23990,\n",
       "       45490, 16990, 30990, 10990, 13490, 14990, 36990, 27490, 25990,\n",
       "       18790, 29690, 34990, 22990, 27990, 15690, 23490, 25990, 30890,\n",
       "       27490, 25490, 36490, 35490, 26490, 11390, 15990, 33990, 23480,\n",
       "       12360, 43990, 34990, 41490, 29990, 30990, 41990, 20990, 41990,\n",
       "       31490, 14490, 31990, 28990, 18990, 32490, 20990, 35490, 11490,\n",
       "       21490, 19990, 29990, 24990, 20990, 10990, 19990, 20990, 14490,\n",
       "       22490, 20990, 28499, 18499, 14999, 26999, 25999, 15999, 37998,\n",
       "       17999, 15799, 29799, 29499, 44799, 20999, 31499, 36799, 26499,\n",
       "       38499, 41998, 21999, 18299, 19399, 15333, 24999, 18999, 33299,\n",
       "       33299, 33299, 36299, 33299, 13999, 33299, 24999, 27999, 32299,\n",
       "       33299, 15999, 11999, 18499, 13999, 34299, 27999, 27490, 29990,\n",
       "       16499, 29999, 25999, 24290, 20499, 23999, 15499, 18999, 31699,\n",
       "       23799, 33599, 16985, 23985, 21185, 21895, 34685, 23990, 14500,\n",
       "       23490, 18900, 12990, 11990, 11490, 30690, 14590, 11790, 26490,\n",
       "       17300, 43900, 31700, 20000, 28500, 32900, 20500, 32990, 38890,\n",
       "       11990,  8990, 28290, 20690, 17990, 27490, 36990, 23490, 14990,\n",
       "       21990, 13980, 17780, 11083, 13980, 34780, 17990, 22990, 22990,\n",
       "       14290, 12990, 38490, 12490, 24990, 32990, 37990, 22990, 26490,\n",
       "       31490, 25990, 26990, 24490, 22990, 17990, 17990, 26990, 18490,\n",
       "       35490, 24990, 12290, 22490, 21490, 28990, 16490, 12490, 33990,\n",
       "       37490, 17990, 34990, 27490, 12490, 22990, 17990, 22990, 17790,\n",
       "       32990, 33990, 31490, 37490, 36490, 38990, 21990], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr = KNeighborsRegressor()\n",
    "knr_gs = GridSearchCV(\n",
    "    knr,\n",
    "    {\n",
    "        \"n_neighbors\": range(5, 15),\n",
    "        \"weights\": (\"uniform\", \"distance\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.053869</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform'}</td>\n",
       "      <td>0.237296</td>\n",
       "      <td>0.138595</td>\n",
       "      <td>0.085176</td>\n",
       "      <td>0.199244</td>\n",
       "      <td>0.242035</td>\n",
       "      <td>0.180469</td>\n",
       "      <td>0.060343</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.010615</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.310453</td>\n",
       "      <td>0.242396</td>\n",
       "      <td>0.161994</td>\n",
       "      <td>0.256855</td>\n",
       "      <td>0.352684</td>\n",
       "      <td>0.264876</td>\n",
       "      <td>0.064718</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'uniform'}</td>\n",
       "      <td>0.226388</td>\n",
       "      <td>0.150351</td>\n",
       "      <td>0.076146</td>\n",
       "      <td>0.150914</td>\n",
       "      <td>0.250056</td>\n",
       "      <td>0.170771</td>\n",
       "      <td>0.061878</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'distance'}</td>\n",
       "      <td>0.320819</td>\n",
       "      <td>0.256992</td>\n",
       "      <td>0.164710</td>\n",
       "      <td>0.260437</td>\n",
       "      <td>0.362410</td>\n",
       "      <td>0.273074</td>\n",
       "      <td>0.066965</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'uniform'}</td>\n",
       "      <td>0.136164</td>\n",
       "      <td>0.192242</td>\n",
       "      <td>0.077164</td>\n",
       "      <td>0.164597</td>\n",
       "      <td>0.241459</td>\n",
       "      <td>0.162325</td>\n",
       "      <td>0.054953</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.000796      0.000398         0.036902        0.053869   \n",
       "1       0.000596      0.000486         0.010615        0.001336   \n",
       "2       0.000599      0.000489         0.006581        0.000797   \n",
       "3       0.000798      0.000399         0.007579        0.000488   \n",
       "4       0.000362      0.000448         0.006197        0.000723   \n",
       "\n",
       "  param_n_neighbors param_weights                                     params  \\\n",
       "0                 5       uniform   {'n_neighbors': 5, 'weights': 'uniform'}   \n",
       "1                 5      distance  {'n_neighbors': 5, 'weights': 'distance'}   \n",
       "2                 6       uniform   {'n_neighbors': 6, 'weights': 'uniform'}   \n",
       "3                 6      distance  {'n_neighbors': 6, 'weights': 'distance'}   \n",
       "4                 7       uniform   {'n_neighbors': 7, 'weights': 'uniform'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.237296           0.138595           0.085176           0.199244   \n",
       "1           0.310453           0.242396           0.161994           0.256855   \n",
       "2           0.226388           0.150351           0.076146           0.150914   \n",
       "3           0.320819           0.256992           0.164710           0.260437   \n",
       "4           0.136164           0.192242           0.077164           0.164597   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.242035         0.180469        0.060343               11  \n",
       "1           0.352684         0.264876        0.064718               10  \n",
       "2           0.250056         0.170771        0.061878               13  \n",
       "3           0.362410         0.273074        0.066965                2  \n",
       "4           0.241459         0.162325        0.054953               18  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knr_gs.fit(X_tr, y_tr)\n",
    "knr_df = pd.DataFrame(knr_gs.cv_results_)\n",
    "knr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_neighbors': 10, 'weights': 'distance'}, 0.27441340092389555)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knr_gs.best_params_, knr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr_gs = GridSearchCV(\n",
    "    rfr,\n",
    "    {   \n",
    "        \"n_estimators\": (8 , 16, 32, 64, 128, 256),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030977</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_estimators': 8}</td>\n",
       "      <td>0.863831</td>\n",
       "      <td>0.923225</td>\n",
       "      <td>0.915406</td>\n",
       "      <td>0.869892</td>\n",
       "      <td>0.919614</td>\n",
       "      <td>0.898394</td>\n",
       "      <td>0.025935</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053447</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_estimators': 16}</td>\n",
       "      <td>0.859975</td>\n",
       "      <td>0.910930</td>\n",
       "      <td>0.901864</td>\n",
       "      <td>0.866947</td>\n",
       "      <td>0.912811</td>\n",
       "      <td>0.890505</td>\n",
       "      <td>0.022498</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105126</td>\n",
       "      <td>0.010302</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>32</td>\n",
       "      <td>{'n_estimators': 32}</td>\n",
       "      <td>0.863968</td>\n",
       "      <td>0.920875</td>\n",
       "      <td>0.925860</td>\n",
       "      <td>0.879619</td>\n",
       "      <td>0.925305</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.026114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204340</td>\n",
       "      <td>0.014336</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>64</td>\n",
       "      <td>{'n_estimators': 64}</td>\n",
       "      <td>0.856954</td>\n",
       "      <td>0.923371</td>\n",
       "      <td>0.928749</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.929887</td>\n",
       "      <td>0.902459</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430837</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>128</td>\n",
       "      <td>{'n_estimators': 128}</td>\n",
       "      <td>0.862111</td>\n",
       "      <td>0.919943</td>\n",
       "      <td>0.929261</td>\n",
       "      <td>0.876534</td>\n",
       "      <td>0.927674</td>\n",
       "      <td>0.903105</td>\n",
       "      <td>0.028135</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.030977      0.001561         0.001136        0.000445   \n",
       "1       0.053447      0.001018         0.002006        0.000013   \n",
       "2       0.105126      0.010302         0.003179        0.000749   \n",
       "3       0.204340      0.014336         0.004864        0.000777   \n",
       "4       0.430837      0.021800         0.009987        0.001670   \n",
       "\n",
       "  param_n_estimators                 params  split0_test_score  \\\n",
       "0                  8    {'n_estimators': 8}           0.863831   \n",
       "1                 16   {'n_estimators': 16}           0.859975   \n",
       "2                 32   {'n_estimators': 32}           0.863968   \n",
       "3                 64   {'n_estimators': 64}           0.856954   \n",
       "4                128  {'n_estimators': 128}           0.862111   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.923225           0.915406           0.869892           0.919614   \n",
       "1           0.910930           0.901864           0.866947           0.912811   \n",
       "2           0.920875           0.925860           0.879619           0.925305   \n",
       "3           0.923371           0.928749           0.873333           0.929887   \n",
       "4           0.919943           0.929261           0.876534           0.927674   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.898394        0.025935                5  \n",
       "1         0.890505        0.022498                6  \n",
       "2         0.903125        0.026114                2  \n",
       "3         0.902459        0.030983                4  \n",
       "4         0.903105        0.028135                3  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_gs.fit(X_tr, y_tr)\n",
    "rfr_df = pd.DataFrame(rfr_gs.cv_results_)\n",
    "rfr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 256}, 0.9048408377007304)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_gs.best_params_, rfr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_epsilon</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.1}</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.057369</td>\n",
       "      <td>-0.201811</td>\n",
       "      <td>-0.029707</td>\n",
       "      <td>-0.115842</td>\n",
       "      <td>-0.080923</td>\n",
       "      <td>0.071524</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007984</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 1.0}</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.057370</td>\n",
       "      <td>-0.201811</td>\n",
       "      <td>-0.029701</td>\n",
       "      <td>-0.115827</td>\n",
       "      <td>-0.080919</td>\n",
       "      <td>0.071523</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 10}</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.056837</td>\n",
       "      <td>-0.201811</td>\n",
       "      <td>-0.029279</td>\n",
       "      <td>-0.116559</td>\n",
       "      <td>-0.080874</td>\n",
       "      <td>0.071692</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1.0, 'epsilon': 0.1}</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>-0.055183</td>\n",
       "      <td>-0.200572</td>\n",
       "      <td>-0.027467</td>\n",
       "      <td>-0.115196</td>\n",
       "      <td>-0.079428</td>\n",
       "      <td>0.071772</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008629</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.005003</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'epsilon': 1.0}</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>-0.055180</td>\n",
       "      <td>-0.200572</td>\n",
       "      <td>-0.027467</td>\n",
       "      <td>-0.115196</td>\n",
       "      <td>-0.079427</td>\n",
       "      <td>0.071773</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.009369      0.001486         0.005388        0.001955     0.1   \n",
       "1       0.007984      0.000621         0.003935        0.000644     0.1   \n",
       "2       0.008379      0.000488         0.004378        0.000497     0.1   \n",
       "3       0.009176      0.001162         0.004388        0.000488     1.0   \n",
       "4       0.008629      0.001687         0.005003        0.001116     1.0   \n",
       "\n",
       "  param_epsilon                      params  split0_test_score  \\\n",
       "0           0.1  {'C': 0.1, 'epsilon': 0.1}           0.000116   \n",
       "1           1.0  {'C': 0.1, 'epsilon': 1.0}           0.000116   \n",
       "2            10   {'C': 0.1, 'epsilon': 10}           0.000116   \n",
       "3           0.1  {'C': 1.0, 'epsilon': 0.1}           0.001278   \n",
       "4           1.0  {'C': 1.0, 'epsilon': 1.0}           0.001278   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -0.057369          -0.201811          -0.029707          -0.115842   \n",
       "1          -0.057370          -0.201811          -0.029701          -0.115827   \n",
       "2          -0.056837          -0.201811          -0.029279          -0.116559   \n",
       "3          -0.055183          -0.200572          -0.027467          -0.115196   \n",
       "4          -0.055180          -0.200572          -0.027467          -0.115196   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -0.080923        0.071524                9  \n",
       "1        -0.080919        0.071523                8  \n",
       "2        -0.080874        0.071692                7  \n",
       "3        -0.079428        0.071772                6  \n",
       "4        -0.079427        0.071773                5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr_gs = GridSearchCV(\n",
    "    svr,\n",
    "    {\n",
    "        \"C\": (0.1, 1.0, 10),\n",
    "        \"epsilon\": (0.1, 1.0, 10),\n",
    "    }\n",
    ")\n",
    "svr_gs.fit(X_tr, y_tr)\n",
    "\n",
    "svr_df = pd.DataFrame(svr_gs.cv_results_)\n",
    "svr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 10, 'epsilon': 0.1}, -0.0679771280241436)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_gs.best_params_, svr_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(\n",
    "    [\n",
    "        (\"mise_echelle\", MinMaxScaler()),\n",
    "        (\"support_vecteurs\", SVR()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_gs = GridSearchCV(\n",
    "    pl,\n",
    "    {\n",
    "        \"support_vecteurs__C\": (0.1, 1.0, 10),\n",
    "        \"support_vecteurs__epsilon\": (0.1, 1.0, 10),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_support_vecteurs__C</th>\n",
       "      <th>param_support_vecteurs__epsilon</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'support_vecteurs__C': 0.1, 'support_vecteurs...</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>-0.057256</td>\n",
       "      <td>-0.201915</td>\n",
       "      <td>-0.029561</td>\n",
       "      <td>-0.115632</td>\n",
       "      <td>-0.080811</td>\n",
       "      <td>0.071610</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008577</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'support_vecteurs__C': 0.1, 'support_vecteurs...</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>-0.057221</td>\n",
       "      <td>-0.201915</td>\n",
       "      <td>-0.029556</td>\n",
       "      <td>-0.115663</td>\n",
       "      <td>-0.080809</td>\n",
       "      <td>0.071616</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008384</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'support_vecteurs__C': 0.1, 'support_vecteurs...</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>-0.056686</td>\n",
       "      <td>-0.201915</td>\n",
       "      <td>-0.029134</td>\n",
       "      <td>-0.116420</td>\n",
       "      <td>-0.080770</td>\n",
       "      <td>0.071787</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'support_vecteurs__C': 1.0, 'support_vecteurs...</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>-0.054037</td>\n",
       "      <td>-0.199610</td>\n",
       "      <td>-0.026008</td>\n",
       "      <td>-0.113175</td>\n",
       "      <td>-0.077928</td>\n",
       "      <td>0.071966</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.004791</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'support_vecteurs__C': 1.0, 'support_vecteurs...</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>-0.054045</td>\n",
       "      <td>-0.199610</td>\n",
       "      <td>-0.026008</td>\n",
       "      <td>-0.113175</td>\n",
       "      <td>-0.077930</td>\n",
       "      <td>0.071965</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.008177      0.000977         0.004787        0.000747   \n",
       "1       0.008577      0.000790         0.005180        0.001463   \n",
       "2       0.008384      0.000484         0.003990        0.000891   \n",
       "3       0.008373      0.000489         0.004778        0.000980   \n",
       "4       0.008773      0.000397         0.004791        0.000753   \n",
       "\n",
       "  param_support_vecteurs__C param_support_vecteurs__epsilon  \\\n",
       "0                       0.1                             0.1   \n",
       "1                       0.1                             1.0   \n",
       "2                       0.1                              10   \n",
       "3                       1.0                             0.1   \n",
       "4                       1.0                             1.0   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'support_vecteurs__C': 0.1, 'support_vecteurs...           0.000307   \n",
       "1  {'support_vecteurs__C': 0.1, 'support_vecteurs...           0.000307   \n",
       "2  {'support_vecteurs__C': 0.1, 'support_vecteurs...           0.000307   \n",
       "3  {'support_vecteurs__C': 1.0, 'support_vecteurs...           0.003189   \n",
       "4  {'support_vecteurs__C': 1.0, 'support_vecteurs...           0.003189   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -0.057256          -0.201915          -0.029561          -0.115632   \n",
       "1          -0.057221          -0.201915          -0.029556          -0.115663   \n",
       "2          -0.056686          -0.201915          -0.029134          -0.116420   \n",
       "3          -0.054037          -0.199610          -0.026008          -0.113175   \n",
       "4          -0.054045          -0.199610          -0.026008          -0.113175   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -0.080811        0.071610                9  \n",
       "1        -0.080809        0.071616                8  \n",
       "2        -0.080770        0.071787                7  \n",
       "3        -0.077928        0.071966                4  \n",
       "4        -0.077930        0.071965                5  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_gs.fit(X_tr, y_tr)\n",
    "\n",
    "pl_df = pd.DataFrame(pl_gs.cv_results_)\n",
    "pl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'support_vecteurs__C': 10, 'support_vecteurs__epsilon': 10},\n",
       " -0.04766514608492325)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_gs.best_params_, pl_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln = Pipeline(\n",
    "    [\n",
    "        (\"mise_echelle\", MinMaxScaler()),\n",
    "        (\"neurones\", MLPRegressor()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln_gs = GridSearchCV(\n",
    "    pln,\n",
    "    {\n",
    "        \"neurones__alpha\": 10.0 ** -np.arange(1, 7),\n",
    "        'neurones__hidden_layer_sizes': ((25,), (50, ), (100,), (20, 20)),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_neurones__alpha</th>\n",
       "      <th>param_neurones__hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.276860</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(25,)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-7.265260</td>\n",
       "      <td>-7.803490</td>\n",
       "      <td>-7.418769</td>\n",
       "      <td>-8.308542</td>\n",
       "      <td>-7.885371</td>\n",
       "      <td>-7.736286</td>\n",
       "      <td>0.367941</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.557897</td>\n",
       "      <td>0.022063</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-7.169583</td>\n",
       "      <td>-7.742505</td>\n",
       "      <td>-7.361349</td>\n",
       "      <td>-8.244487</td>\n",
       "      <td>-7.828612</td>\n",
       "      <td>-7.669307</td>\n",
       "      <td>0.375801</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.553783</td>\n",
       "      <td>0.028081</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-7.104080</td>\n",
       "      <td>-7.622723</td>\n",
       "      <td>-7.283237</td>\n",
       "      <td>-8.092599</td>\n",
       "      <td>-7.723177</td>\n",
       "      <td>-7.565163</td>\n",
       "      <td>0.345991</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.179531</td>\n",
       "      <td>0.012099</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>{'neurones__alpha': 0.1, 'neurones__hidden_lay...</td>\n",
       "      <td>-6.613025</td>\n",
       "      <td>-7.484969</td>\n",
       "      <td>-6.646206</td>\n",
       "      <td>-7.246459</td>\n",
       "      <td>-7.058851</td>\n",
       "      <td>-7.009902</td>\n",
       "      <td>0.338771</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.270261</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(25,)</td>\n",
       "      <td>{'neurones__alpha': 0.01, 'neurones__hidden_la...</td>\n",
       "      <td>-7.257464</td>\n",
       "      <td>-7.810626</td>\n",
       "      <td>-7.397353</td>\n",
       "      <td>-8.338590</td>\n",
       "      <td>-7.873456</td>\n",
       "      <td>-7.735498</td>\n",
       "      <td>0.382428</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.276860      0.008912         0.000604        0.000493   \n",
       "1       0.557897      0.022063         0.000923        0.000146   \n",
       "2       0.553783      0.028081         0.001001        0.000010   \n",
       "3       0.179531      0.012099         0.000395        0.000483   \n",
       "4       0.270261      0.001663         0.000817        0.000409   \n",
       "\n",
       "  param_neurones__alpha param_neurones__hidden_layer_sizes  \\\n",
       "0                   0.1                              (25,)   \n",
       "1                   0.1                              (50,)   \n",
       "2                   0.1                             (100,)   \n",
       "3                   0.1                           (20, 20)   \n",
       "4                  0.01                              (25,)   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -7.265260   \n",
       "1  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -7.169583   \n",
       "2  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -7.104080   \n",
       "3  {'neurones__alpha': 0.1, 'neurones__hidden_lay...          -6.613025   \n",
       "4  {'neurones__alpha': 0.01, 'neurones__hidden_la...          -7.257464   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -7.803490          -7.418769          -8.308542          -7.885371   \n",
       "1          -7.742505          -7.361349          -8.244487          -7.828612   \n",
       "2          -7.622723          -7.283237          -8.092599          -7.723177   \n",
       "3          -7.484969          -6.646206          -7.246459          -7.058851   \n",
       "4          -7.810626          -7.397353          -8.338590          -7.873456   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -7.736286        0.367941               23  \n",
       "1        -7.669307        0.375801               14  \n",
       "2        -7.565163        0.345991               10  \n",
       "3        -7.009902        0.338771                3  \n",
       "4        -7.735498        0.382428               22  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln_gs.fit(X_tr, y_tr)\n",
    "\n",
    "pln_df = pd.DataFrame(pln_gs.cv_results_)\n",
    "pln_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.913083383837953"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln_gs.best_params_\n",
    "\n",
    "pln_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neurones__alpha': 0.0001, 'neurones__hidden_layer_sizes': (20, 20)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai = en_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0629e+04, 2.0210e+03, 1.1000e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [5.1040e+03, 2.0220e+03, 1.8100e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [8.9000e+03, 2.0210e+03, 1.3100e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       ...,\n",
       "       [3.0000e+01, 2.0220e+03, 1.1000e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [3.0000e+01, 2.0220e+03, 1.1000e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [3.0000e+01, 2.0220e+03, 1.1000e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prix_prédits = essai.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prix_reels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([22990, 42790, 23990, 17290, 17490, 26980, 37390, 17990, 18490,\n",
       "        13790, 12280, 29790, 33790, 11480, 27290, 14990, 10990, 13990,\n",
       "        31990, 23990, 10990, 23990, 19990, 11990, 24990, 23490, 34990,\n",
       "        22990,  9790, 13990, 15990, 13790, 26790, 19390, 26790, 13990,\n",
       "        24990, 26990, 27990, 22890, 14990, 21990, 26990, 15790, 15790,\n",
       "        15790, 14990, 27790, 10990, 26990, 15490, 27990,  7490, 21990,\n",
       "         9990, 18990, 11990, 18890, 19990, 19890, 13990, 22990, 13990,\n",
       "        27990, 25990, 15980, 27490, 45990, 27490, 22990, 24990, 16990,\n",
       "        15990, 20990, 26990, 26990, 43990, 14490, 24990, 19990, 18990,\n",
       "        16490, 17990, 20990, 23990, 19490, 31990, 20490, 18990, 19790,\n",
       "        18990,  9790, 33990, 17490, 16990, 36990, 13990, 27490, 13990,\n",
       "        32990, 34990, 26890, 11990, 39000, 27900, 11500, 26900, 30900,\n",
       "        31900, 29500, 49000, 18900, 18800, 17900, 22400, 25900, 16500,\n",
       "        30500, 28500, 27900, 22500, 36500, 44990, 23900, 18900, 40900,\n",
       "        26900, 21000, 29500, 14900, 29500, 30900, 21000, 19500, 19300,\n",
       "        21100, 15500, 19800, 19900, 32900, 27900, 17500, 28500, 27490,\n",
       "        13500, 19500, 17900, 13490, 10990, 12490, 18990, 24990, 15990,\n",
       "        10990, 13490, 12490, 15990, 16490, 23990, 32990, 14990, 23990,\n",
       "        24990, 14490, 17490, 27990, 12990, 17490, 12990, 17490, 23990,\n",
       "        22990, 41990, 24990, 39790, 22900, 18490, 23490, 16490, 17990,\n",
       "        29490, 26490, 16490, 24490, 27990, 25490, 24990, 24990, 24990,\n",
       "        18990, 16990,  9990, 18490, 22990, 18990, 24990, 15990, 19990,\n",
       "        16990, 18990, 22990, 13850, 29490, 24990, 13490, 17990, 35990,\n",
       "        27990, 11990, 34900, 26990, 25990, 18990, 19990, 15990, 18990,\n",
       "        11990, 27990, 26990, 16490, 14200, 14500, 28990, 18990, 27900,\n",
       "        28900, 31500, 15499, 24990, 15990, 23490, 26499, 22490, 24995,\n",
       "        25999, 29100, 16500, 26890, 18995, 15990, 18990, 18300, 28900,\n",
       "        26990, 24990, 16990, 15990, 13500, 15980, 17990, 14900, 11500,\n",
       "        14900, 18990, 24300, 18340, 20150, 31350, 23990, 14990,  9600,\n",
       "        14900, 20990, 28900, 28900, 28900, 28900, 27900, 24300, 14500,\n",
       "        29900, 23195, 13450, 39990, 29250, 16150, 14050, 29250, 18250,\n",
       "        28850, 21350, 19950, 27250, 26850, 21250, 22450, 29650, 28250,\n",
       "        25990, 37188, 13790, 15990, 18790, 18990, 25490, 17990, 31990,\n",
       "        10790, 11990,  8990, 36290, 20999, 13899, 12299, 17999, 20999,\n",
       "        18499, 18490, 13899, 14499, 14199, 13999, 25499, 14499, 14499,\n",
       "        13999, 14499, 24999, 14499, 28799, 29499, 38999, 13285, 13200,\n",
       "        19485, 22295, 18490, 13995, 11325, 34985, 11485, 16990, 12490,\n",
       "         9890, 25490, 12490,  8490, 37980, 14980, 11780, 39990, 14780,\n",
       "        49990, 17980, 31390, 25250, 14980, 14950, 23950, 13980, 15980,\n",
       "        20950, 47490, 28480, 26490, 23880, 30990, 39590, 24780, 36990,\n",
       "        23900, 24950, 28450, 38250, 33213, 25890, 28600, 16950, 28450,\n",
       "        13850, 15880, 25480,  9950, 24480, 14280, 17480, 17950, 12480,\n",
       "        18280, 22780, 21250, 19480, 31780, 17280, 23980, 14350, 17440,\n",
       "        16780, 16280, 19480, 23480, 23250, 27242, 25480, 17480, 21980,\n",
       "        15450, 18834, 18280, 15250, 19780, 15750, 20250, 37480, 27980,\n",
       "        27450, 16200, 16250, 16200, 16250, 20250, 35780, 15980, 20150,\n",
       "        15700, 20150, 16600, 44980, 16980, 17280, 20980, 15280, 15480,\n",
       "        37980, 33890, 49990, 26780, 17980, 40980, 15280, 34490, 29990,\n",
       "        31490, 29990, 20388, 28990, 13990, 20990, 12490, 19490, 16990,\n",
       "        26990, 26990, 31990, 12490, 18799, 28990, 13890, 11490, 22490,\n",
       "        15990, 12490, 13490, 12990, 11890, 11990, 19990, 36490, 21990,\n",
       "        31990, 27390, 27990, 27390, 31990, 27990, 15990, 11990, 13490,\n",
       "        26490, 14490, 19990, 15990, 15990, 11990, 15990, 19990, 27990,\n",
       "        17990, 15990, 19990, 15990, 29990,  9990, 20990, 20990, 14490,\n",
       "        14900, 20990, 45900, 15490, 18490, 21490, 18490, 18490, 15990,\n",
       "        11290, 16990, 11490, 18990, 11490, 10890, 14990, 18490, 13990,\n",
       "        21990, 14990, 15990, 15490, 38490, 33990, 20490, 45990, 12990,\n",
       "        13990, 38990, 12990, 24990, 26490, 19990, 18990, 23990, 12490,\n",
       "        15490, 48990, 27990, 15490, 11990, 37290, 28990, 17490, 29490,\n",
       "        19900,  8990, 14700, 13900, 17290, 28900, 22900, 25900, 21490,\n",
       "        28900, 31900, 20490, 17900, 28900, 13900, 21900, 20900, 13490,\n",
       "        29900, 15900, 14900, 21790, 18900, 15490, 27489, 15489, 19889,\n",
       "        13989, 16989, 15489, 32960, 29000, 13490, 23950, 11378, 16989,\n",
       "        17389, 35489, 19990, 25989, 34689, 15889, 11989, 16989, 11999,\n",
       "        13889, 18989, 15889, 36849, 13999, 11999, 32989, 32989, 21589,\n",
       "        22979, 32489, 11399, 36790, 12879, 13799, 15799, 21489, 16989,\n",
       "        19989, 17579, 22689, 22689, 22689, 22689], dtype=int64),\n",
       " array([22032.16884637, 41493.97568329, 24969.01072275, 17015.3782826 ,\n",
       "        17126.27646582, 27114.10183904, 33576.76423118, 19583.24971472,\n",
       "        18458.24464883, 16119.24664827, 11553.52919896, 28559.24319469,\n",
       "        33350.51359537, 12961.59346727, 27344.15342119, 15604.64210085,\n",
       "        10332.40695653, 15868.1933297 , 35350.51151928, 24947.14173634,\n",
       "         9507.27973956, 24999.61094805, 20437.72395714, 16183.5785166 ,\n",
       "        27850.37764051, 24385.08499141, 37405.14574699, 23939.98606217,\n",
       "        11153.80307871, 11257.19463506, 16320.25719375, 12501.68882293,\n",
       "        26683.83113381, 18697.69449216, 27204.38577592, 13768.77143029,\n",
       "        26995.87023121, 31328.11651601, 30319.07857488, 22677.05061951,\n",
       "        15929.1929971 , 21785.09065053, 27350.29152896, 17481.89883403,\n",
       "        16997.2907344 , 17008.89317683, 16604.82248709, 28832.39067338,\n",
       "        11051.50005201, 28996.1101355 , 15901.17853315, 26686.1155067 ,\n",
       "         6650.5662699 , 23074.67351689, 11616.04192409, 20669.03596089,\n",
       "        11358.93640592, 20117.74131627, 20718.46461345, 22993.67238777,\n",
       "        14660.63925068, 23948.73624228, 13376.76084315, 29987.95737348,\n",
       "        27141.23274189, 16325.18439697, 25271.28647523, 46985.94534936,\n",
       "        28155.12638628, 23556.00680641, 26584.09624549, 16308.80218015,\n",
       "        14859.24238181, 21145.08940523, 26632.84303938, 24988.96406895,\n",
       "        40162.16637192, 13142.24710183, 24169.2926553 , 17940.32029912,\n",
       "        15902.2504726 , 15292.82517551, 18265.28574553, 20727.08287248,\n",
       "        23285.67704694, 15707.66116519, 28636.74769687, 18761.75969968,\n",
       "        14814.80873764, 17827.14308292, 15071.39516383,  4902.57402336,\n",
       "        30957.8890345 , 16162.94362214, 14104.33457989, 32241.5444019 ,\n",
       "        11940.93630392, 25277.3932859 , 13501.36295835, 30394.90920751,\n",
       "        32529.28850541, 23815.71941918, 12352.15895519, 33273.46400833,\n",
       "        29367.34218642,  7847.64494393, 25896.366726  , 28236.80585252,\n",
       "        29826.61015542, 26864.74683905, 46426.43789215, 17374.84490606,\n",
       "        16973.29088805, 18159.82012588, 19627.88377635, 24988.59238854,\n",
       "        18394.38708687, 29671.0862962 , 29974.49128361, 26528.60224143,\n",
       "        23105.87563573, 33013.28976272, 40992.68196919, 26710.57804033,\n",
       "        17374.84490606, 39811.56337394, 26769.88229728, 19892.59706936,\n",
       "        29213.24688099, 14401.38251957, 29807.33871942, 33284.30689278,\n",
       "        19030.31293024, 18374.52361096, 16718.91785975, 23105.87563573,\n",
       "        14556.50314409, 20783.48636758, 16767.55085198, 28680.73695063,\n",
       "        24227.70823932, 14483.97634384, 26335.98956639, 26766.84908071,\n",
       "        11837.55701326, 15883.42103534, 18980.83950275, 16300.94629872,\n",
       "        10782.14395941, 12550.02357793, 19667.49434723, 26319.09136745,\n",
       "        17739.97232954,  5415.99405466, 13348.09580941, 12804.52240446,\n",
       "        16729.67294472, 16935.62137146, 24301.92333544, 33750.37496652,\n",
       "        16163.44502529, 21408.28605127, 25411.03951085, 16409.10079139,\n",
       "        20527.16054165, 27587.89320749, 12070.82080825, 19445.49869893,\n",
       "        12070.82080825, 19445.49869893, 23855.83823108, 21972.213002  ,\n",
       "        41590.01322558, 24922.55460572, 40608.62028196, 21684.87692947,\n",
       "        19785.00624329, 24008.59340863, 14361.71637686, 16431.71071812,\n",
       "        27721.05898276, 28182.28720894, 17407.6352632 , 20188.75169754,\n",
       "        29213.42872829, 27613.29706664, 23740.66667812, 23892.34586549,\n",
       "        23790.13337879, 17721.90640933, 18354.03191447,  9721.06973939,\n",
       "        17744.53795967, 22580.21748946, 19790.49884426, 23187.57966636,\n",
       "        13803.70561034, 21341.79174113, 16754.22688999, 18694.82333065,\n",
       "        22743.55996813, 15857.62451575, 28010.40615463, 23095.03802971,\n",
       "        13084.78054452, 17749.76964721, 33612.1273641 , 27076.94358413,\n",
       "        12283.00674533, 32253.70464586, 27120.06397257, 25817.53255569,\n",
       "        18263.92149185, 22166.9350696 , 18773.52877903, 19905.92169013,\n",
       "        14192.75123877, 27961.84294222, 29890.97742311, 17480.48237594,\n",
       "        14772.02958685, 17044.13780605, 30257.86335952, 20402.85341452,\n",
       "        26897.8487709 , 26993.93366841, 30312.26793558, 15226.82177855,\n",
       "        26927.60914573, 15149.92589355, 23410.05318677, 26804.80943896,\n",
       "        23034.91999699, 25744.93674696, 27250.89428199, 29331.58262836,\n",
       "        17840.2253371 , 27112.4414427 , 20049.56946381, 15204.18641774,\n",
       "        20898.29371258, 19932.85028245, 28464.70939286, 28150.2745974 ,\n",
       "        26600.93438933, 16425.25525467, 14760.18758514, 13360.43137631,\n",
       "        16094.72225145, 17907.90046451, 17565.81231081, 11097.24832555,\n",
       "        17548.72128783, 16763.85918125, 23850.42255827, 18775.96613278,\n",
       "        20150.36773632, 33459.01546071, 23609.93550849, 12196.93891702,\n",
       "        12413.30617384, 16770.80556898, 21845.36463768, 26828.99834904,\n",
       "        26890.90120058, 26953.18307168, 26970.86773495, 27072.88970828,\n",
       "        24247.79193946, 15912.29543603, 27800.67582361, 19694.99121251,\n",
       "        12804.92965217, 36188.50519352, 27285.8405607 , 13214.93599921,\n",
       "        12524.53215897, 26445.18455212, 16919.3208199 , 29354.92888488,\n",
       "        19648.65952786, 22465.8382469 , 28140.84455085, 25177.54374892,\n",
       "        21472.27789784, 25488.27989623, 26511.11189397, 27220.68232053,\n",
       "        25046.13575117, 35741.5751152 , 13751.64897978, 14295.7714834 ,\n",
       "        17391.00123279, 19175.30466713, 23227.9439873 , 18468.98701533,\n",
       "        26275.76498031, 10716.84541485, 11969.23671064,  6737.20406084,\n",
       "        39883.0557719 , 22156.14441774, 14812.0474643 , 10008.30855428,\n",
       "        20337.84333505, 21613.73982728, 18149.14933876, 18248.2874153 ,\n",
       "        14509.14712572, 15670.83663141, 15085.57330775, 14777.240137  ,\n",
       "        27152.95704157, 15443.23422777, 15442.95632495, 14691.64607068,\n",
       "        15352.01262948, 24988.75023303, 15315.4684096 , 28583.48961142,\n",
       "        28632.02895614, 33529.25597384, 13994.70292254, 15593.27424773,\n",
       "        22826.93574239, 22127.83913393, 20905.85797306, 12580.58965014,\n",
       "         9349.39697002, 32412.63175153, 14143.77192575, 19471.06487019,\n",
       "        11381.37463788,  8398.04313168, 27228.0597585 , 18557.65322095,\n",
       "        10793.9776733 , 34116.51486406, 16196.15592088, 10829.27268464,\n",
       "        41784.44265501, 14288.85991997, 47211.2692821 , 17620.17805374,\n",
       "        29015.23940603, 26527.24057421, 16015.49374343, 15855.9080532 ,\n",
       "        25661.3236766 , 15511.06330186, 15739.69887159, 25223.50115704,\n",
       "        42227.63676511, 27260.59853917, 27093.25912808, 20165.88202077,\n",
       "        37816.38526655, 33815.48123374, 23903.26177152, 35745.63802905,\n",
       "        26771.7675065 , 27232.0337484 , 28689.92134502, 32794.62429307,\n",
       "        33695.91066041, 28788.74003233, 32520.10797563, 16870.83656911,\n",
       "        28766.89317526, 14025.74043849, 16084.16571463, 28368.2454253 ,\n",
       "         7381.80809545, 23446.35743253, 11536.49149595, 17575.89664829,\n",
       "        17221.28020771, 12173.16861696, 17421.90156122, 23246.6736923 ,\n",
       "        24065.65247669, 19446.31953463, 32790.33396716, 15557.08721146,\n",
       "        21591.70398464, 16290.68902283, 18341.68233261, 17585.83775694,\n",
       "        16914.67466894, 19909.96131916, 24834.55330663, 25310.99381372,\n",
       "        26538.8151698 , 27534.34759068, 17352.88572415, 22054.7485284 ,\n",
       "        16798.83800102, 19062.90589496, 19855.78031639, 16946.33491889,\n",
       "        22787.00394071, 17743.72526103, 22259.3903808 , 35922.43211305,\n",
       "        27921.16518744, 27976.23307591, 17681.0203421 , 17436.33150706,\n",
       "        17802.64065733, 17565.90369351, 22092.44026604, 39433.08055442,\n",
       "        17729.93123714, 21974.33157062, 17215.43201399, 20586.05037286,\n",
       "        16957.38155569, 46246.47519741, 20995.89838207, 19541.27648578,\n",
       "        22940.30266076, 16339.28914393, 16813.51093254, 36069.53234707,\n",
       "        29524.70014592, 47298.61765475, 25999.50451873, 19340.0237333 ,\n",
       "        35673.67302849, 17201.77399691, 34628.46859955, 29058.73801757,\n",
       "        29872.77022436, 30281.19260837, 21177.38626541, 28803.15680668,\n",
       "        13163.91275458, 22468.72975752, 13284.40144628, 19273.68174323,\n",
       "        17545.16781817, 23113.46873045, 20556.82859907, 33744.92857918,\n",
       "        14438.75190919, 20443.57817332, 29517.95222103, 13110.30164298,\n",
       "        10771.33901668, 22264.76101158, 16907.7419308 , 12767.03606919,\n",
       "        15004.76080173, 13223.36217979,  9559.61118202, 10128.76333836,\n",
       "        19482.01231752, 33286.21423001, 20716.54356512, 29462.87780285,\n",
       "        25204.63775844, 27452.1456553 , 25204.63775844, 29480.71883126,\n",
       "        27512.83747592, 16503.34197927, 14216.95786928, 11139.1274517 ,\n",
       "        27398.585185  , 15615.56788581, 20062.97861616, 15737.710729  ,\n",
       "        15841.22952675,  9553.37763458, 17114.54817843, 23097.12685309,\n",
       "        28727.22282806, 18591.29706113, 15974.55340117, 20503.62089186,\n",
       "        15546.07904296, 30226.67386925,  9162.36256032, 21472.59852422,\n",
       "        21464.92304344, 16063.35620498, 14302.48028767, 21640.78637447,\n",
       "        45513.24017073, 15925.02420759, 20788.51351038, 23805.34340449,\n",
       "        20915.93195002, 17927.15667457, 16538.57212523,  9355.5108319 ,\n",
       "        14672.32623213, 14015.58925336, 19037.7505824 , 13227.31792499,\n",
       "        12165.55273538, 18450.18746534, 20540.38456504, 13804.06295005,\n",
       "        19972.76177065, 14209.38257546, 16771.0869259 , 15168.42518227,\n",
       "        36352.83121308, 33874.96767658, 21608.38395494, 41500.74121545,\n",
       "        11762.62001974, 15935.36513524, 33804.66064334, 12817.50796478,\n",
       "        27078.34700164, 29584.85602916, 23756.32365274, 18974.26749387,\n",
       "        23041.19392526, 12893.74376409, 15760.14086834, 47190.00021904,\n",
       "        28029.42520134, 16054.44437391, 13918.51043058, 35468.40416891,\n",
       "        28206.86199364, 17762.85146388, 28702.87589289, 20363.02185447,\n",
       "         7938.69261812, 13665.91772598, 15031.39659026, 16452.6704087 ,\n",
       "        27110.57751781, 21437.41618919, 28892.45528113, 21291.08738605,\n",
       "        26991.62990163, 28838.47010812, 20516.42360344, 17354.83061311,\n",
       "        26395.28150284, 13856.53038285, 23392.13023915, 21077.54701866,\n",
       "        13550.80341177, 27911.85372663, 14609.13951443, 15313.38526179,\n",
       "        21788.10076555, 19626.89758566, 15605.32140116, 28274.11862797,\n",
       "        16514.19094459, 19751.48057943, 15908.09301886, 17723.45047011,\n",
       "        15707.63492943, 35812.61260692, 29718.10393244, 13480.76349607,\n",
       "        24815.34457945, 12390.58699428, 17256.2429482 , 17288.96600441,\n",
       "        33320.7085187 , 18959.63198587, 24482.37486813, 33019.72227032,\n",
       "        17806.07161166,  9178.79519879, 16881.36057539, 11887.32775948,\n",
       "        15854.50955505, 20198.77253246, 17806.07161166, 37846.75316983,\n",
       "        15296.06953979, 13798.99552229, 33695.91066041, 33695.91066041,\n",
       "        21881.75861905, 22318.68157058, 37601.16458134, 13031.92356682,\n",
       "        32732.82585253, 12844.81146571, 17969.30624957, 19802.0283495 ,\n",
       "        22558.40357678, 16853.32010235, 22011.60331406, 18157.42037493,\n",
       "        22440.42834914, 22440.42834914, 22810.93768265, 22810.93768265]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prix_reels,prix_prédits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prix_prédits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prix_reels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22032.16884637, 41493.97568329, 24969.01072275, 17015.3782826 ,\n",
       "       17126.27646582, 27114.10183904, 33576.76423118, 19583.24971472,\n",
       "       18458.24464883, 16119.24664827, 11553.52919896, 28559.24319469,\n",
       "       33350.51359537, 12961.59346727, 27344.15342119, 15604.64210085,\n",
       "       10332.40695653, 15868.1933297 , 35350.51151928, 24947.14173634,\n",
       "        9507.27973956, 24999.61094805, 20437.72395714, 16183.5785166 ,\n",
       "       27850.37764051, 24385.08499141, 37405.14574699, 23939.98606217,\n",
       "       11153.80307871, 11257.19463506, 16320.25719375, 12501.68882293,\n",
       "       26683.83113381, 18697.69449216, 27204.38577592, 13768.77143029,\n",
       "       26995.87023121, 31328.11651601, 30319.07857488, 22677.05061951,\n",
       "       15929.1929971 , 21785.09065053, 27350.29152896, 17481.89883403,\n",
       "       16997.2907344 , 17008.89317683, 16604.82248709, 28832.39067338,\n",
       "       11051.50005201, 28996.1101355 , 15901.17853315, 26686.1155067 ,\n",
       "        6650.5662699 , 23074.67351689, 11616.04192409, 20669.03596089,\n",
       "       11358.93640592, 20117.74131627, 20718.46461345, 22993.67238777,\n",
       "       14660.63925068, 23948.73624228, 13376.76084315, 29987.95737348,\n",
       "       27141.23274189, 16325.18439697, 25271.28647523, 46985.94534936,\n",
       "       28155.12638628, 23556.00680641, 26584.09624549, 16308.80218015,\n",
       "       14859.24238181, 21145.08940523, 26632.84303938, 24988.96406895,\n",
       "       40162.16637192, 13142.24710183, 24169.2926553 , 17940.32029912,\n",
       "       15902.2504726 , 15292.82517551, 18265.28574553, 20727.08287248,\n",
       "       23285.67704694, 15707.66116519, 28636.74769687, 18761.75969968,\n",
       "       14814.80873764, 17827.14308292, 15071.39516383,  4902.57402336,\n",
       "       30957.8890345 , 16162.94362214, 14104.33457989, 32241.5444019 ,\n",
       "       11940.93630392, 25277.3932859 , 13501.36295835, 30394.90920751,\n",
       "       32529.28850541, 23815.71941918, 12352.15895519, 33273.46400833,\n",
       "       29367.34218642,  7847.64494393, 25896.366726  , 28236.80585252,\n",
       "       29826.61015542, 26864.74683905, 46426.43789215, 17374.84490606,\n",
       "       16973.29088805, 18159.82012588, 19627.88377635, 24988.59238854,\n",
       "       18394.38708687, 29671.0862962 , 29974.49128361, 26528.60224143,\n",
       "       23105.87563573, 33013.28976272, 40992.68196919, 26710.57804033,\n",
       "       17374.84490606, 39811.56337394, 26769.88229728, 19892.59706936,\n",
       "       29213.24688099, 14401.38251957, 29807.33871942, 33284.30689278,\n",
       "       19030.31293024, 18374.52361096, 16718.91785975, 23105.87563573,\n",
       "       14556.50314409, 20783.48636758, 16767.55085198, 28680.73695063,\n",
       "       24227.70823932, 14483.97634384, 26335.98956639, 26766.84908071,\n",
       "       11837.55701326, 15883.42103534, 18980.83950275, 16300.94629872,\n",
       "       10782.14395941, 12550.02357793, 19667.49434723, 26319.09136745,\n",
       "       17739.97232954,  5415.99405466, 13348.09580941, 12804.52240446,\n",
       "       16729.67294472, 16935.62137146, 24301.92333544, 33750.37496652,\n",
       "       16163.44502529, 21408.28605127, 25411.03951085, 16409.10079139,\n",
       "       20527.16054165, 27587.89320749, 12070.82080825, 19445.49869893,\n",
       "       12070.82080825, 19445.49869893, 23855.83823108, 21972.213002  ,\n",
       "       41590.01322558, 24922.55460572, 40608.62028196, 21684.87692947,\n",
       "       19785.00624329, 24008.59340863, 14361.71637686, 16431.71071812,\n",
       "       27721.05898276, 28182.28720894, 17407.6352632 , 20188.75169754,\n",
       "       29213.42872829, 27613.29706664, 23740.66667812, 23892.34586549,\n",
       "       23790.13337879, 17721.90640933, 18354.03191447,  9721.06973939,\n",
       "       17744.53795967, 22580.21748946, 19790.49884426, 23187.57966636,\n",
       "       13803.70561034, 21341.79174113, 16754.22688999, 18694.82333065,\n",
       "       22743.55996813, 15857.62451575, 28010.40615463, 23095.03802971,\n",
       "       13084.78054452, 17749.76964721, 33612.1273641 , 27076.94358413,\n",
       "       12283.00674533, 32253.70464586, 27120.06397257, 25817.53255569,\n",
       "       18263.92149185, 22166.9350696 , 18773.52877903, 19905.92169013,\n",
       "       14192.75123877, 27961.84294222, 29890.97742311, 17480.48237594,\n",
       "       14772.02958685, 17044.13780605, 30257.86335952, 20402.85341452,\n",
       "       26897.8487709 , 26993.93366841, 30312.26793558, 15226.82177855,\n",
       "       26927.60914573, 15149.92589355, 23410.05318677, 26804.80943896,\n",
       "       23034.91999699, 25744.93674696, 27250.89428199, 29331.58262836,\n",
       "       17840.2253371 , 27112.4414427 , 20049.56946381, 15204.18641774,\n",
       "       20898.29371258, 19932.85028245, 28464.70939286, 28150.2745974 ,\n",
       "       26600.93438933, 16425.25525467, 14760.18758514, 13360.43137631,\n",
       "       16094.72225145, 17907.90046451, 17565.81231081, 11097.24832555,\n",
       "       17548.72128783, 16763.85918125, 23850.42255827, 18775.96613278,\n",
       "       20150.36773632, 33459.01546071, 23609.93550849, 12196.93891702,\n",
       "       12413.30617384, 16770.80556898, 21845.36463768, 26828.99834904,\n",
       "       26890.90120058, 26953.18307168, 26970.86773495, 27072.88970828,\n",
       "       24247.79193946, 15912.29543603, 27800.67582361, 19694.99121251,\n",
       "       12804.92965217, 36188.50519352, 27285.8405607 , 13214.93599921,\n",
       "       12524.53215897, 26445.18455212, 16919.3208199 , 29354.92888488,\n",
       "       19648.65952786, 22465.8382469 , 28140.84455085, 25177.54374892,\n",
       "       21472.27789784, 25488.27989623, 26511.11189397, 27220.68232053,\n",
       "       25046.13575117, 35741.5751152 , 13751.64897978, 14295.7714834 ,\n",
       "       17391.00123279, 19175.30466713, 23227.9439873 , 18468.98701533,\n",
       "       26275.76498031, 10716.84541485, 11969.23671064,  6737.20406084,\n",
       "       39883.0557719 , 22156.14441774, 14812.0474643 , 10008.30855428,\n",
       "       20337.84333505, 21613.73982728, 18149.14933876, 18248.2874153 ,\n",
       "       14509.14712572, 15670.83663141, 15085.57330775, 14777.240137  ,\n",
       "       27152.95704157, 15443.23422777, 15442.95632495, 14691.64607068,\n",
       "       15352.01262948, 24988.75023303, 15315.4684096 , 28583.48961142,\n",
       "       28632.02895614, 33529.25597384, 13994.70292254, 15593.27424773,\n",
       "       22826.93574239, 22127.83913393, 20905.85797306, 12580.58965014,\n",
       "        9349.39697002, 32412.63175153, 14143.77192575, 19471.06487019,\n",
       "       11381.37463788,  8398.04313168, 27228.0597585 , 18557.65322095,\n",
       "       10793.9776733 , 34116.51486406, 16196.15592088, 10829.27268464,\n",
       "       41784.44265501, 14288.85991997, 47211.2692821 , 17620.17805374,\n",
       "       29015.23940603, 26527.24057421, 16015.49374343, 15855.9080532 ,\n",
       "       25661.3236766 , 15511.06330186, 15739.69887159, 25223.50115704,\n",
       "       42227.63676511, 27260.59853917, 27093.25912808, 20165.88202077,\n",
       "       37816.38526655, 33815.48123374, 23903.26177152, 35745.63802905,\n",
       "       26771.7675065 , 27232.0337484 , 28689.92134502, 32794.62429307,\n",
       "       33695.91066041, 28788.74003233, 32520.10797563, 16870.83656911,\n",
       "       28766.89317526, 14025.74043849, 16084.16571463, 28368.2454253 ,\n",
       "        7381.80809545, 23446.35743253, 11536.49149595, 17575.89664829,\n",
       "       17221.28020771, 12173.16861696, 17421.90156122, 23246.6736923 ,\n",
       "       24065.65247669, 19446.31953463, 32790.33396716, 15557.08721146,\n",
       "       21591.70398464, 16290.68902283, 18341.68233261, 17585.83775694,\n",
       "       16914.67466894, 19909.96131916, 24834.55330663, 25310.99381372,\n",
       "       26538.8151698 , 27534.34759068, 17352.88572415, 22054.7485284 ,\n",
       "       16798.83800102, 19062.90589496, 19855.78031639, 16946.33491889,\n",
       "       22787.00394071, 17743.72526103, 22259.3903808 , 35922.43211305,\n",
       "       27921.16518744, 27976.23307591, 17681.0203421 , 17436.33150706,\n",
       "       17802.64065733, 17565.90369351, 22092.44026604, 39433.08055442,\n",
       "       17729.93123714, 21974.33157062, 17215.43201399, 20586.05037286,\n",
       "       16957.38155569, 46246.47519741, 20995.89838207, 19541.27648578,\n",
       "       22940.30266076, 16339.28914393, 16813.51093254, 36069.53234707,\n",
       "       29524.70014592, 47298.61765475, 25999.50451873, 19340.0237333 ,\n",
       "       35673.67302849, 17201.77399691, 34628.46859955, 29058.73801757,\n",
       "       29872.77022436, 30281.19260837, 21177.38626541, 28803.15680668,\n",
       "       13163.91275458, 22468.72975752, 13284.40144628, 19273.68174323,\n",
       "       17545.16781817, 23113.46873045, 20556.82859907, 33744.92857918,\n",
       "       14438.75190919, 20443.57817332, 29517.95222103, 13110.30164298,\n",
       "       10771.33901668, 22264.76101158, 16907.7419308 , 12767.03606919,\n",
       "       15004.76080173, 13223.36217979,  9559.61118202, 10128.76333836,\n",
       "       19482.01231752, 33286.21423001, 20716.54356512, 29462.87780285,\n",
       "       25204.63775844, 27452.1456553 , 25204.63775844, 29480.71883126,\n",
       "       27512.83747592, 16503.34197927, 14216.95786928, 11139.1274517 ,\n",
       "       27398.585185  , 15615.56788581, 20062.97861616, 15737.710729  ,\n",
       "       15841.22952675,  9553.37763458, 17114.54817843, 23097.12685309,\n",
       "       28727.22282806, 18591.29706113, 15974.55340117, 20503.62089186,\n",
       "       15546.07904296, 30226.67386925,  9162.36256032, 21472.59852422,\n",
       "       21464.92304344, 16063.35620498, 14302.48028767, 21640.78637447,\n",
       "       45513.24017073, 15925.02420759, 20788.51351038, 23805.34340449,\n",
       "       20915.93195002, 17927.15667457, 16538.57212523,  9355.5108319 ,\n",
       "       14672.32623213, 14015.58925336, 19037.7505824 , 13227.31792499,\n",
       "       12165.55273538, 18450.18746534, 20540.38456504, 13804.06295005,\n",
       "       19972.76177065, 14209.38257546, 16771.0869259 , 15168.42518227,\n",
       "       36352.83121308, 33874.96767658, 21608.38395494, 41500.74121545,\n",
       "       11762.62001974, 15935.36513524, 33804.66064334, 12817.50796478,\n",
       "       27078.34700164, 29584.85602916, 23756.32365274, 18974.26749387,\n",
       "       23041.19392526, 12893.74376409, 15760.14086834, 47190.00021904,\n",
       "       28029.42520134, 16054.44437391, 13918.51043058, 35468.40416891,\n",
       "       28206.86199364, 17762.85146388, 28702.87589289, 20363.02185447,\n",
       "        7938.69261812, 13665.91772598, 15031.39659026, 16452.6704087 ,\n",
       "       27110.57751781, 21437.41618919, 28892.45528113, 21291.08738605,\n",
       "       26991.62990163, 28838.47010812, 20516.42360344, 17354.83061311,\n",
       "       26395.28150284, 13856.53038285, 23392.13023915, 21077.54701866,\n",
       "       13550.80341177, 27911.85372663, 14609.13951443, 15313.38526179,\n",
       "       21788.10076555, 19626.89758566, 15605.32140116, 28274.11862797,\n",
       "       16514.19094459, 19751.48057943, 15908.09301886, 17723.45047011,\n",
       "       15707.63492943, 35812.61260692, 29718.10393244, 13480.76349607,\n",
       "       24815.34457945, 12390.58699428, 17256.2429482 , 17288.96600441,\n",
       "       33320.7085187 , 18959.63198587, 24482.37486813, 33019.72227032,\n",
       "       17806.07161166,  9178.79519879, 16881.36057539, 11887.32775948,\n",
       "       15854.50955505, 20198.77253246, 17806.07161166, 37846.75316983,\n",
       "       15296.06953979, 13798.99552229, 33695.91066041, 33695.91066041,\n",
       "       21881.75861905, 22318.68157058, 37601.16458134, 13031.92356682,\n",
       "       32732.82585253, 12844.81146571, 17969.30624957, 19802.0283495 ,\n",
       "       22558.40357678, 16853.32010235, 22011.60331406, 18157.42037493,\n",
       "       22440.42834914, 22440.42834914, 22810.93768265, 22810.93768265])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prix_prédits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22990, 42790, 23990, 17290, 17490, 26980, 37390, 17990, 18490,\n",
       "       13790, 12280, 29790, 33790, 11480, 27290, 14990, 10990, 13990,\n",
       "       31990, 23990, 10990, 23990, 19990, 11990, 24990, 23490, 34990,\n",
       "       22990,  9790, 13990, 15990, 13790, 26790, 19390, 26790, 13990,\n",
       "       24990, 26990, 27990, 22890, 14990, 21990, 26990, 15790, 15790,\n",
       "       15790, 14990, 27790, 10990, 26990, 15490, 27990,  7490, 21990,\n",
       "        9990, 18990, 11990, 18890, 19990, 19890, 13990, 22990, 13990,\n",
       "       27990, 25990, 15980, 27490, 45990, 27490, 22990, 24990, 16990,\n",
       "       15990, 20990, 26990, 26990, 43990, 14490, 24990, 19990, 18990,\n",
       "       16490, 17990, 20990, 23990, 19490, 31990, 20490, 18990, 19790,\n",
       "       18990,  9790, 33990, 17490, 16990, 36990, 13990, 27490, 13990,\n",
       "       32990, 34990, 26890, 11990, 39000, 27900, 11500, 26900, 30900,\n",
       "       31900, 29500, 49000, 18900, 18800, 17900, 22400, 25900, 16500,\n",
       "       30500, 28500, 27900, 22500, 36500, 44990, 23900, 18900, 40900,\n",
       "       26900, 21000, 29500, 14900, 29500, 30900, 21000, 19500, 19300,\n",
       "       21100, 15500, 19800, 19900, 32900, 27900, 17500, 28500, 27490,\n",
       "       13500, 19500, 17900, 13490, 10990, 12490, 18990, 24990, 15990,\n",
       "       10990, 13490, 12490, 15990, 16490, 23990, 32990, 14990, 23990,\n",
       "       24990, 14490, 17490, 27990, 12990, 17490, 12990, 17490, 23990,\n",
       "       22990, 41990, 24990, 39790, 22900, 18490, 23490, 16490, 17990,\n",
       "       29490, 26490, 16490, 24490, 27990, 25490, 24990, 24990, 24990,\n",
       "       18990, 16990,  9990, 18490, 22990, 18990, 24990, 15990, 19990,\n",
       "       16990, 18990, 22990, 13850, 29490, 24990, 13490, 17990, 35990,\n",
       "       27990, 11990, 34900, 26990, 25990, 18990, 19990, 15990, 18990,\n",
       "       11990, 27990, 26990, 16490, 14200, 14500, 28990, 18990, 27900,\n",
       "       28900, 31500, 15499, 24990, 15990, 23490, 26499, 22490, 24995,\n",
       "       25999, 29100, 16500, 26890, 18995, 15990, 18990, 18300, 28900,\n",
       "       26990, 24990, 16990, 15990, 13500, 15980, 17990, 14900, 11500,\n",
       "       14900, 18990, 24300, 18340, 20150, 31350, 23990, 14990,  9600,\n",
       "       14900, 20990, 28900, 28900, 28900, 28900, 27900, 24300, 14500,\n",
       "       29900, 23195, 13450, 39990, 29250, 16150, 14050, 29250, 18250,\n",
       "       28850, 21350, 19950, 27250, 26850, 21250, 22450, 29650, 28250,\n",
       "       25990, 37188, 13790, 15990, 18790, 18990, 25490, 17990, 31990,\n",
       "       10790, 11990,  8990, 36290, 20999, 13899, 12299, 17999, 20999,\n",
       "       18499, 18490, 13899, 14499, 14199, 13999, 25499, 14499, 14499,\n",
       "       13999, 14499, 24999, 14499, 28799, 29499, 38999, 13285, 13200,\n",
       "       19485, 22295, 18490, 13995, 11325, 34985, 11485, 16990, 12490,\n",
       "        9890, 25490, 12490,  8490, 37980, 14980, 11780, 39990, 14780,\n",
       "       49990, 17980, 31390, 25250, 14980, 14950, 23950, 13980, 15980,\n",
       "       20950, 47490, 28480, 26490, 23880, 30990, 39590, 24780, 36990,\n",
       "       23900, 24950, 28450, 38250, 33213, 25890, 28600, 16950, 28450,\n",
       "       13850, 15880, 25480,  9950, 24480, 14280, 17480, 17950, 12480,\n",
       "       18280, 22780, 21250, 19480, 31780, 17280, 23980, 14350, 17440,\n",
       "       16780, 16280, 19480, 23480, 23250, 27242, 25480, 17480, 21980,\n",
       "       15450, 18834, 18280, 15250, 19780, 15750, 20250, 37480, 27980,\n",
       "       27450, 16200, 16250, 16200, 16250, 20250, 35780, 15980, 20150,\n",
       "       15700, 20150, 16600, 44980, 16980, 17280, 20980, 15280, 15480,\n",
       "       37980, 33890, 49990, 26780, 17980, 40980, 15280, 34490, 29990,\n",
       "       31490, 29990, 20388, 28990, 13990, 20990, 12490, 19490, 16990,\n",
       "       26990, 26990, 31990, 12490, 18799, 28990, 13890, 11490, 22490,\n",
       "       15990, 12490, 13490, 12990, 11890, 11990, 19990, 36490, 21990,\n",
       "       31990, 27390, 27990, 27390, 31990, 27990, 15990, 11990, 13490,\n",
       "       26490, 14490, 19990, 15990, 15990, 11990, 15990, 19990, 27990,\n",
       "       17990, 15990, 19990, 15990, 29990,  9990, 20990, 20990, 14490,\n",
       "       14900, 20990, 45900, 15490, 18490, 21490, 18490, 18490, 15990,\n",
       "       11290, 16990, 11490, 18990, 11490, 10890, 14990, 18490, 13990,\n",
       "       21990, 14990, 15990, 15490, 38490, 33990, 20490, 45990, 12990,\n",
       "       13990, 38990, 12990, 24990, 26490, 19990, 18990, 23990, 12490,\n",
       "       15490, 48990, 27990, 15490, 11990, 37290, 28990, 17490, 29490,\n",
       "       19900,  8990, 14700, 13900, 17290, 28900, 22900, 25900, 21490,\n",
       "       28900, 31900, 20490, 17900, 28900, 13900, 21900, 20900, 13490,\n",
       "       29900, 15900, 14900, 21790, 18900, 15490, 27489, 15489, 19889,\n",
       "       13989, 16989, 15489, 32960, 29000, 13490, 23950, 11378, 16989,\n",
       "       17389, 35489, 19990, 25989, 34689, 15889, 11989, 16989, 11999,\n",
       "       13889, 18989, 15889, 36849, 13999, 11999, 32989, 32989, 21589,\n",
       "       22979, 32489, 11399, 36790, 12879, 13799, 15799, 21489, 16989,\n",
       "       19989, 17579, 22689, 22689, 22689, 22689], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prix_reels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif : maximiser le surplus de l'acheteur, i.e, si l'acheteur à un budget R, et n contraintes, quel véhicule maximiserait son surplus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_finale = conversion_df.data_frame_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_finale['prix_predits'] = prix_prédits\n",
    "data_finale['surplus_conso'] = data_finale['prix'] - data_finale['prix_predits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prix</th>\n",
       "      <th>kilometrage</th>\n",
       "      <th>date_mise_circulation</th>\n",
       "      <th>puissance</th>\n",
       "      <th>nb_places</th>\n",
       "      <th>puissance_fiscale</th>\n",
       "      <th>critair</th>\n",
       "      <th>ptac</th>\n",
       "      <th>nb_portes</th>\n",
       "      <th>BERLINGO</th>\n",
       "      <th>...</th>\n",
       "      <th>SPOTICAR PREMIUM</th>\n",
       "      <th>Ex-Auto-école</th>\n",
       "      <th>Ex-Import</th>\n",
       "      <th>Ex-Loueur</th>\n",
       "      <th>Ex-Particulier</th>\n",
       "      <th>Ex-Société</th>\n",
       "      <th>Véhicule de direction</th>\n",
       "      <th>Citroen</th>\n",
       "      <th>prix_predits</th>\n",
       "      <th>surplus_conso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22990</td>\n",
       "      <td>20629.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22032.168846</td>\n",
       "      <td>957.831154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42790</td>\n",
       "      <td>5104.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>181.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41493.975683</td>\n",
       "      <td>1296.024317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23990</td>\n",
       "      <td>8900.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24969.010723</td>\n",
       "      <td>-979.010723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17290</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17015.378283</td>\n",
       "      <td>274.621717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17490</td>\n",
       "      <td>37377.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17126.276466</td>\n",
       "      <td>363.723534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>17579</td>\n",
       "      <td>10598.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18157.420375</td>\n",
       "      <td>-578.420375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>22689</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22440.428349</td>\n",
       "      <td>248.571651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>22689</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22440.428349</td>\n",
       "      <td>248.571651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>22689</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22810.937683</td>\n",
       "      <td>-121.937683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>22689</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22810.937683</td>\n",
       "      <td>-121.937683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prix  kilometrage  date_mise_circulation  puissance  nb_places  \\\n",
       "0    22990      20629.0                   2021      110.0        5.0   \n",
       "1    42790       5104.0                   2022      181.0        5.0   \n",
       "2    23990       8900.0                   2021      131.0        5.0   \n",
       "3    17290       1305.0                   2021       83.0        5.0   \n",
       "4    17490      37377.0                   2019      110.0        5.0   \n",
       "..     ...          ...                    ...        ...        ...   \n",
       "595  17579      10598.0                   2018      110.0        5.0   \n",
       "596  22689         30.0                   2022      110.0        5.0   \n",
       "597  22689         30.0                   2022      110.0        5.0   \n",
       "598  22689         30.0                   2022      110.0        5.0   \n",
       "599  22689         30.0                   2022      110.0        5.0   \n",
       "\n",
       "     puissance_fiscale  critair    ptac  nb_portes  BERLINGO  ...  \\\n",
       "0                  6.0      2.0  1835.0        5.0         0  ...   \n",
       "1                 10.0      1.0  2300.0        5.0         0  ...   \n",
       "2                  7.0      1.0  1735.0        5.0         0  ...   \n",
       "3                  4.0      1.0  1540.0        5.0         0  ...   \n",
       "4                  5.0      1.0  1600.0        5.0         0  ...   \n",
       "..                 ...      ...     ...        ...       ...  ...   \n",
       "595                5.0      1.0  1795.0        5.0         0  ...   \n",
       "596                6.0      1.0  1610.0        5.0         0  ...   \n",
       "597                6.0      1.0  1610.0        5.0         0  ...   \n",
       "598                6.0      1.0  1610.0        5.0         0  ...   \n",
       "599                6.0      1.0  1610.0        5.0         0  ...   \n",
       "\n",
       "     SPOTICAR PREMIUM  Ex-Auto-école  Ex-Import  Ex-Loueur  Ex-Particulier  \\\n",
       "0                   1              0          1          0               0   \n",
       "1                   1              0          0          1               0   \n",
       "2                   1              0          1          0               0   \n",
       "3                   1              0          1          0               0   \n",
       "4                   1              0          1          0               0   \n",
       "..                ...            ...        ...        ...             ...   \n",
       "595                 1              0          0          0               1   \n",
       "596                 1              0          1          0               0   \n",
       "597                 1              0          1          0               0   \n",
       "598                 1              0          1          0               0   \n",
       "599                 1              0          1          0               0   \n",
       "\n",
       "     Ex-Société  Véhicule de direction  Citroen  prix_predits  surplus_conso  \n",
       "0             0                      0        1  22032.168846     957.831154  \n",
       "1             0                      0        1  41493.975683    1296.024317  \n",
       "2             0                      0        1  24969.010723    -979.010723  \n",
       "3             0                      0        1  17015.378283     274.621717  \n",
       "4             0                      0        1  17126.276466     363.723534  \n",
       "..          ...                    ...      ...           ...            ...  \n",
       "595           0                      0        1  18157.420375    -578.420375  \n",
       "596           0                      0        1  22440.428349     248.571651  \n",
       "597           0                      0        1  22440.428349     248.571651  \n",
       "598           0                      0        1  22810.937683    -121.937683  \n",
       "599           0                      0        1  22810.937683    -121.937683  \n",
       "\n",
       "[600 rows x 67 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_finale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95d745ba7d4956a2c972602a1881faa5aacde8c57f39878a3d2b517a3ec985cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
